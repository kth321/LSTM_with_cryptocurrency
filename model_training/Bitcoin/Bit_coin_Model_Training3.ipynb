{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eoUg8l58jQ6A","executionInfo":{"status":"ok","timestamp":1669953198569,"user_tz":-540,"elapsed":20259,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"3b559d7a-3f45-4060-8381-bd7479e53136"},"id":"eoUg8l58jQ6A","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":2,"id":"e31618f6","metadata":{"id":"e31618f6","executionInfo":{"status":"ok","timestamp":1669953201938,"user_tz":-540,"elapsed":3375,"user":{"displayName":"구태형","userId":"12113658638621684006"}}},"outputs":[],"source":["import math\n","\n","import sys\n","\n","import numpy as np\n","\n","import matplotlib.pyplot as plt\n","\n","import keras\n","\n","import pandas as pd\n","\n","import numpy as np\n","\n","from keras.models import Sequential\n","\n","from keras.layers import Dense\n","\n","from keras.layers import LSTM\n","\n","from keras.layers import Dropout\n","\n","from keras.layers import *\n","\n","from sklearn.preprocessing import MinMaxScaler\n","\n","from sklearn.preprocessing import StandardScaler\n","\n","from sklearn.metrics import mean_squared_error\n","\n","from sklearn.metrics import mean_absolute_error\n","\n","from sklearn.model_selection import train_test_split\n","\n","from keras.callbacks import EarlyStopping"]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/학교/3학년2학기/소프트웨어융합개론/coin/indicator"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pL_c18W0jo2h","executionInfo":{"status":"ok","timestamp":1669953202426,"user_tz":-540,"elapsed":493,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"923a3a65-30c1-45d8-a8ed-c888a5c14af0"},"id":"pL_c18W0jo2h","execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/학교/3학년2학기/소프트웨어융합개론/coin/indicator\n"]}]},{"cell_type":"code","execution_count":4,"id":"764ecdc5","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":500},"id":"764ecdc5","executionInfo":{"status":"ok","timestamp":1669953203563,"user_tz":-540,"elapsed":1140,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"df0af8eb-e83d-4ab3-cfc2-613e1a4e3e5e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of rows and columns: (3962, 25)\n"]},{"output_type":"execute_result","data":{"text/plain":["           close  close_log        nvi         pvi        ma_5       ma_10  \\\n","0      3091000.0  14.944005   1.163482   3063000.0   3084200.0   3170200.0   \n","1      3087000.0  14.942710   1.163482   3087000.0   3088600.0   3137500.0   \n","2      3071000.0  14.937514   1.157451   3087000.0   3085200.0   3106200.0   \n","3      3050000.0  14.930652   1.157451   3050000.0   3072400.0   3086100.0   \n","4      3003000.0  14.915122   1.139615   3050000.0   3060400.0   3063700.0   \n","...          ...        ...        ...         ...         ...         ...   \n","3957  22320000.0  16.920994  19.407960  22320000.0  22490200.0  22593100.0   \n","3958  22403000.0  16.924705  19.480131  22320000.0  22430800.0  22571300.0   \n","3959  23004000.0  16.951179  19.480131  23004000.0  22496800.0  22612900.0   \n","3960  22790000.0  16.941832  19.298913  23004000.0  22581400.0  22618800.0   \n","3961  23097000.0  16.955213  19.298913  23097000.0  22722800.0  22648600.0   \n","\n","           ma_20         ma_60        rsi           vpt  ...        mfi  \\\n","0      3289500.0  3.215300e+06  24.735450 -50913.192669  ...  53.117928   \n","1      3279000.0  3.216817e+06  25.546448 -50921.710773  ...  54.027715   \n","2      3262700.0  3.216783e+06  25.304465 -50942.230512  ...  52.648713   \n","3      3243350.0  3.215633e+06  26.044568 -50979.943691  ...  53.324172   \n","4      3223000.0  3.214083e+06  25.442177 -51042.834596  ...  54.476339   \n","...          ...           ...        ...           ...  ...        ...   \n","3957  22691850.0  2.493500e+07  46.624136   2341.093255  ...  53.458386   \n","3958  22662550.0  2.482275e+07  48.006214   2346.997775  ...  53.335951   \n","3959  22660250.0  2.472663e+07  51.684312   2391.934249  ...  43.927284   \n","3960  22651250.0  2.462907e+07  47.797063   2377.924759  ...  45.856043   \n","3961  22682950.0  2.453300e+07  51.084237   2402.135900  ...  45.480344   \n","\n","             ema_5        ema_10        ema_20        ema_60            fi  \\\n","0     3.101464e+06  3.154992e+06  3.207830e+06  3.195372e+06 -2.058452e+09   \n","1     3.096642e+06  3.142630e+06  3.196323e+06  3.191819e+06 -2.356487e+09   \n","2     3.088095e+06  3.129606e+06  3.184387e+06  3.187857e+06 -1.445045e+09   \n","3     3.075397e+06  3.115132e+06  3.171588e+06  3.183338e+06 -1.897196e+09   \n","4     3.051264e+06  3.094745e+06  3.155532e+06  3.177425e+06 -1.473320e+09   \n","...            ...           ...           ...           ...           ...   \n","3957  2.245848e+07  2.256368e+07  2.277992e+07  2.431527e+07 -2.116684e+08   \n","3958  2.243999e+07  2.253446e+07  2.274402e+07  2.425257e+07 -1.222620e+08   \n","3959  2.262799e+07  2.261983e+07  2.276878e+07  2.421164e+07  1.172543e+08   \n","3960  2.268200e+07  2.265077e+07  2.277080e+07  2.416503e+07 -1.490895e+08   \n","3961  2.282033e+07  2.273190e+07  2.280187e+07  2.413001e+07  9.345974e+07   \n","\n","               ubb         mbb           lbb       volume  \n","0     3.610062e+06   3289500.0  2.968938e+06  5388.617973  \n","1     3.612042e+06   3279000.0  2.945958e+06  6582.364759  \n","2     3.603251e+06   3262700.0  2.922149e+06  3959.027066  \n","3     3.586173e+06   3243350.0  2.900527e+06  5515.103573  \n","4     3.572426e+06   3223000.0  2.873574e+06  4081.218313  \n","...            ...         ...           ...          ...  \n","3957  2.316037e+07  22691850.0  2.222333e+07  1666.680241  \n","3958  2.312610e+07  22662550.0  2.219900e+07  1587.817986  \n","3959  2.311609e+07  22660250.0  2.220441e+07  1675.061266  \n","3960  2.308805e+07  22651250.0  2.221445e+07  1505.954700  \n","3961  2.315299e+07  22682950.0  2.221291e+07  1797.302637  \n","\n","[3962 rows x 25 columns]"],"text/html":["\n","  <div id=\"df-ea724d52-1178-48a4-a109-e93850bb2ca5\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>close</th>\n","      <th>close_log</th>\n","      <th>nvi</th>\n","      <th>pvi</th>\n","      <th>ma_5</th>\n","      <th>ma_10</th>\n","      <th>ma_20</th>\n","      <th>ma_60</th>\n","      <th>rsi</th>\n","      <th>vpt</th>\n","      <th>...</th>\n","      <th>mfi</th>\n","      <th>ema_5</th>\n","      <th>ema_10</th>\n","      <th>ema_20</th>\n","      <th>ema_60</th>\n","      <th>fi</th>\n","      <th>ubb</th>\n","      <th>mbb</th>\n","      <th>lbb</th>\n","      <th>volume</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3091000.0</td>\n","      <td>14.944005</td>\n","      <td>1.163482</td>\n","      <td>3063000.0</td>\n","      <td>3084200.0</td>\n","      <td>3170200.0</td>\n","      <td>3289500.0</td>\n","      <td>3.215300e+06</td>\n","      <td>24.735450</td>\n","      <td>-50913.192669</td>\n","      <td>...</td>\n","      <td>53.117928</td>\n","      <td>3.101464e+06</td>\n","      <td>3.154992e+06</td>\n","      <td>3.207830e+06</td>\n","      <td>3.195372e+06</td>\n","      <td>-2.058452e+09</td>\n","      <td>3.610062e+06</td>\n","      <td>3289500.0</td>\n","      <td>2.968938e+06</td>\n","      <td>5388.617973</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3087000.0</td>\n","      <td>14.942710</td>\n","      <td>1.163482</td>\n","      <td>3087000.0</td>\n","      <td>3088600.0</td>\n","      <td>3137500.0</td>\n","      <td>3279000.0</td>\n","      <td>3.216817e+06</td>\n","      <td>25.546448</td>\n","      <td>-50921.710773</td>\n","      <td>...</td>\n","      <td>54.027715</td>\n","      <td>3.096642e+06</td>\n","      <td>3.142630e+06</td>\n","      <td>3.196323e+06</td>\n","      <td>3.191819e+06</td>\n","      <td>-2.356487e+09</td>\n","      <td>3.612042e+06</td>\n","      <td>3279000.0</td>\n","      <td>2.945958e+06</td>\n","      <td>6582.364759</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3071000.0</td>\n","      <td>14.937514</td>\n","      <td>1.157451</td>\n","      <td>3087000.0</td>\n","      <td>3085200.0</td>\n","      <td>3106200.0</td>\n","      <td>3262700.0</td>\n","      <td>3.216783e+06</td>\n","      <td>25.304465</td>\n","      <td>-50942.230512</td>\n","      <td>...</td>\n","      <td>52.648713</td>\n","      <td>3.088095e+06</td>\n","      <td>3.129606e+06</td>\n","      <td>3.184387e+06</td>\n","      <td>3.187857e+06</td>\n","      <td>-1.445045e+09</td>\n","      <td>3.603251e+06</td>\n","      <td>3262700.0</td>\n","      <td>2.922149e+06</td>\n","      <td>3959.027066</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3050000.0</td>\n","      <td>14.930652</td>\n","      <td>1.157451</td>\n","      <td>3050000.0</td>\n","      <td>3072400.0</td>\n","      <td>3086100.0</td>\n","      <td>3243350.0</td>\n","      <td>3.215633e+06</td>\n","      <td>26.044568</td>\n","      <td>-50979.943691</td>\n","      <td>...</td>\n","      <td>53.324172</td>\n","      <td>3.075397e+06</td>\n","      <td>3.115132e+06</td>\n","      <td>3.171588e+06</td>\n","      <td>3.183338e+06</td>\n","      <td>-1.897196e+09</td>\n","      <td>3.586173e+06</td>\n","      <td>3243350.0</td>\n","      <td>2.900527e+06</td>\n","      <td>5515.103573</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>3003000.0</td>\n","      <td>14.915122</td>\n","      <td>1.139615</td>\n","      <td>3050000.0</td>\n","      <td>3060400.0</td>\n","      <td>3063700.0</td>\n","      <td>3223000.0</td>\n","      <td>3.214083e+06</td>\n","      <td>25.442177</td>\n","      <td>-51042.834596</td>\n","      <td>...</td>\n","      <td>54.476339</td>\n","      <td>3.051264e+06</td>\n","      <td>3.094745e+06</td>\n","      <td>3.155532e+06</td>\n","      <td>3.177425e+06</td>\n","      <td>-1.473320e+09</td>\n","      <td>3.572426e+06</td>\n","      <td>3223000.0</td>\n","      <td>2.873574e+06</td>\n","      <td>4081.218313</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>3957</th>\n","      <td>22320000.0</td>\n","      <td>16.920994</td>\n","      <td>19.407960</td>\n","      <td>22320000.0</td>\n","      <td>22490200.0</td>\n","      <td>22593100.0</td>\n","      <td>22691850.0</td>\n","      <td>2.493500e+07</td>\n","      <td>46.624136</td>\n","      <td>2341.093255</td>\n","      <td>...</td>\n","      <td>53.458386</td>\n","      <td>2.245848e+07</td>\n","      <td>2.256368e+07</td>\n","      <td>2.277992e+07</td>\n","      <td>2.431527e+07</td>\n","      <td>-2.116684e+08</td>\n","      <td>2.316037e+07</td>\n","      <td>22691850.0</td>\n","      <td>2.222333e+07</td>\n","      <td>1666.680241</td>\n","    </tr>\n","    <tr>\n","      <th>3958</th>\n","      <td>22403000.0</td>\n","      <td>16.924705</td>\n","      <td>19.480131</td>\n","      <td>22320000.0</td>\n","      <td>22430800.0</td>\n","      <td>22571300.0</td>\n","      <td>22662550.0</td>\n","      <td>2.482275e+07</td>\n","      <td>48.006214</td>\n","      <td>2346.997775</td>\n","      <td>...</td>\n","      <td>53.335951</td>\n","      <td>2.243999e+07</td>\n","      <td>2.253446e+07</td>\n","      <td>2.274402e+07</td>\n","      <td>2.425257e+07</td>\n","      <td>-1.222620e+08</td>\n","      <td>2.312610e+07</td>\n","      <td>22662550.0</td>\n","      <td>2.219900e+07</td>\n","      <td>1587.817986</td>\n","    </tr>\n","    <tr>\n","      <th>3959</th>\n","      <td>23004000.0</td>\n","      <td>16.951179</td>\n","      <td>19.480131</td>\n","      <td>23004000.0</td>\n","      <td>22496800.0</td>\n","      <td>22612900.0</td>\n","      <td>22660250.0</td>\n","      <td>2.472663e+07</td>\n","      <td>51.684312</td>\n","      <td>2391.934249</td>\n","      <td>...</td>\n","      <td>43.927284</td>\n","      <td>2.262799e+07</td>\n","      <td>2.261983e+07</td>\n","      <td>2.276878e+07</td>\n","      <td>2.421164e+07</td>\n","      <td>1.172543e+08</td>\n","      <td>2.311609e+07</td>\n","      <td>22660250.0</td>\n","      <td>2.220441e+07</td>\n","      <td>1675.061266</td>\n","    </tr>\n","    <tr>\n","      <th>3960</th>\n","      <td>22790000.0</td>\n","      <td>16.941832</td>\n","      <td>19.298913</td>\n","      <td>23004000.0</td>\n","      <td>22581400.0</td>\n","      <td>22618800.0</td>\n","      <td>22651250.0</td>\n","      <td>2.462907e+07</td>\n","      <td>47.797063</td>\n","      <td>2377.924759</td>\n","      <td>...</td>\n","      <td>45.856043</td>\n","      <td>2.268200e+07</td>\n","      <td>2.265077e+07</td>\n","      <td>2.277080e+07</td>\n","      <td>2.416503e+07</td>\n","      <td>-1.490895e+08</td>\n","      <td>2.308805e+07</td>\n","      <td>22651250.0</td>\n","      <td>2.221445e+07</td>\n","      <td>1505.954700</td>\n","    </tr>\n","    <tr>\n","      <th>3961</th>\n","      <td>23097000.0</td>\n","      <td>16.955213</td>\n","      <td>19.298913</td>\n","      <td>23097000.0</td>\n","      <td>22722800.0</td>\n","      <td>22648600.0</td>\n","      <td>22682950.0</td>\n","      <td>2.453300e+07</td>\n","      <td>51.084237</td>\n","      <td>2402.135900</td>\n","      <td>...</td>\n","      <td>45.480344</td>\n","      <td>2.282033e+07</td>\n","      <td>2.273190e+07</td>\n","      <td>2.280187e+07</td>\n","      <td>2.413001e+07</td>\n","      <td>9.345974e+07</td>\n","      <td>2.315299e+07</td>\n","      <td>22682950.0</td>\n","      <td>2.221291e+07</td>\n","      <td>1797.302637</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3962 rows × 25 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ea724d52-1178-48a4-a109-e93850bb2ca5')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ea724d52-1178-48a4-a109-e93850bb2ca5 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ea724d52-1178-48a4-a109-e93850bb2ca5');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":4}],"source":["df=pd.read_csv(\"bitcoin_indicator.csv\")\n","df_time = pd.read_csv(\"time.csv\")\n","print('Number of rows and columns:', df.shape)\n","\n","time_step = 30\n","index_rsi = 14\n","n_days = 15\n","\n","df"]},{"cell_type":"code","execution_count":5,"id":"a7df70f9","metadata":{"id":"a7df70f9","executionInfo":{"status":"ok","timestamp":1669953203564,"user_tz":-540,"elapsed":55,"user":{"displayName":"구태형","userId":"12113658638621684006"}}},"outputs":[],"source":["df_time = df_time.iloc[:,0]"]},{"cell_type":"code","execution_count":6,"id":"c97a1fe6","metadata":{"id":"c97a1fe6","executionInfo":{"status":"ok","timestamp":1669953203565,"user_tz":-540,"elapsed":53,"user":{"displayName":"구태형","userId":"12113658638621684006"}}},"outputs":[],"source":["df_time = df_time.str[:10]"]},{"cell_type":"code","source":["res = []"],"metadata":{"id":"ZyQ-jsXKoupq","executionInfo":{"status":"ok","timestamp":1669953203566,"user_tz":-540,"elapsed":53,"user":{"displayName":"구태형","userId":"12113658638621684006"}}},"id":"ZyQ-jsXKoupq","execution_count":7,"outputs":[]},{"cell_type":"markdown","id":"c3e84c6b","metadata":{"id":"c3e84c6b"},"source":["# training set/ test set"]},{"cell_type":"code","execution_count":8,"id":"37574682","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"37574682","executionInfo":{"status":"ok","timestamp":1669953203566,"user_tz":-540,"elapsed":52,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"7f34d0bd-203d-4f13-b1bf-c73d7dffc52f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3169, 24)"]},"metadata":{},"execution_count":8}],"source":["feature = df.iloc[:,1:]\n","\n","idx = int(feature.shape[0]*0.8)\n","\n","training_set = feature.iloc[:idx].values\n","test_set = feature.iloc[idx:].values\n","training_set.shape"]},{"cell_type":"code","execution_count":9,"id":"664f1c48","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"664f1c48","executionInfo":{"status":"ok","timestamp":1669953203567,"user_tz":-540,"elapsed":44,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"e04e9127-5ee5-4a62-85ec-3031bb39ab09"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1.49440052e+01, 1.16348160e+00, 3.06300000e+06, ...,\n","        3.28950000e+06, 2.96893767e+06, 5.38861797e+03],\n","       [1.49427103e+01, 1.16348160e+00, 3.08700000e+06, ...,\n","        3.27900000e+06, 2.94595788e+06, 6.58236476e+03],\n","       [1.49375138e+01, 1.15745125e+00, 3.08700000e+06, ...,\n","        3.26270000e+06, 2.92214868e+06, 3.95902707e+03],\n","       ...,\n","       [1.81156490e+01, 2.14693282e+01, 7.37100000e+07, ...,\n","        7.54120500e+07, 7.09528907e+07, 2.58543345e+03],\n","       [1.81241328e+01, 2.16522442e+01, 7.37100000e+07, ...,\n","        7.52044000e+07, 7.09676991e+07, 2.22946506e+03],\n","       [1.81121971e+01, 2.13953462e+01, 7.37100000e+07, ...,\n","        7.48318500e+07, 7.14908085e+07, 1.95423116e+03]])"]},"metadata":{},"execution_count":9}],"source":["training_set"]},{"cell_type":"code","execution_count":10,"id":"fed35bac","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fed35bac","executionInfo":{"status":"ok","timestamp":1669953203567,"user_tz":-540,"elapsed":36,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"4e5dee63-360f-403b-a5ec-23a5c5a2c6b9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([-1.66957522, -1.66488984, -1.67506461, ...,  2.15800037,\n","        2.16822929,  2.15383842])"]},"metadata":{},"execution_count":10}],"source":["# 정규화\n","ss = StandardScaler()\n","\n","training_set_scaled = ss.fit_transform(training_set)\n","\n","X_train = []\n","\n","y_train = []\n","\n","for i in range(time_step, idx-n_days):\n","    X_train.append(training_set_scaled[i-time_step:i])\n","\n","    y_train.append(training_set_scaled[i+n_days, 0])\n","\n","X_train, y_train = np.array(X_train), np.array(y_train)\n","y_train"]},{"cell_type":"code","execution_count":11,"id":"6db2ea61","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6db2ea61","executionInfo":{"status":"ok","timestamp":1669953203567,"user_tz":-540,"elapsed":28,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"97e01962-a57d-4920-cea7-7dfdbe0851bc"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3124, 30, 24)"]},"metadata":{},"execution_count":11}],"source":["X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], X_train.shape[2]))\n","X_train.shape"]},{"cell_type":"code","execution_count":12,"id":"a210853a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a210853a","executionInfo":{"status":"ok","timestamp":1669953203568,"user_tz":-540,"elapsed":21,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"a9bb0c83-acab-4e32-e3ac-f325c415644b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3124,)"]},"metadata":{},"execution_count":12}],"source":["y_train.shape"]},{"cell_type":"markdown","id":"0e0265a7","metadata":{"id":"0e0265a7"},"source":["# 모델 학습"]},{"cell_type":"code","execution_count":13,"id":"b3a399d2","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b3a399d2","executionInfo":{"status":"ok","timestamp":1669953387316,"user_tz":-540,"elapsed":183761,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"eb9b76c3-0507-45b8-8062-59b92bd10a3d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/80\n","98/98 [==============================] - 18s 21ms/step - loss: 0.1454\n","Epoch 2/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0580\n","Epoch 3/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0485\n","Epoch 4/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0434\n","Epoch 5/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0406\n","Epoch 6/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0388\n","Epoch 7/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0361\n","Epoch 8/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0336\n","Epoch 9/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0320\n","Epoch 10/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0302\n","Epoch 11/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0291\n","Epoch 12/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0313\n","Epoch 13/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0283\n","Epoch 14/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0264\n","Epoch 15/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0267\n","Epoch 16/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0247\n","Epoch 17/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0256\n","Epoch 18/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0249\n","Epoch 19/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0244\n","Epoch 20/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0230\n","Epoch 21/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0230\n","Epoch 22/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0200\n","Epoch 23/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0233\n","Epoch 24/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0242\n","Epoch 25/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0224\n","Epoch 26/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0206\n","Epoch 27/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0220\n","Epoch 28/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0191\n","Epoch 29/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0194\n","Epoch 30/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0197\n","Epoch 31/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0192\n","Epoch 32/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0185\n","Epoch 33/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0211\n","Epoch 34/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0189\n","Epoch 35/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0186\n","Epoch 36/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0201\n","Epoch 37/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0200\n","Epoch 38/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0186\n","Epoch 39/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0186\n","Epoch 40/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0207\n","Epoch 41/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0205\n","Epoch 42/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0219\n","Epoch 43/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0211\n","Epoch 44/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0183\n","Epoch 45/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0181\n","Epoch 46/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0178\n","Epoch 47/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0172\n","Epoch 48/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0204\n","Epoch 49/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0200\n","Epoch 50/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0170\n","Epoch 51/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0159\n","Epoch 52/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0176\n","Epoch 53/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0179\n","Epoch 54/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0167\n","Epoch 55/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0171\n","Epoch 56/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0175\n","Epoch 57/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0193\n","Epoch 58/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0175\n","Epoch 59/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0179\n","Epoch 60/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0180\n","Epoch 61/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0193\n","Epoch 62/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0175\n","Epoch 63/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0174\n","Epoch 64/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0178\n","Epoch 65/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0171\n","Epoch 66/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0200\n","Epoch 67/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0178\n","Epoch 68/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0186\n","Epoch 69/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0157\n","Epoch 70/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0184\n","Epoch 71/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0171\n","Epoch 72/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0191\n","Epoch 73/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0161\n","Epoch 74/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0174\n","Epoch 75/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0160\n","Epoch 76/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0154\n","Epoch 77/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0163\n","Epoch 78/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0169\n","Epoch 79/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0164\n","Epoch 80/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0165\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f8ad662c670>"]},"metadata":{},"execution_count":13}],"source":["model = Sequential()\n","\n","#Adding the first LSTM layer and some Dropout regularisation\n","\n","model.add(LSTM(units = 100, return_sequences = True, input_shape = (X_train.shape[-2:])))\n","\n","model.add(LSTM(100, return_sequences=True))\n","model.add(Dropout(0.4))\n","\n","\n","model.add(LSTM(100, return_sequences=True))\n","model.add(Dropout(0.4))\n","\n","#model.add(RepeatVector(time_step))\n","\n","# Adding a second LSTM layer and some Dropout regularisation\n","\n","model.add(LSTM(units = 100, return_sequences = True))\n","model.add(Dropout(0.4))\n","\n","# Adding a third LSTM layer and some Dropout regularisation\n","\n","model.add(LSTM(units = 60, return_sequences = True))\n","model.add(Dropout(0.4))\n","\n","model.add(LSTM(units = 60, return_sequences = True))\n","model.add(Dropout(0.4))\n","\n","\n","model.add(LSTM(units = 60, return_sequences = True))\n","model.add(Dropout(0.4))\n","\n","# Adding a fourth LSTM layer and some Dropout regularisation\n","\n","model.add(LSTM(units = 60))\n","model.add(Dropout(0.4))\n","\n","\n","# Adding the output layer i \n"," \n","model.add(Dense(units = 1))\n","\n","# Compiling the RNN\n","\n","model.compile(optimizer = 'adam' , loss = 'mean_squared_error' )\n","\n","# Fitting the RNN to the Training set\n","\n","model.fit(X_train, y_train, epochs = 80, batch_size = 32)"]},{"cell_type":"code","execution_count":14,"id":"1a56d4a2","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1a56d4a2","executionInfo":{"status":"ok","timestamp":1669953387317,"user_tz":-540,"elapsed":35,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"e0dec645-7365-4943-9ee2-79e0c393d07e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm (LSTM)                 (None, 30, 100)           50000     \n","                                                                 \n"," lstm_1 (LSTM)               (None, 30, 100)           80400     \n","                                                                 \n"," dropout (Dropout)           (None, 30, 100)           0         \n","                                                                 \n"," lstm_2 (LSTM)               (None, 30, 100)           80400     \n","                                                                 \n"," dropout_1 (Dropout)         (None, 30, 100)           0         \n","                                                                 \n"," lstm_3 (LSTM)               (None, 30, 100)           80400     \n","                                                                 \n"," dropout_2 (Dropout)         (None, 30, 100)           0         \n","                                                                 \n"," lstm_4 (LSTM)               (None, 30, 60)            38640     \n","                                                                 \n"," dropout_3 (Dropout)         (None, 30, 60)            0         \n","                                                                 \n"," lstm_5 (LSTM)               (None, 30, 60)            29040     \n","                                                                 \n"," dropout_4 (Dropout)         (None, 30, 60)            0         \n","                                                                 \n"," lstm_6 (LSTM)               (None, 30, 60)            29040     \n","                                                                 \n"," dropout_5 (Dropout)         (None, 30, 60)            0         \n","                                                                 \n"," lstm_7 (LSTM)               (None, 60)                29040     \n","                                                                 \n"," dropout_6 (Dropout)         (None, 60)                0         \n","                                                                 \n"," dense (Dense)               (None, 1)                 61        \n","                                                                 \n","=================================================================\n","Total params: 417,021\n","Trainable params: 417,021\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"markdown","id":"9573b370","metadata":{"id":"9573b370"},"source":["# 모델이 예상한 값 불러오기"]},{"cell_type":"code","execution_count":15,"id":"068ce98a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"068ce98a","executionInfo":{"status":"ok","timestamp":1669953387318,"user_tz":-540,"elapsed":16,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"bc3feb3e-a2cd-42be-c05b-74a3b155ece4"},"outputs":[{"output_type":"stream","name":"stdout","text":["(763, 30, 24)\n"]}],"source":["dataset_train = feature.iloc[:idx] \n","\n","dataset_test = feature.iloc[idx:]\n","\n","dataset_total = pd.concat((dataset_train, dataset_test), axis = 0)\n","\n","inputs = dataset_total[len(dataset_total) - len(dataset_test) - time_step:].values\n","\n","#inputs = inputs.reshape(-1,n_features)\n","\n","inputs = ss.transform(inputs)\n","\n","X_test = []\n","for i in range(time_step, dataset_test.shape[0]):\n","\n","    X_test.append(inputs[i-time_step:i])\n","\n","X_test = np.array(X_test)\n","\n","X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], X_test.shape[2]))\n","\n","print(X_test.shape)"]},{"cell_type":"code","execution_count":16,"id":"d501d596","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d501d596","executionInfo":{"status":"ok","timestamp":1669953390282,"user_tz":-540,"elapsed":2971,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"3ec424eb-a6c2-4019-e26d-4d2328bcaa0a"},"outputs":[{"output_type":"stream","name":"stdout","text":["24/24 [==============================] - 3s 8ms/step\n"]}],"source":["predicted_stock_price = model.predict(X_test)"]},{"cell_type":"code","execution_count":17,"id":"c1a86e14","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c1a86e14","executionInfo":{"status":"ok","timestamp":1669953390283,"user_tz":-540,"elapsed":34,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"b79a8eb7-d13f-4700-be64-ab002cbcd90e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["763"]},"metadata":{},"execution_count":17}],"source":["X_test.shape[0]"]},{"cell_type":"code","execution_count":18,"id":"e3b635e6","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":483},"id":"e3b635e6","executionInfo":{"status":"ok","timestamp":1669953390284,"user_tz":-540,"elapsed":31,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"6dea082a-6a65-4dd3-f5f3-4a24f39ea4bc"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["      close_log        nvi         pvi        ma_5       ma_10       ma_20  \\\n","0     14.944005   1.163482   3063000.0   3084200.0   3170200.0   3289500.0   \n","1     14.942710   1.163482   3087000.0   3088600.0   3137500.0   3279000.0   \n","2     14.937514   1.157451   3087000.0   3085200.0   3106200.0   3262700.0   \n","3     14.930652   1.157451   3050000.0   3072400.0   3086100.0   3243350.0   \n","4     14.915122   1.139615   3050000.0   3060400.0   3063700.0   3223000.0   \n","...         ...        ...         ...         ...         ...         ...   \n","3957  16.920994  19.407960  22320000.0  22490200.0  22593100.0  22691850.0   \n","3958  16.924705  19.480131  22320000.0  22430800.0  22571300.0  22662550.0   \n","3959  16.951179  19.480131  23004000.0  22496800.0  22612900.0  22660250.0   \n","3960  16.941832  19.298913  23004000.0  22581400.0  22618800.0  22651250.0   \n","3961  16.955213  19.298913  23097000.0  22722800.0  22648600.0  22682950.0   \n","\n","             ma_60        rsi           vpt           obv  ...        mfi  \\\n","0     3.215300e+06  24.735450 -50913.192669  7.758012e+04  ...  53.117928   \n","1     3.216817e+06  25.546448 -50921.710773  7.099776e+04  ...  54.027715   \n","2     3.216783e+06  25.304465 -50942.230512  6.703873e+04  ...  52.648713   \n","3     3.215633e+06  26.044568 -50979.943691  6.152363e+04  ...  53.324172   \n","4     3.214083e+06  25.442177 -51042.834596  5.744241e+04  ...  54.476339   \n","...            ...        ...           ...           ...  ...        ...   \n","3957  2.493500e+07  46.624136   2341.093255  1.475735e+06  ...  53.458386   \n","3958  2.482275e+07  48.006214   2346.997775  1.477323e+06  ...  53.335951   \n","3959  2.472663e+07  51.684312   2391.934249  1.478998e+06  ...  43.927284   \n","3960  2.462907e+07  47.797063   2377.924759  1.477492e+06  ...  45.856043   \n","3961  2.453300e+07  51.084237   2402.135900  1.479290e+06  ...  45.480344   \n","\n","             ema_5        ema_10        ema_20        ema_60            fi  \\\n","0     3.101464e+06  3.154992e+06  3.207830e+06  3.195372e+06 -2.058452e+09   \n","1     3.096642e+06  3.142630e+06  3.196323e+06  3.191819e+06 -2.356487e+09   \n","2     3.088095e+06  3.129606e+06  3.184387e+06  3.187857e+06 -1.445045e+09   \n","3     3.075397e+06  3.115132e+06  3.171588e+06  3.183338e+06 -1.897196e+09   \n","4     3.051264e+06  3.094745e+06  3.155532e+06  3.177425e+06 -1.473320e+09   \n","...            ...           ...           ...           ...           ...   \n","3957  2.245848e+07  2.256368e+07  2.277992e+07  2.431527e+07 -2.116684e+08   \n","3958  2.243999e+07  2.253446e+07  2.274402e+07  2.425257e+07 -1.222620e+08   \n","3959  2.262799e+07  2.261983e+07  2.276878e+07  2.421164e+07  1.172543e+08   \n","3960  2.268200e+07  2.265077e+07  2.277080e+07  2.416503e+07 -1.490895e+08   \n","3961  2.282033e+07  2.273190e+07  2.280187e+07  2.413001e+07  9.345974e+07   \n","\n","               ubb         mbb           lbb       volume  \n","0     3.610062e+06   3289500.0  2.968938e+06  5388.617973  \n","1     3.612042e+06   3279000.0  2.945958e+06  6582.364759  \n","2     3.603251e+06   3262700.0  2.922149e+06  3959.027066  \n","3     3.586173e+06   3243350.0  2.900527e+06  5515.103573  \n","4     3.572426e+06   3223000.0  2.873574e+06  4081.218313  \n","...            ...         ...           ...          ...  \n","3957  2.316037e+07  22691850.0  2.222333e+07  1666.680241  \n","3958  2.312610e+07  22662550.0  2.219900e+07  1587.817986  \n","3959  2.311609e+07  22660250.0  2.220441e+07  1675.061266  \n","3960  2.308805e+07  22651250.0  2.221445e+07  1505.954700  \n","3961  2.315299e+07  22682950.0  2.221291e+07  1797.302637  \n","\n","[3962 rows x 24 columns]"],"text/html":["\n","  <div id=\"df-da62947c-7427-4ccb-8af1-1985594d5700\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>close_log</th>\n","      <th>nvi</th>\n","      <th>pvi</th>\n","      <th>ma_5</th>\n","      <th>ma_10</th>\n","      <th>ma_20</th>\n","      <th>ma_60</th>\n","      <th>rsi</th>\n","      <th>vpt</th>\n","      <th>obv</th>\n","      <th>...</th>\n","      <th>mfi</th>\n","      <th>ema_5</th>\n","      <th>ema_10</th>\n","      <th>ema_20</th>\n","      <th>ema_60</th>\n","      <th>fi</th>\n","      <th>ubb</th>\n","      <th>mbb</th>\n","      <th>lbb</th>\n","      <th>volume</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>14.944005</td>\n","      <td>1.163482</td>\n","      <td>3063000.0</td>\n","      <td>3084200.0</td>\n","      <td>3170200.0</td>\n","      <td>3289500.0</td>\n","      <td>3.215300e+06</td>\n","      <td>24.735450</td>\n","      <td>-50913.192669</td>\n","      <td>7.758012e+04</td>\n","      <td>...</td>\n","      <td>53.117928</td>\n","      <td>3.101464e+06</td>\n","      <td>3.154992e+06</td>\n","      <td>3.207830e+06</td>\n","      <td>3.195372e+06</td>\n","      <td>-2.058452e+09</td>\n","      <td>3.610062e+06</td>\n","      <td>3289500.0</td>\n","      <td>2.968938e+06</td>\n","      <td>5388.617973</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>14.942710</td>\n","      <td>1.163482</td>\n","      <td>3087000.0</td>\n","      <td>3088600.0</td>\n","      <td>3137500.0</td>\n","      <td>3279000.0</td>\n","      <td>3.216817e+06</td>\n","      <td>25.546448</td>\n","      <td>-50921.710773</td>\n","      <td>7.099776e+04</td>\n","      <td>...</td>\n","      <td>54.027715</td>\n","      <td>3.096642e+06</td>\n","      <td>3.142630e+06</td>\n","      <td>3.196323e+06</td>\n","      <td>3.191819e+06</td>\n","      <td>-2.356487e+09</td>\n","      <td>3.612042e+06</td>\n","      <td>3279000.0</td>\n","      <td>2.945958e+06</td>\n","      <td>6582.364759</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>14.937514</td>\n","      <td>1.157451</td>\n","      <td>3087000.0</td>\n","      <td>3085200.0</td>\n","      <td>3106200.0</td>\n","      <td>3262700.0</td>\n","      <td>3.216783e+06</td>\n","      <td>25.304465</td>\n","      <td>-50942.230512</td>\n","      <td>6.703873e+04</td>\n","      <td>...</td>\n","      <td>52.648713</td>\n","      <td>3.088095e+06</td>\n","      <td>3.129606e+06</td>\n","      <td>3.184387e+06</td>\n","      <td>3.187857e+06</td>\n","      <td>-1.445045e+09</td>\n","      <td>3.603251e+06</td>\n","      <td>3262700.0</td>\n","      <td>2.922149e+06</td>\n","      <td>3959.027066</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>14.930652</td>\n","      <td>1.157451</td>\n","      <td>3050000.0</td>\n","      <td>3072400.0</td>\n","      <td>3086100.0</td>\n","      <td>3243350.0</td>\n","      <td>3.215633e+06</td>\n","      <td>26.044568</td>\n","      <td>-50979.943691</td>\n","      <td>6.152363e+04</td>\n","      <td>...</td>\n","      <td>53.324172</td>\n","      <td>3.075397e+06</td>\n","      <td>3.115132e+06</td>\n","      <td>3.171588e+06</td>\n","      <td>3.183338e+06</td>\n","      <td>-1.897196e+09</td>\n","      <td>3.586173e+06</td>\n","      <td>3243350.0</td>\n","      <td>2.900527e+06</td>\n","      <td>5515.103573</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>14.915122</td>\n","      <td>1.139615</td>\n","      <td>3050000.0</td>\n","      <td>3060400.0</td>\n","      <td>3063700.0</td>\n","      <td>3223000.0</td>\n","      <td>3.214083e+06</td>\n","      <td>25.442177</td>\n","      <td>-51042.834596</td>\n","      <td>5.744241e+04</td>\n","      <td>...</td>\n","      <td>54.476339</td>\n","      <td>3.051264e+06</td>\n","      <td>3.094745e+06</td>\n","      <td>3.155532e+06</td>\n","      <td>3.177425e+06</td>\n","      <td>-1.473320e+09</td>\n","      <td>3.572426e+06</td>\n","      <td>3223000.0</td>\n","      <td>2.873574e+06</td>\n","      <td>4081.218313</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>3957</th>\n","      <td>16.920994</td>\n","      <td>19.407960</td>\n","      <td>22320000.0</td>\n","      <td>22490200.0</td>\n","      <td>22593100.0</td>\n","      <td>22691850.0</td>\n","      <td>2.493500e+07</td>\n","      <td>46.624136</td>\n","      <td>2341.093255</td>\n","      <td>1.475735e+06</td>\n","      <td>...</td>\n","      <td>53.458386</td>\n","      <td>2.245848e+07</td>\n","      <td>2.256368e+07</td>\n","      <td>2.277992e+07</td>\n","      <td>2.431527e+07</td>\n","      <td>-2.116684e+08</td>\n","      <td>2.316037e+07</td>\n","      <td>22691850.0</td>\n","      <td>2.222333e+07</td>\n","      <td>1666.680241</td>\n","    </tr>\n","    <tr>\n","      <th>3958</th>\n","      <td>16.924705</td>\n","      <td>19.480131</td>\n","      <td>22320000.0</td>\n","      <td>22430800.0</td>\n","      <td>22571300.0</td>\n","      <td>22662550.0</td>\n","      <td>2.482275e+07</td>\n","      <td>48.006214</td>\n","      <td>2346.997775</td>\n","      <td>1.477323e+06</td>\n","      <td>...</td>\n","      <td>53.335951</td>\n","      <td>2.243999e+07</td>\n","      <td>2.253446e+07</td>\n","      <td>2.274402e+07</td>\n","      <td>2.425257e+07</td>\n","      <td>-1.222620e+08</td>\n","      <td>2.312610e+07</td>\n","      <td>22662550.0</td>\n","      <td>2.219900e+07</td>\n","      <td>1587.817986</td>\n","    </tr>\n","    <tr>\n","      <th>3959</th>\n","      <td>16.951179</td>\n","      <td>19.480131</td>\n","      <td>23004000.0</td>\n","      <td>22496800.0</td>\n","      <td>22612900.0</td>\n","      <td>22660250.0</td>\n","      <td>2.472663e+07</td>\n","      <td>51.684312</td>\n","      <td>2391.934249</td>\n","      <td>1.478998e+06</td>\n","      <td>...</td>\n","      <td>43.927284</td>\n","      <td>2.262799e+07</td>\n","      <td>2.261983e+07</td>\n","      <td>2.276878e+07</td>\n","      <td>2.421164e+07</td>\n","      <td>1.172543e+08</td>\n","      <td>2.311609e+07</td>\n","      <td>22660250.0</td>\n","      <td>2.220441e+07</td>\n","      <td>1675.061266</td>\n","    </tr>\n","    <tr>\n","      <th>3960</th>\n","      <td>16.941832</td>\n","      <td>19.298913</td>\n","      <td>23004000.0</td>\n","      <td>22581400.0</td>\n","      <td>22618800.0</td>\n","      <td>22651250.0</td>\n","      <td>2.462907e+07</td>\n","      <td>47.797063</td>\n","      <td>2377.924759</td>\n","      <td>1.477492e+06</td>\n","      <td>...</td>\n","      <td>45.856043</td>\n","      <td>2.268200e+07</td>\n","      <td>2.265077e+07</td>\n","      <td>2.277080e+07</td>\n","      <td>2.416503e+07</td>\n","      <td>-1.490895e+08</td>\n","      <td>2.308805e+07</td>\n","      <td>22651250.0</td>\n","      <td>2.221445e+07</td>\n","      <td>1505.954700</td>\n","    </tr>\n","    <tr>\n","      <th>3961</th>\n","      <td>16.955213</td>\n","      <td>19.298913</td>\n","      <td>23097000.0</td>\n","      <td>22722800.0</td>\n","      <td>22648600.0</td>\n","      <td>22682950.0</td>\n","      <td>2.453300e+07</td>\n","      <td>51.084237</td>\n","      <td>2402.135900</td>\n","      <td>1.479290e+06</td>\n","      <td>...</td>\n","      <td>45.480344</td>\n","      <td>2.282033e+07</td>\n","      <td>2.273190e+07</td>\n","      <td>2.280187e+07</td>\n","      <td>2.413001e+07</td>\n","      <td>9.345974e+07</td>\n","      <td>2.315299e+07</td>\n","      <td>22682950.0</td>\n","      <td>2.221291e+07</td>\n","      <td>1797.302637</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3962 rows × 24 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-da62947c-7427-4ccb-8af1-1985594d5700')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-da62947c-7427-4ccb-8af1-1985594d5700 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-da62947c-7427-4ccb-8af1-1985594d5700');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":18}],"source":["feature"]},{"cell_type":"markdown","id":"19a7d92d","metadata":{"id":"19a7d92d"},"source":["# 표준화했던 값을 원래 값으로 되돌림"]},{"cell_type":"code","execution_count":19,"id":"d215843a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d215843a","executionInfo":{"status":"ok","timestamp":1669953390284,"user_tz":-540,"elapsed":27,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"096a270f-391f-40c0-c9c2-a7b8b768b2ba"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(763, 1)"]},"metadata":{},"execution_count":19}],"source":["log = feature.iloc[:feature.shape[0]-X_test.shape[0], 0].values\n","data_mean = log.mean(axis=0) \n","data_std = log.std(axis=0)\n","original = (predicted_stock_price)*data_std+data_mean\n","original.shape"]},{"cell_type":"code","execution_count":20,"id":"a17b1190","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a17b1190","executionInfo":{"status":"ok","timestamp":1669953390285,"user_tz":-540,"elapsed":26,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"f9a49b5c-9f46-4210-8370-9e379969c8ad"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["3199"]},"metadata":{},"execution_count":20}],"source":["index = df.shape[0] - original.shape[0]\n","index"]},{"cell_type":"code","execution_count":21,"id":"fd7a4d8e","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fd7a4d8e","executionInfo":{"status":"ok","timestamp":1669953390286,"user_tz":-540,"elapsed":20,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"e14e22d4-343f-4952-fe4c-db1b1a1f1f52"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["2.872630468159154"]},"metadata":{},"execution_count":21}],"source":["y = feature.iloc[feature.shape[0]-X_test.shape[0]:, 1:2].values\n","rmse = np.sqrt(np.mean(((original - y) ** 2)))\n","rmse"]},{"cell_type":"code","execution_count":22,"id":"247bceb7","metadata":{"id":"247bceb7","executionInfo":{"status":"ok","timestamp":1669953390286,"user_tz":-540,"elapsed":13,"user":{"displayName":"구태형","userId":"12113658638621684006"}}},"outputs":[],"source":["def measure_accuarcy(predict, real = dataset_test.values[:,0], n_days=1):\n","    predict_result = []\n","    real_result = []\n","    count = 0\n","    result = 0\n","    correct_up = 0\n","    correct_down = 0\n","    real_up = 0\n","    real_down = 0\n","    \n","    n_predicting_days = predict.shape[0]-n_days\n","    \n","    for i in range(0,n_predicting_days):\n","        if predict[i] > predict[i+n_days]:\n","            result = 1\n","        else:\n","            result = 0\n","        predict_result.append(result)\n","    \n","    for i in range(0,n_predicting_days):\n","        if real[i] > real[i+n_days]:\n","            result = 1\n","        else:\n","            result = 0\n","        real_result.append(result)\n","        \n","    for i in range(0,n_predicting_days):\n","        if real_result[i]==1:\n","            real_up += 1\n","            if predict_result[i] ==1:\n","                correct_up += 1\n","        elif real_result[i]==0:\n","            if predict_result[i] == 0:\n","                correct_down += 1\n","                \n","    count = correct_up + correct_down\n","    \n","    return (count/n_predicting_days,correct_up,correct_down)"]},{"cell_type":"code","execution_count":23,"id":"5fa7acd2","metadata":{"id":"5fa7acd2","executionInfo":{"status":"ok","timestamp":1669953390287,"user_tz":-540,"elapsed":13,"user":{"displayName":"구태형","userId":"12113658638621684006"}}},"outputs":[],"source":["res.append(round(measure_accuarcy(original, n_days = 15)[0]  * 100,2))"]},{"cell_type":"code","execution_count":24,"id":"39180870","metadata":{"id":"39180870","executionInfo":{"status":"ok","timestamp":1669953390287,"user_tz":-540,"elapsed":13,"user":{"displayName":"구태형","userId":"12113658638621684006"}}},"outputs":[],"source":["def measure_diff(predict, real = dataset_test.values[:,0], n_days=1):\n","    \n","    predict_result = []\n","    real_result = []\n","    result = 0\n","    predict_diff = 0\n","    \n","    n_predicting_days = predict.shape[0]-n_days\n","    \n","    for i in range(0,n_predicting_days):\n","        if predict[i] > predict[i+n_days]:\n","            result = 1\n","        else:\n","            result = 0\n","        predict_result.append(result)\n","    \n","    for i in range(0,n_predicting_days):\n","        if real[i] > real[i+n_days]:\n","            result = 1\n","        else:\n","            result = 0\n","        real_result.append(result)\n","        \n","    for i in range(0,n_predicting_days):\n","        if real_result[i]==predict_result[i]:\n","            predict_diff += abs(predict[i]-real[i])\n","        else:\n","            predict_diff -= abs(predict[i]-real[i])\n","    \n","    return predict_diff"]},{"cell_type":"code","execution_count":25,"id":"582943e7","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"582943e7","executionInfo":{"status":"ok","timestamp":1669953390736,"user_tz":-540,"elapsed":9,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"672d2f30-4b1d-465e-9fa4-c324a5df8ccb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([34.39019], dtype=float32)"]},"metadata":{},"execution_count":25}],"source":["measure_diff(original, n_days = 15)"]},{"cell_type":"code","source":["model2 = Sequential()\n","\n","#Adding the first LSTM layer and some Dropout regularisation\n","\n","model2.add(LSTM(units = 100, return_sequences = True, input_shape = (X_train.shape[-2:])))\n","\n","model2.add(LSTM(100, return_sequences=True))\n","model2.add(Dropout(0.8))\n","\n","\n","model2.add(LSTM(100, return_sequences=True))\n","model2.add(Dropout(0.8))\n","\n","#model2.add(RepeatVector(time_step))\n","\n","# Adding a second LSTM layer and some Dropout regularisation\n","\n","model2.add(LSTM(units = 100, return_sequences = True))\n","model2.add(Dropout(0.8))\n","\n","# Adding a third LSTM layer and some Dropout regularisation\n","\n","model2.add(LSTM(units = 60, return_sequences = True))\n","model2.add(Dropout(0.8))\n","\n","model2.add(LSTM(units = 60, return_sequences = True))\n","model2.add(Dropout(0.8))\n","\n","\n","model2.add(LSTM(units = 60, return_sequences = True))\n","model2.add(Dropout(0.8))\n","\n","# Adding a fourth LSTM layer and some Dropout regularisation\n","\n","model2.add(LSTM(units = 60))\n","model2.add(Dropout(0.8))\n","\n","\n","# Adding the output layer i \n"," \n","model2.add(Dense(units = 1))\n","\n","# Compiling the RNN\n","\n","model2.compile(optimizer = 'adam' , loss = 'mean_squared_error' )\n","\n","# Fitting the RNN to the Training set\n","\n","model2.fit(X_train, y_train, epochs = 80, batch_size = 32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vDMdXROao0UC","executionInfo":{"status":"ok","timestamp":1669953564814,"user_tz":-540,"elapsed":174084,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"4ed2e0b2-491d-44d9-841d-27bbccd47b68"},"id":"vDMdXROao0UC","execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/80\n","98/98 [==============================] - 12s 21ms/step - loss: 0.2756\n","Epoch 2/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.1570\n","Epoch 3/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.1358\n","Epoch 4/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.1377\n","Epoch 5/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.1224\n","Epoch 6/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.1088\n","Epoch 7/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.1123\n","Epoch 8/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.1131\n","Epoch 9/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.1048\n","Epoch 10/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.1054\n","Epoch 11/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0982\n","Epoch 12/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.1014\n","Epoch 13/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0965\n","Epoch 14/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.1069\n","Epoch 15/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0928\n","Epoch 16/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0883\n","Epoch 17/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0963\n","Epoch 18/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0935\n","Epoch 19/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0988\n","Epoch 20/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0909\n","Epoch 21/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0949\n","Epoch 22/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0887\n","Epoch 23/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0884\n","Epoch 24/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0946\n","Epoch 25/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0851\n","Epoch 26/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0940\n","Epoch 27/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0916\n","Epoch 28/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0872\n","Epoch 29/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0925\n","Epoch 30/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0833\n","Epoch 31/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0874\n","Epoch 32/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0858\n","Epoch 33/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0862\n","Epoch 34/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0852\n","Epoch 35/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0874\n","Epoch 36/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0852\n","Epoch 37/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0765\n","Epoch 38/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0904\n","Epoch 39/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0885\n","Epoch 40/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0783\n","Epoch 41/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0847\n","Epoch 42/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0842\n","Epoch 43/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0792\n","Epoch 44/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0860\n","Epoch 45/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0815\n","Epoch 46/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0792\n","Epoch 47/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0883\n","Epoch 48/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0844\n","Epoch 49/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0827\n","Epoch 50/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0836\n","Epoch 51/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0834\n","Epoch 52/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0854\n","Epoch 53/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0854\n","Epoch 54/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0901\n","Epoch 55/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0815\n","Epoch 56/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0823\n","Epoch 57/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0765\n","Epoch 58/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0804\n","Epoch 59/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0790\n","Epoch 60/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0810\n","Epoch 61/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0835\n","Epoch 62/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0759\n","Epoch 63/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0845\n","Epoch 64/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0804\n","Epoch 65/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0835\n","Epoch 66/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0796\n","Epoch 67/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0793\n","Epoch 68/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0811\n","Epoch 69/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0804\n","Epoch 70/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0813\n","Epoch 71/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0829\n","Epoch 72/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0757\n","Epoch 73/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0730\n","Epoch 74/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0791\n","Epoch 75/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0795\n","Epoch 76/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0787\n","Epoch 77/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0842\n","Epoch 78/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0819\n","Epoch 79/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0756\n","Epoch 80/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0798\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f8aa3d08370>"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["predicted_stock_price = model2.predict(X_test)\n","log = feature.iloc[:feature.shape[0]-X_test.shape[0], 0].values\n","data_mean = log.mean(axis=0) \n","data_std = log.std(axis=0)\n","original = (predicted_stock_price)*data_std+data_mean\n","\n","y = feature.iloc[feature.shape[0]-X_test.shape[0]:, 1:2].values\n","rmse = np.sqrt(np.mean(((original - y) ** 2)))\n","print(rmse)\n","\n","res.append(round(measure_accuarcy(original, n_days = 15)[0]  * 100,2))\n","print(measure_diff(original, n_days = 15))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ogi_-BlGocGM","executionInfo":{"status":"ok","timestamp":1669953567650,"user_tz":-540,"elapsed":2843,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"c05c2dc6-a7a3-4b63-e298-89757eef2e12"},"id":"ogi_-BlGocGM","execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["24/24 [==============================] - 3s 8ms/step\n","3.0091192785289986\n","[17.634342]\n"]}]},{"cell_type":"code","source":["model3 = Sequential()\n","\n","#Adding the first LSTM layer and some Dropout regularisation\n","\n","model3.add(LSTM(units = 100, return_sequences = True, input_shape = (X_train.shape[-2:])))\n","\n","model3.add(LSTM(100, return_sequences=True))\n","model3.add(Dropout(0.4))\n","\n","\n","model3.add(LSTM(100, return_sequences=True))\n","model3.add(Dropout(0.4))\n","\n","#model3.add(RepeatVector(time_step))\n","\n","# Adding a second LSTM layer and some Dropout regularisation\n","\n","model3.add(LSTM(units = 100, return_sequences = True))\n","model3.add(Dropout(0.4))\n","\n","# Adding a third LSTM layer and some Dropout regularisation\n","\n","model3.add(LSTM(units = 100, return_sequences = True))\n","model3.add(Dropout(0.4))\n","\n","model3.add(LSTM(units = 100, return_sequences = True))\n","model3.add(Dropout(0.4))\n","\n","\n","model3.add(LSTM(units = 100, return_sequences = True))\n","model3.add(Dropout(0.4))\n","\n","# Adding a fourth LSTM layer and some Dropout regularisation\n","\n","model3.add(LSTM(units = 100))\n","model3.add(Dropout(0.4))\n","\n","\n","# Adding the output layer i \n"," \n","model3.add(Dense(units = 1))\n","\n","# Compiling the RNN\n","\n","model3.compile(optimizer = 'adam' , loss = 'mean_squared_error' )\n","\n","# Fitting the RNN to the Training set\n","\n","model3.fit(X_train, y_train, epochs = 80, batch_size = 32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QHT0GA8Jl-2N","executionInfo":{"status":"ok","timestamp":1669953750377,"user_tz":-540,"elapsed":182731,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"ffb275a2-3390-4077-86a2-2b341c256651"},"id":"QHT0GA8Jl-2N","execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/80\n","98/98 [==============================] - 12s 22ms/step - loss: 0.1277\n","Epoch 2/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0499\n","Epoch 3/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0451\n","Epoch 4/80\n","98/98 [==============================] - 2s 23ms/step - loss: 0.0414\n","Epoch 5/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0328\n","Epoch 6/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0360\n","Epoch 7/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0320\n","Epoch 8/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0283\n","Epoch 9/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0293\n","Epoch 10/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0271\n","Epoch 11/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0243\n","Epoch 12/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0241\n","Epoch 13/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0205\n","Epoch 14/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0195\n","Epoch 15/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0218\n","Epoch 16/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0183\n","Epoch 17/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0208\n","Epoch 18/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0215\n","Epoch 19/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0228\n","Epoch 20/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0212\n","Epoch 21/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0199\n","Epoch 22/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0178\n","Epoch 23/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0164\n","Epoch 24/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0164\n","Epoch 25/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0176\n","Epoch 26/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0168\n","Epoch 27/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0195\n","Epoch 28/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0165\n","Epoch 29/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0169\n","Epoch 30/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0181\n","Epoch 31/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0162\n","Epoch 32/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0164\n","Epoch 33/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0151\n","Epoch 34/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0154\n","Epoch 35/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0149\n","Epoch 36/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0153\n","Epoch 37/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0147\n","Epoch 38/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0175\n","Epoch 39/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0137\n","Epoch 40/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0140\n","Epoch 41/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0146\n","Epoch 42/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0146\n","Epoch 43/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0142\n","Epoch 44/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0137\n","Epoch 45/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0148\n","Epoch 46/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0130\n","Epoch 47/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0128\n","Epoch 48/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0137\n","Epoch 49/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0149\n","Epoch 50/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0137\n","Epoch 51/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0140\n","Epoch 52/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0151\n","Epoch 53/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0136\n","Epoch 54/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0142\n","Epoch 55/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0127\n","Epoch 56/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0135\n","Epoch 57/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0139\n","Epoch 58/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0134\n","Epoch 59/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0123\n","Epoch 60/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0118\n","Epoch 61/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0128\n","Epoch 62/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0129\n","Epoch 63/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0133\n","Epoch 64/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0122\n","Epoch 65/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0127\n","Epoch 66/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0118\n","Epoch 67/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0109\n","Epoch 68/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0112\n","Epoch 69/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0112\n","Epoch 70/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0116\n","Epoch 71/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0122\n","Epoch 72/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0142\n","Epoch 73/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0127\n","Epoch 74/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0127\n","Epoch 75/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0128\n","Epoch 76/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0139\n","Epoch 77/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0118\n","Epoch 78/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0126\n","Epoch 79/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0111\n","Epoch 80/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0122\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f8aa38d93d0>"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["predicted_stock_price = model3.predict(X_test)\n","log = feature.iloc[:feature.shape[0]-X_test.shape[0], 0].values\n","data_mean = log.mean(axis=0) \n","data_std = log.std(axis=0)\n","original = (predicted_stock_price)*data_std+data_mean\n","\n","y = feature.iloc[feature.shape[0]-X_test.shape[0]:, 1:2].values\n","rmse = np.sqrt(np.mean(((original - y) ** 2)))\n","print(rmse)\n","\n","res.append(round(measure_accuarcy(original, n_days = 15)[0]  * 100,2))\n","print(measure_diff(original, n_days = 15))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TbwYo0tEpJ1K","executionInfo":{"status":"ok","timestamp":1669953753213,"user_tz":-540,"elapsed":2843,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"91219b57-ce16-488c-be57-8e5a234335d4"},"id":"TbwYo0tEpJ1K","execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["24/24 [==============================] - 3s 9ms/step\n","2.8822293102639898\n","[37.8522]\n"]}]},{"cell_type":"code","source":["model4 = Sequential()\n","\n","#Adding the first LSTM layer and some Dropout regularisation\n","\n","model4.add(LSTM(units = 100, return_sequences = True, input_shape = (X_train.shape[-2:])))\n","\n","model4.add(LSTM(100, return_sequences=True))\n","model4.add(Dropout(0.8))\n","\n","\n","model4.add(LSTM(100, return_sequences=True))\n","model4.add(Dropout(0.8))\n","\n","#model4.add(RepeatVector(time_step))\n","\n","# Adding a second LSTM layer and some Dropout regularisation\n","\n","model4.add(LSTM(units = 100, return_sequences = True))\n","model4.add(Dropout(0.8))\n","\n","# Adding a third LSTM layer and some Dropout regularisation\n","\n","model4.add(LSTM(units = 100, return_sequences = True))\n","model4.add(Dropout(0.8))\n","\n","model4.add(LSTM(units = 100, return_sequences = True))\n","model4.add(Dropout(0.8))\n","\n","\n","model4.add(LSTM(units = 100, return_sequences = True))\n","model4.add(Dropout(0.8))\n","\n","# Adding a fourth LSTM layer and some Dropout regularisation\n","\n","model4.add(LSTM(units = 100))\n","model4.add(Dropout(0.8))\n","\n","\n","# Adding the output layer i \n"," \n","model4.add(Dense(units = 1))\n","\n","# Compiling the RNN\n","\n","model4.compile(optimizer = 'adam' , loss = 'mean_squared_error' )\n","\n","# Fitting the RNN to the Training set\n","\n","model4.fit(X_train, y_train, epochs = 80, batch_size = 32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ctnFEGs9pKuH","executionInfo":{"status":"ok","timestamp":1669953936832,"user_tz":-540,"elapsed":183624,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"09607d65-fc7e-4f53-e190-69dcf55507d8"},"id":"ctnFEGs9pKuH","execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/80\n","98/98 [==============================] - 13s 22ms/step - loss: 0.2386\n","Epoch 2/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.1352\n","Epoch 3/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.1137\n","Epoch 4/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.1084\n","Epoch 5/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0975\n","Epoch 6/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0924\n","Epoch 7/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0933\n","Epoch 8/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0807\n","Epoch 9/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0864\n","Epoch 10/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0848\n","Epoch 11/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0795\n","Epoch 12/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0792\n","Epoch 13/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0768\n","Epoch 14/80\n","98/98 [==============================] - 2s 23ms/step - loss: 0.0703\n","Epoch 15/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0705\n","Epoch 16/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0681\n","Epoch 17/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0738\n","Epoch 18/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0750\n","Epoch 19/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0719\n","Epoch 20/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0657\n","Epoch 21/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0710\n","Epoch 22/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0696\n","Epoch 23/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0687\n","Epoch 24/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0669\n","Epoch 25/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0646\n","Epoch 26/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0637\n","Epoch 27/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0619\n","Epoch 28/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0601\n","Epoch 29/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0615\n","Epoch 30/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0625\n","Epoch 31/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0611\n","Epoch 32/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0618\n","Epoch 33/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0547\n","Epoch 34/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0586\n","Epoch 35/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0630\n","Epoch 36/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0586\n","Epoch 37/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0579\n","Epoch 38/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0625\n","Epoch 39/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0667\n","Epoch 40/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0602\n","Epoch 41/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0601\n","Epoch 42/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0574\n","Epoch 43/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0591\n","Epoch 44/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0621\n","Epoch 45/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0599\n","Epoch 46/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0627\n","Epoch 47/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0619\n","Epoch 48/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0560\n","Epoch 49/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0594\n","Epoch 50/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0602\n","Epoch 51/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0589\n","Epoch 52/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0540\n","Epoch 53/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0544\n","Epoch 54/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0563\n","Epoch 55/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0603\n","Epoch 56/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0584\n","Epoch 57/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0556\n","Epoch 58/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0539\n","Epoch 59/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0521\n","Epoch 60/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0561\n","Epoch 61/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0559\n","Epoch 62/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0547\n","Epoch 63/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0598\n","Epoch 64/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0573\n","Epoch 65/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0550\n","Epoch 66/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0579\n","Epoch 67/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0545\n","Epoch 68/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0543\n","Epoch 69/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0557\n","Epoch 70/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0522\n","Epoch 71/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0532\n","Epoch 72/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0577\n","Epoch 73/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0520\n","Epoch 74/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0544\n","Epoch 75/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0515\n","Epoch 76/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0561\n","Epoch 77/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0524\n","Epoch 78/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0537\n","Epoch 79/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0516\n","Epoch 80/80\n","98/98 [==============================] - 2s 22ms/step - loss: 0.0541\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f8aa3454e20>"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["predicted_stock_price = model4.predict(X_test)\n","log = feature.iloc[:feature.shape[0]-X_test.shape[0], 0].values\n","data_mean = log.mean(axis=0) \n","data_std = log.std(axis=0)\n","original = (predicted_stock_price)*data_std+data_mean\n","\n","y = feature.iloc[feature.shape[0]-X_test.shape[0]:, 1:2].values\n","rmse = np.sqrt(np.mean(((original - y) ** 2)))\n","print(rmse)\n","\n","res.append(round(measure_accuarcy(original, n_days = 15)[0]  * 100,2))\n","print(measure_diff(original, n_days = 15))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jLwhAHLgpMTR","executionInfo":{"status":"ok","timestamp":1669953939215,"user_tz":-540,"elapsed":2401,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"2df92871-17ff-482e-f6f9-a18fa32a3dc9"},"id":"jLwhAHLgpMTR","execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["24/24 [==============================] - 3s 9ms/step\n","2.9827079022698606\n","[42.959095]\n"]}]},{"cell_type":"code","source":["model5 = Sequential()\n","\n","#Adding the first LSTM layer and some Dropout regularisation\n","\n","model5.add(LSTM(units = 100, return_sequences = True, input_shape = (X_train.shape[-2:])))\n","\n","model5.add(LSTM(100, return_sequences=True))\n","model5.add(Dropout(0.4))\n","\n","#model5.add(RepeatVector(time_step))\n","\n","# Adding a second LSTM layer and some Dropout regularisation\n","\n","model5.add(LSTM(units = 100, return_sequences = True))\n","model5.add(Dropout(0.4))\n","\n","# Adding a third LSTM layer and some Dropout regularisation\n","\n","model5.add(LSTM(units = 60, return_sequences = True))\n","model5.add(Dropout(0.4))\n","\n","model5.add(LSTM(units = 60, return_sequences = True))\n","model5.add(Dropout(0.4))\n","\n","# Adding a fourth LSTM layer and some Dropout regularisation\n","\n","model5.add(LSTM(units = 60))\n","model5.add(Dropout(0.4))\n","\n","# Adding the output layer i \n"," \n","model5.add(Dense(units = 1))\n","\n","# Compiling the RNN\n","\n","model5.compile(optimizer = 'adam' , loss = 'mean_squared_error' )\n","\n","# Fitting the RNN to the Training set\n","\n","model5.fit(X_train, y_train, epochs = 80, batch_size = 32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kO6GLkFfpbML","executionInfo":{"status":"ok","timestamp":1669954075452,"user_tz":-540,"elapsed":136246,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"a07fb4cf-fce3-43e8-c87d-1076608a1042"},"id":"kO6GLkFfpbML","execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/80\n","98/98 [==============================] - 10s 16ms/step - loss: 0.1248\n","Epoch 2/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0479\n","Epoch 3/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0460\n","Epoch 4/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0437\n","Epoch 5/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0382\n","Epoch 6/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0363\n","Epoch 7/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0343\n","Epoch 8/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0297\n","Epoch 9/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0305\n","Epoch 10/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0289\n","Epoch 11/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0252\n","Epoch 12/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0286\n","Epoch 13/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0262\n","Epoch 14/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0256\n","Epoch 15/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0240\n","Epoch 16/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0262\n","Epoch 17/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0238\n","Epoch 18/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0236\n","Epoch 19/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0259\n","Epoch 20/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0232\n","Epoch 21/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0213\n","Epoch 22/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0217\n","Epoch 23/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0220\n","Epoch 24/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0207\n","Epoch 25/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0197\n","Epoch 26/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0192\n","Epoch 27/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0190\n","Epoch 28/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0203\n","Epoch 29/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0193\n","Epoch 30/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0197\n","Epoch 31/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0218\n","Epoch 32/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0199\n","Epoch 33/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0192\n","Epoch 34/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0197\n","Epoch 35/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0180\n","Epoch 36/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0185\n","Epoch 37/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0180\n","Epoch 38/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0180\n","Epoch 39/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0206\n","Epoch 40/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0185\n","Epoch 41/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0182\n","Epoch 42/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0168\n","Epoch 43/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0181\n","Epoch 44/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0175\n","Epoch 45/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0166\n","Epoch 46/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0183\n","Epoch 47/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0182\n","Epoch 48/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0177\n","Epoch 49/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0188\n","Epoch 50/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0176\n","Epoch 51/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0173\n","Epoch 52/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0188\n","Epoch 53/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0195\n","Epoch 54/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0195\n","Epoch 55/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0177\n","Epoch 56/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0176\n","Epoch 57/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0164\n","Epoch 58/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0164\n","Epoch 59/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0192\n","Epoch 60/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0181\n","Epoch 61/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0163\n","Epoch 62/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0162\n","Epoch 63/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0156\n","Epoch 64/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0163\n","Epoch 65/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0143\n","Epoch 66/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0170\n","Epoch 67/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0191\n","Epoch 68/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0168\n","Epoch 69/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0167\n","Epoch 70/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0179\n","Epoch 71/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0159\n","Epoch 72/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0161\n","Epoch 73/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0166\n","Epoch 74/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0169\n","Epoch 75/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0178\n","Epoch 76/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0173\n","Epoch 77/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0172\n","Epoch 78/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0162\n","Epoch 79/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0155\n","Epoch 80/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0151\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f8aa32671f0>"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["predicted_stock_price = model5.predict(X_test)\n","log = feature.iloc[:feature.shape[0]-X_test.shape[0], 0].values\n","data_mean = log.mean(axis=0) \n","data_std = log.std(axis=0)\n","original = (predicted_stock_price)*data_std+data_mean\n","\n","y = feature.iloc[feature.shape[0]-X_test.shape[0]:, 1:2].values\n","rmse = np.sqrt(np.mean(((original - y) ** 2)))\n","print(rmse)\n","\n","res.append(round(measure_accuarcy(original, n_days = 15)[0]  * 100,2))\n","print(measure_diff(original, n_days = 15))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wq7tPxaYpOyC","executionInfo":{"status":"ok","timestamp":1669954077115,"user_tz":-540,"elapsed":1676,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"b9e2dc85-a10a-4df8-8914-f55dedd72a8f"},"id":"Wq7tPxaYpOyC","execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["24/24 [==============================] - 2s 7ms/step\n","2.824452723670035\n","[41.51143]\n"]}]},{"cell_type":"code","source":["model6 = Sequential()\n","\n","#Adding the first LSTM layer and some Dropout regularisation\n","\n","model6.add(LSTM(units = 100, return_sequences = True, input_shape = (X_train.shape[-2:])))\n","\n","model6.add(LSTM(100, return_sequences=True))\n","model6.add(Dropout(0.8))\n","\n","#model6.add(RepeatVector(time_step))\n","\n","# Adding a second LSTM layer and some Dropout regularisation\n","\n","model6.add(LSTM(units = 100, return_sequences = True))\n","model6.add(Dropout(0.8))\n","\n","# Adding a third LSTM layer and some Dropout regularisation\n","\n","model6.add(LSTM(units = 60, return_sequences = True))\n","model6.add(Dropout(0.8))\n","\n","model6.add(LSTM(units = 60, return_sequences = True))\n","model6.add(Dropout(0.8))\n","\n","# Adding a fourth LSTM layer and some Dropout regularisation\n","\n","model6.add(LSTM(units = 60))\n","model6.add(Dropout(0.8))\n","\n","# Adding the output layer i \n"," \n","model6.add(Dense(units = 1))\n","\n","# Compiling the RNN\n","\n","model6.compile(optimizer = 'adam' , loss = 'mean_squared_error' )\n","\n","# Fitting the RNN to the Training set\n","\n","model6.fit(X_train, y_train, epochs = 80, batch_size = 32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ns1HZyLBmbye","executionInfo":{"status":"ok","timestamp":1669954212128,"user_tz":-540,"elapsed":135021,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"57a9d86e-be7b-4c5e-d536-3a915fd53afd"},"id":"Ns1HZyLBmbye","execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/80\n","98/98 [==============================] - 9s 16ms/step - loss: 0.2600\n","Epoch 2/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.1473\n","Epoch 3/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.1372\n","Epoch 4/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.1235\n","Epoch 5/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.1086\n","Epoch 6/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.1085\n","Epoch 7/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.1077\n","Epoch 8/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.1101\n","Epoch 9/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.1088\n","Epoch 10/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.1055\n","Epoch 11/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0949\n","Epoch 12/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0926\n","Epoch 13/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0948\n","Epoch 14/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0945\n","Epoch 15/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.1006\n","Epoch 16/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0893\n","Epoch 17/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0858\n","Epoch 18/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0934\n","Epoch 19/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0850\n","Epoch 20/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0923\n","Epoch 21/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0887\n","Epoch 22/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0836\n","Epoch 23/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0811\n","Epoch 24/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0870\n","Epoch 25/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0915\n","Epoch 26/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0890\n","Epoch 27/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0893\n","Epoch 28/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0835\n","Epoch 29/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0837\n","Epoch 30/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0854\n","Epoch 31/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0887\n","Epoch 32/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0838\n","Epoch 33/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0805\n","Epoch 34/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0793\n","Epoch 35/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0864\n","Epoch 36/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0880\n","Epoch 37/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0854\n","Epoch 38/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0831\n","Epoch 39/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0931\n","Epoch 40/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0744\n","Epoch 41/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0816\n","Epoch 42/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0861\n","Epoch 43/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0782\n","Epoch 44/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0847\n","Epoch 45/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0799\n","Epoch 46/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0841\n","Epoch 47/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0893\n","Epoch 48/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0838\n","Epoch 49/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0821\n","Epoch 50/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0760\n","Epoch 51/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0852\n","Epoch 52/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0819\n","Epoch 53/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0825\n","Epoch 54/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0821\n","Epoch 55/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0775\n","Epoch 56/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0763\n","Epoch 57/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0789\n","Epoch 58/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0813\n","Epoch 59/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0811\n","Epoch 60/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0787\n","Epoch 61/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0815\n","Epoch 62/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0802\n","Epoch 63/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0746\n","Epoch 64/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0811\n","Epoch 65/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0826\n","Epoch 66/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0756\n","Epoch 67/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0800\n","Epoch 68/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0761\n","Epoch 69/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0766\n","Epoch 70/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0791\n","Epoch 71/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0781\n","Epoch 72/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0773\n","Epoch 73/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0784\n","Epoch 74/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0731\n","Epoch 75/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0798\n","Epoch 76/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0747\n","Epoch 77/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0776\n","Epoch 78/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0727\n","Epoch 79/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0778\n","Epoch 80/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0793\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f8aa2e8c640>"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["predicted_stock_price = model6.predict(X_test)\n","log = feature.iloc[:feature.shape[0]-X_test.shape[0], 0].values\n","data_mean = log.mean(axis=0) \n","data_std = log.std(axis=0)\n","original = (predicted_stock_price)*data_std+data_mean\n","\n","y = feature.iloc[feature.shape[0]-X_test.shape[0]:, 1:2].values\n","rmse = np.sqrt(np.mean(((original - y) ** 2)))\n","print(rmse)\n","\n","res.append(round(measure_accuarcy(original, n_days = 15)[0]  * 100,2))\n","print(measure_diff(original, n_days = 15))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yATUUjsopQmt","executionInfo":{"status":"ok","timestamp":1669954214119,"user_tz":-540,"elapsed":2002,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"88aa9665-54f8-477d-b42c-c755b91a6240"},"id":"yATUUjsopQmt","execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["24/24 [==============================] - 2s 7ms/step\n","2.9228026100212987\n","[38.034767]\n"]}]},{"cell_type":"code","source":["model7 = Sequential()\n","\n","#Adding the first LSTM layer and some Dropout regularisation\n","\n","model7.add(LSTM(units = 100, return_sequences = True, input_shape = (X_train.shape[-2:])))\n","\n","model7.add(LSTM(100, return_sequences=True))\n","model7.add(Dropout(0.4))\n","\n","#model7.add(RepeatVector(time_step))\n","\n","# Adding a second LSTM layer and some Dropout regularisation\n","\n","model7.add(LSTM(units = 100, return_sequences = True))\n","model7.add(Dropout(0.4))\n","\n","# Adding a third LSTM layer and some Dropout regularisation\n","\n","model7.add(LSTM(units = 100, return_sequences = True))\n","model7.add(Dropout(0.4))\n","\n","model7.add(LSTM(units = 100, return_sequences = True))\n","model7.add(Dropout(0.4))\n","\n","# Adding a fourth LSTM layer and some Dropout regularisation\n","\n","model7.add(LSTM(units = 100))\n","model7.add(Dropout(0.4))\n","\n","# Adding the output layer i \n"," \n","model7.add(Dense(units = 1))\n","\n","# Compiling the RNN\n","\n","model7.compile(optimizer = 'adam' , loss = 'mean_squared_error' )\n","\n","# Fitting the RNN to the Training set\n","\n","model7.fit(X_train, y_train, epochs = 80, batch_size = 32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dL7f0ZjYp2F2","executionInfo":{"status":"ok","timestamp":1669954357032,"user_tz":-540,"elapsed":142919,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"101f1e78-75e9-43f4-94ad-35813753cefd"},"id":"dL7f0ZjYp2F2","execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/80\n","98/98 [==============================] - 10s 17ms/step - loss: 0.0928\n","Epoch 2/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0481\n","Epoch 3/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0405\n","Epoch 4/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0389\n","Epoch 5/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0335\n","Epoch 6/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0314\n","Epoch 7/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0280\n","Epoch 8/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0296\n","Epoch 9/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0265\n","Epoch 10/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0249\n","Epoch 11/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0247\n","Epoch 12/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0238\n","Epoch 13/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0221\n","Epoch 14/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0215\n","Epoch 15/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0227\n","Epoch 16/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0207\n","Epoch 17/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0191\n","Epoch 18/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0202\n","Epoch 19/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0180\n","Epoch 20/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0177\n","Epoch 21/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0181\n","Epoch 22/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0165\n","Epoch 23/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0169\n","Epoch 24/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0175\n","Epoch 25/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0176\n","Epoch 26/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0163\n","Epoch 27/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0158\n","Epoch 28/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0172\n","Epoch 29/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0178\n","Epoch 30/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0164\n","Epoch 31/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0151\n","Epoch 32/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0146\n","Epoch 33/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0170\n","Epoch 34/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0163\n","Epoch 35/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0163\n","Epoch 36/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0163\n","Epoch 37/80\n","98/98 [==============================] - 2s 18ms/step - loss: 0.0146\n","Epoch 38/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0149\n","Epoch 39/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0148\n","Epoch 40/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0141\n","Epoch 41/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0138\n","Epoch 42/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0135\n","Epoch 43/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0168\n","Epoch 44/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0152\n","Epoch 45/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0151\n","Epoch 46/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0149\n","Epoch 47/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0137\n","Epoch 48/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0139\n","Epoch 49/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0118\n","Epoch 50/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0140\n","Epoch 51/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0149\n","Epoch 52/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0117\n","Epoch 53/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0129\n","Epoch 54/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0122\n","Epoch 55/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0121\n","Epoch 56/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0125\n","Epoch 57/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0127\n","Epoch 58/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0116\n","Epoch 59/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0130\n","Epoch 60/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0115\n","Epoch 61/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0141\n","Epoch 62/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0139\n","Epoch 63/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0149\n","Epoch 64/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0140\n","Epoch 65/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0118\n","Epoch 66/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0135\n","Epoch 67/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0125\n","Epoch 68/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0135\n","Epoch 69/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0137\n","Epoch 70/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0116\n","Epoch 71/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0123\n","Epoch 72/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0121\n","Epoch 73/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0113\n","Epoch 74/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0129\n","Epoch 75/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0111\n","Epoch 76/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0120\n","Epoch 77/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0112\n","Epoch 78/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0110\n","Epoch 79/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0114\n","Epoch 80/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0105\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f8aa2be9ee0>"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":["predicted_stock_price = model7.predict(X_test)\n","log = feature.iloc[:feature.shape[0]-X_test.shape[0], 0].values\n","data_mean = log.mean(axis=0) \n","data_std = log.std(axis=0)\n","original = (predicted_stock_price)*data_std+data_mean\n","\n","y = feature.iloc[feature.shape[0]-X_test.shape[0]:, 1:2].values\n","rmse = np.sqrt(np.mean(((original - y) ** 2)))\n","print(rmse)\n","\n","res.append(round(measure_accuarcy(original, n_days = 15)[0]  * 100,2))\n","print(measure_diff(original, n_days = 15))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8md7FX03pTK6","executionInfo":{"status":"ok","timestamp":1669954358986,"user_tz":-540,"elapsed":1964,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"ead2089f-afe7-44d0-d090-b3915775be04"},"id":"8md7FX03pTK6","execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["24/24 [==============================] - 2s 7ms/step\n","2.87541207538877\n","[14.611294]\n"]}]},{"cell_type":"code","source":["model8 = Sequential()\n","\n","#Adding the first LSTM layer and some Dropout regularisation\n","\n","model8.add(LSTM(units = 100, return_sequences = True, input_shape = (X_train.shape[-2:])))\n","\n","model8.add(LSTM(100, return_sequences=True))\n","model8.add(Dropout(0.8))\n","\n","#model8.add(RepeatVector(time_step))\n","\n","# Adding a second LSTM layer and some Dropout regularisation\n","\n","model8.add(LSTM(units = 100, return_sequences = True))\n","model8.add(Dropout(0.8))\n","\n","# Adding a third LSTM layer and some Dropout regularisation\n","\n","model8.add(LSTM(units = 100, return_sequences = True))\n","model8.add(Dropout(0.8))\n","\n","model8.add(LSTM(units = 100, return_sequences = True))\n","model8.add(Dropout(0.8))\n","\n","# Adding a fourth LSTM layer and some Dropout regularisation\n","\n","model8.add(LSTM(units = 100))\n","model8.add(Dropout(0.8))\n","\n","# Adding the output layer i \n"," \n","model8.add(Dense(units = 1))\n","\n","# Compiling the RNN\n","\n","model8.compile(optimizer = 'adam' , loss = 'mean_squared_error' )\n","\n","# Fitting the RNN to the Training set\n","\n","model8.fit(X_train, y_train, epochs = 80, batch_size = 32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UgfuXRWXmwXm","executionInfo":{"status":"ok","timestamp":1669954501545,"user_tz":-540,"elapsed":142564,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"a36855fd-6c5e-47cf-a99c-a7d9be7ce426"},"id":"UgfuXRWXmwXm","execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/80\n","98/98 [==============================] - 9s 17ms/step - loss: 0.2158\n","Epoch 2/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.1210\n","Epoch 3/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.1125\n","Epoch 4/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.1007\n","Epoch 5/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0919\n","Epoch 6/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0893\n","Epoch 7/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0781\n","Epoch 8/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0851\n","Epoch 9/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0751\n","Epoch 10/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0692\n","Epoch 11/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0738\n","Epoch 12/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0784\n","Epoch 13/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0730\n","Epoch 14/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0745\n","Epoch 15/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0695\n","Epoch 16/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0696\n","Epoch 17/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0644\n","Epoch 18/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0712\n","Epoch 19/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0655\n","Epoch 20/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0620\n","Epoch 21/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0656\n","Epoch 22/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0701\n","Epoch 23/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0691\n","Epoch 24/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0644\n","Epoch 25/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0645\n","Epoch 26/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0640\n","Epoch 27/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0582\n","Epoch 28/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0605\n","Epoch 29/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0576\n","Epoch 30/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0612\n","Epoch 31/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0627\n","Epoch 32/80\n","98/98 [==============================] - 2s 18ms/step - loss: 0.0593\n","Epoch 33/80\n","98/98 [==============================] - 2s 18ms/step - loss: 0.0566\n","Epoch 34/80\n","98/98 [==============================] - 2s 18ms/step - loss: 0.0624\n","Epoch 35/80\n","98/98 [==============================] - 2s 18ms/step - loss: 0.0611\n","Epoch 36/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0578\n","Epoch 37/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0646\n","Epoch 38/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0607\n","Epoch 39/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0588\n","Epoch 40/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0619\n","Epoch 41/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0563\n","Epoch 42/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0552\n","Epoch 43/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0593\n","Epoch 44/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0589\n","Epoch 45/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0585\n","Epoch 46/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0597\n","Epoch 47/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0612\n","Epoch 48/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0551\n","Epoch 49/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0581\n","Epoch 50/80\n","98/98 [==============================] - 2s 18ms/step - loss: 0.0536\n","Epoch 51/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0568\n","Epoch 52/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0589\n","Epoch 53/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0544\n","Epoch 54/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0569\n","Epoch 55/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0535\n","Epoch 56/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0566\n","Epoch 57/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0541\n","Epoch 58/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0528\n","Epoch 59/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0572\n","Epoch 60/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0541\n","Epoch 61/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0551\n","Epoch 62/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0547\n","Epoch 63/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0567\n","Epoch 64/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0571\n","Epoch 65/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0618\n","Epoch 66/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0531\n","Epoch 67/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0569\n","Epoch 68/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0515\n","Epoch 69/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0528\n","Epoch 70/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0571\n","Epoch 71/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0559\n","Epoch 72/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0599\n","Epoch 73/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0551\n","Epoch 74/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0564\n","Epoch 75/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0539\n","Epoch 76/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0516\n","Epoch 77/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0529\n","Epoch 78/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0571\n","Epoch 79/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0550\n","Epoch 80/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0528\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f8aa28a6040>"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["predicted_stock_price = model8.predict(X_test)\n","log = feature.iloc[:feature.shape[0]-X_test.shape[0], 0].values\n","data_mean = log.mean(axis=0) \n","data_std = log.std(axis=0)\n","original = (predicted_stock_price)*data_std+data_mean\n","\n","y = feature.iloc[feature.shape[0]-X_test.shape[0]:, 1:2].values\n","rmse = np.sqrt(np.mean(((original - y) ** 2)))\n","print(rmse)\n","\n","res.append(round(measure_accuarcy(original, n_days = 15)[0]  * 100,2))\n","print(measure_diff(original, n_days = 15))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CnmEC4-vpU6e","executionInfo":{"status":"ok","timestamp":1669954503752,"user_tz":-540,"elapsed":2222,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"555eaba0-3da2-4d39-be5f-bd0401e300d5"},"id":"CnmEC4-vpU6e","execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["24/24 [==============================] - 2s 7ms/step\n","2.951158934844124\n","[19.767517]\n"]}]},{"cell_type":"code","source":["model9 = Sequential()\n","\n","#Adding the first LSTM layer and some Dropout regularisation\n","\n","model9.add(LSTM(units = 100, return_sequences = True, input_shape = (X_train.shape[-2:])))\n","\n","model9.add(LSTM(100, return_sequences=True))\n","model9.add(Dropout(0.4))\n","\n","\n","model9.add(LSTM(60, return_sequences=True))\n","model9.add(Dropout(0.4))\n","\n","#model9.add(RepeatVector(time_step))\n","\n","# Adding a second LSTM layer and some Dropout regularisation\n","\n","model9.add(LSTM(60))\n","model9.add(Dropout(0.4))\n","\n","# Adding the output layer i \n"," \n","model9.add(Dense(units = 1))\n","\n","# Compiling the RNN\n","\n","model9.compile(optimizer = 'adam' , loss = 'mean_squared_error' )\n","\n","# Fitting the RNN to the Training set\n","\n","model9.fit(X_train, y_train, epochs = 80, batch_size = 32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lPzXnBr2clj8","executionInfo":{"status":"ok","timestamp":1669954599939,"user_tz":-540,"elapsed":96194,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"34a29dfe-0195-482d-f520-d28a5e2a151a"},"id":"lPzXnBr2clj8","execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/80\n","98/98 [==============================] - 6s 11ms/step - loss: 0.1039\n","Epoch 2/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0474\n","Epoch 3/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0398\n","Epoch 4/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0401\n","Epoch 5/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0350\n","Epoch 6/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0369\n","Epoch 7/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0298\n","Epoch 8/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0285\n","Epoch 9/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0298\n","Epoch 10/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0291\n","Epoch 11/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0277\n","Epoch 12/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0291\n","Epoch 13/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0280\n","Epoch 14/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0250\n","Epoch 15/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0234\n","Epoch 16/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0234\n","Epoch 17/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0219\n","Epoch 18/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0227\n","Epoch 19/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0228\n","Epoch 20/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0224\n","Epoch 21/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0233\n","Epoch 22/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0235\n","Epoch 23/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0226\n","Epoch 24/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0220\n","Epoch 25/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0213\n","Epoch 26/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0219\n","Epoch 27/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0193\n","Epoch 28/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0193\n","Epoch 29/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0206\n","Epoch 30/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0186\n","Epoch 31/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0195\n","Epoch 32/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0206\n","Epoch 33/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0210\n","Epoch 34/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0206\n","Epoch 35/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0178\n","Epoch 36/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0193\n","Epoch 37/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0187\n","Epoch 38/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0180\n","Epoch 39/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0177\n","Epoch 40/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0176\n","Epoch 41/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0164\n","Epoch 42/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0165\n","Epoch 43/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0183\n","Epoch 44/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0169\n","Epoch 45/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0169\n","Epoch 46/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0170\n","Epoch 47/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0191\n","Epoch 48/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0179\n","Epoch 49/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0176\n","Epoch 50/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0203\n","Epoch 51/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0177\n","Epoch 52/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0164\n","Epoch 53/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0172\n","Epoch 54/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0173\n","Epoch 55/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0163\n","Epoch 56/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0166\n","Epoch 57/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0168\n","Epoch 58/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0166\n","Epoch 59/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0164\n","Epoch 60/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0178\n","Epoch 61/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0167\n","Epoch 62/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0162\n","Epoch 63/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0174\n","Epoch 64/80\n","98/98 [==============================] - 1s 13ms/step - loss: 0.0163\n","Epoch 65/80\n","98/98 [==============================] - 1s 13ms/step - loss: 0.0163\n","Epoch 66/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0162\n","Epoch 67/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0151\n","Epoch 68/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0155\n","Epoch 69/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0166\n","Epoch 70/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0170\n","Epoch 71/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0158\n","Epoch 72/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0160\n","Epoch 73/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0169\n","Epoch 74/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0172\n","Epoch 75/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0162\n","Epoch 76/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0146\n","Epoch 77/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0158\n","Epoch 78/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0147\n","Epoch 79/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0162\n","Epoch 80/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0161\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f8aa01dc340>"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["predicted_stock_price = model9.predict(X_test)\n","log = feature.iloc[:feature.shape[0]-X_test.shape[0], 0].values\n","data_mean = log.mean(axis=0) \n","data_std = log.std(axis=0)\n","original = (predicted_stock_price)*data_std+data_mean\n","\n","y = feature.iloc[feature.shape[0]-X_test.shape[0]:, 1:2].values\n","rmse = np.sqrt(np.mean(((original - y) ** 2)))\n","print(rmse)\n","\n","res.append(round(measure_accuarcy(original, n_days = 15)[0]  * 100,2))\n","print(measure_diff(original, n_days = 15))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fk-Km9E1dZUy","executionInfo":{"status":"ok","timestamp":1669954601353,"user_tz":-540,"elapsed":1434,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"514bd947-6641-4cb5-c7aa-62763b3cbbe6"},"id":"fk-Km9E1dZUy","execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["24/24 [==============================] - 1s 5ms/step\n","2.8747133317037052\n","[25.412144]\n"]}]},{"cell_type":"code","source":["model10 = Sequential()\n","\n","#Adding the first LSTM layer and some Dropout regularisation\n","\n","model10.add(LSTM(units = 100, return_sequences = True, input_shape = (X_train.shape[-2:])))\n","\n","model10.add(LSTM(100, return_sequences=True))\n","model10.add(Dropout(0.8))\n","\n","\n","model10.add(LSTM(60, return_sequences=True))\n","model10.add(Dropout(0.8))\n","\n","#model10.add(RepeatVector(time_step))\n","\n","# Adding a second LSTM layer and some Dropout regularisation\n","\n","model10.add(LSTM(60))\n","model10.add(Dropout(0.8))\n","\n","# Adding the output layer i \n"," \n","model10.add(Dense(units = 1))\n","\n","# Compiling the RNN\n","\n","model10.compile(optimizer = 'adam' , loss = 'mean_squared_error' )\n","\n","# Fitting the RNN to the Training set\n","\n","model10.fit(X_train, y_train, epochs = 80, batch_size = 32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SDxJpS9McmUg","executionInfo":{"status":"ok","timestamp":1669954697628,"user_tz":-540,"elapsed":96283,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"c9c82030-ed73-4bd3-cdf2-4b52b0660107"},"id":"SDxJpS9McmUg","execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/80\n","98/98 [==============================] - 7s 11ms/step - loss: 0.2346\n","Epoch 2/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.1410\n","Epoch 3/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.1354\n","Epoch 4/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.1070\n","Epoch 5/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.1123\n","Epoch 6/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.1026\n","Epoch 7/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.1035\n","Epoch 8/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0973\n","Epoch 9/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.1055\n","Epoch 10/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.1019\n","Epoch 11/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0965\n","Epoch 12/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0892\n","Epoch 13/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0942\n","Epoch 14/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0925\n","Epoch 15/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0913\n","Epoch 16/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0894\n","Epoch 17/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0878\n","Epoch 18/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0892\n","Epoch 19/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0983\n","Epoch 20/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0883\n","Epoch 21/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0923\n","Epoch 22/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0829\n","Epoch 23/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0872\n","Epoch 24/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0799\n","Epoch 25/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0872\n","Epoch 26/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0830\n","Epoch 27/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0804\n","Epoch 28/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0832\n","Epoch 29/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0796\n","Epoch 30/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0795\n","Epoch 31/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0769\n","Epoch 32/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0857\n","Epoch 33/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0836\n","Epoch 34/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0786\n","Epoch 35/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0844\n","Epoch 36/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0817\n","Epoch 37/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0836\n","Epoch 38/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0780\n","Epoch 39/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0762\n","Epoch 40/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0805\n","Epoch 41/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0808\n","Epoch 42/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0815\n","Epoch 43/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0822\n","Epoch 44/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0776\n","Epoch 45/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0752\n","Epoch 46/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0848\n","Epoch 47/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0831\n","Epoch 48/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0900\n","Epoch 49/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0801\n","Epoch 50/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0801\n","Epoch 51/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0802\n","Epoch 52/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0782\n","Epoch 53/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0812\n","Epoch 54/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0755\n","Epoch 55/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0825\n","Epoch 56/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0737\n","Epoch 57/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0797\n","Epoch 58/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0773\n","Epoch 59/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0828\n","Epoch 60/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0766\n","Epoch 61/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0749\n","Epoch 62/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0747\n","Epoch 63/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0737\n","Epoch 64/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0745\n","Epoch 65/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0757\n","Epoch 66/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0839\n","Epoch 67/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0803\n","Epoch 68/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0760\n","Epoch 69/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0843\n","Epoch 70/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0741\n","Epoch 71/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0727\n","Epoch 72/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0797\n","Epoch 73/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0749\n","Epoch 74/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0719\n","Epoch 75/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0711\n","Epoch 76/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0746\n","Epoch 77/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0764\n","Epoch 78/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0741\n","Epoch 79/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0816\n","Epoch 80/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0795\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f8a9f0890d0>"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","source":["predicted_stock_price = model10.predict(X_test)\n","log = feature.iloc[:feature.shape[0]-X_test.shape[0], 0].values\n","data_mean = log.mean(axis=0) \n","data_std = log.std(axis=0)\n","original = (predicted_stock_price)*data_std+data_mean\n","\n","y = feature.iloc[feature.shape[0]-X_test.shape[0]:, 1:2].values\n","rmse = np.sqrt(np.mean(((original - y) ** 2)))\n","print(rmse)\n","\n","res.append(round(measure_accuarcy(original, n_days = 15)[0]  * 100,2))\n","print(measure_diff(original, n_days = 15))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jjzwT_IYdbWs","executionInfo":{"status":"ok","timestamp":1669954699160,"user_tz":-540,"elapsed":1539,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"bde694cc-6ea4-4daf-d03b-606895dc024d"},"id":"jjzwT_IYdbWs","execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["24/24 [==============================] - 1s 5ms/step\n","2.9082876088598715\n","[19.69855]\n"]}]},{"cell_type":"code","source":["model11 = Sequential()\n","\n","#Adding the first LSTM layer and some Dropout regularisation\n","\n","model11.add(LSTM(units = 100, return_sequences = True, input_shape = (X_train.shape[-2:])))\n","\n","model11.add(LSTM(100, return_sequences=True))\n","model11.add(Dropout(0.4))\n","\n","\n","model11.add(LSTM(100, return_sequences=True))\n","model11.add(Dropout(0.4))\n","\n","#model11.add(RepeatVector(time_step))\n","\n","# Adding a second LSTM layer and some Dropout regularisation\n","\n","model11.add(LSTM(100))\n","model11.add(Dropout(0.4))\n","\n","# Adding the output layer i \n"," \n","model11.add(Dense(units = 1))\n","\n","# Compiling the RNN\n","\n","model11.compile(optimizer = 'adam' , loss = 'mean_squared_error' )\n","\n","# Fitting the RNN to the Training set\n","\n","model11.fit(X_train, y_train, epochs = 80, batch_size = 32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u179ijuAc1wT","executionInfo":{"status":"ok","timestamp":1669954799621,"user_tz":-540,"elapsed":100466,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"57f71778-7994-4e8e-ad60-b747809d8e71"},"id":"u179ijuAc1wT","execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/80\n","98/98 [==============================] - 6s 12ms/step - loss: 0.0816\n","Epoch 2/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0457\n","Epoch 3/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0407\n","Epoch 4/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0325\n","Epoch 5/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0324\n","Epoch 6/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0285\n","Epoch 7/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0286\n","Epoch 8/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0256\n","Epoch 9/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0266\n","Epoch 10/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0247\n","Epoch 11/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0230\n","Epoch 12/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0227\n","Epoch 13/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0231\n","Epoch 14/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0220\n","Epoch 15/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0207\n","Epoch 16/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0202\n","Epoch 17/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0208\n","Epoch 18/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0188\n","Epoch 19/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0185\n","Epoch 20/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0177\n","Epoch 21/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0189\n","Epoch 22/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0188\n","Epoch 23/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0175\n","Epoch 24/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0161\n","Epoch 25/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0176\n","Epoch 26/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0158\n","Epoch 27/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0157\n","Epoch 28/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0156\n","Epoch 29/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0144\n","Epoch 30/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0135\n","Epoch 31/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0135\n","Epoch 32/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0146\n","Epoch 33/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0144\n","Epoch 34/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0131\n","Epoch 35/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0133\n","Epoch 36/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0156\n","Epoch 37/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0140\n","Epoch 38/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0151\n","Epoch 39/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0139\n","Epoch 40/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0139\n","Epoch 41/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0151\n","Epoch 42/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0138\n","Epoch 43/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0141\n","Epoch 44/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0136\n","Epoch 45/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0153\n","Epoch 46/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0148\n","Epoch 47/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0131\n","Epoch 48/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0133\n","Epoch 49/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0124\n","Epoch 50/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0132\n","Epoch 51/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0128\n","Epoch 52/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0114\n","Epoch 53/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0120\n","Epoch 54/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0130\n","Epoch 55/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0121\n","Epoch 56/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0129\n","Epoch 57/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0119\n","Epoch 58/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0117\n","Epoch 59/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0144\n","Epoch 60/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0151\n","Epoch 61/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0133\n","Epoch 62/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0126\n","Epoch 63/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0120\n","Epoch 64/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0121\n","Epoch 65/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0124\n","Epoch 66/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0135\n","Epoch 67/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0135\n","Epoch 68/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0117\n","Epoch 69/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0113\n","Epoch 70/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0123\n","Epoch 71/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0124\n","Epoch 72/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0110\n","Epoch 73/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0119\n","Epoch 74/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0111\n","Epoch 75/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0124\n","Epoch 76/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0118\n","Epoch 77/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0119\n","Epoch 78/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0117\n","Epoch 79/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0108\n","Epoch 80/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0114\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f8a9c4f74c0>"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["predicted_stock_price = model11.predict(X_test)\n","log = feature.iloc[:feature.shape[0]-X_test.shape[0], 0].values\n","data_mean = log.mean(axis=0) \n","data_std = log.std(axis=0)\n","original = (predicted_stock_price)*data_std+data_mean\n","\n","y = feature.iloc[feature.shape[0]-X_test.shape[0]:, 1:2].values\n","rmse = np.sqrt(np.mean(((original - y) ** 2)))\n","print(rmse)\n","\n","res.append(round(measure_accuarcy(original, n_days = 15)[0]  * 100,2))\n","print(measure_diff(original, n_days = 15))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O7oE3Qjtdi3f","executionInfo":{"status":"ok","timestamp":1669954801050,"user_tz":-540,"elapsed":1436,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"aab5bb9e-7a29-4b57-d317-72a17e0fe179"},"id":"O7oE3Qjtdi3f","execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["24/24 [==============================] - 1s 5ms/step\n","2.920896742539834\n","[33.73442]\n"]}]},{"cell_type":"code","source":["model12 = Sequential()\n","\n","#Adding the first LSTM layer and some Dropout regularisation\n","\n","model12.add(LSTM(units = 100, return_sequences = True, input_shape = (X_train.shape[-2:])))\n","\n","model12.add(LSTM(100, return_sequences=True))\n","model12.add(Dropout(0.8))\n","\n","\n","model12.add(LSTM(100, return_sequences=True))\n","model12.add(Dropout(0.8))\n","\n","#model12.add(RepeatVector(time_step))\n","\n","# Adding a second LSTM layer and some Dropout regularisation\n","\n","model12.add(LSTM(100))\n","model12.add(Dropout(0.8))\n","\n","# Adding the output layer i \n"," \n","model12.add(Dense(units = 1))\n","\n","# Compiling the RNN\n","\n","model12.compile(optimizer = 'adam' , loss = 'mean_squared_error' )\n","\n","# Fitting the RNN to the Training set\n","\n","model12.fit(X_train, y_train, epochs = 80, batch_size = 32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iT6kPIuRcshm","executionInfo":{"status":"ok","timestamp":1669954900280,"user_tz":-540,"elapsed":99235,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"f23a4a01-8b0e-4cfb-e0ca-f1d21e9d5649"},"id":"iT6kPIuRcshm","execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/80\n","98/98 [==============================] - 6s 12ms/step - loss: 0.2071\n","Epoch 2/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.1150\n","Epoch 3/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.1025\n","Epoch 4/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0833\n","Epoch 5/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0784\n","Epoch 6/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0861\n","Epoch 7/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0797\n","Epoch 8/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0703\n","Epoch 9/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0738\n","Epoch 10/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0729\n","Epoch 11/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0756\n","Epoch 12/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0774\n","Epoch 13/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0719\n","Epoch 14/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0629\n","Epoch 15/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0659\n","Epoch 16/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0677\n","Epoch 17/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0665\n","Epoch 18/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0613\n","Epoch 19/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0638\n","Epoch 20/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0649\n","Epoch 21/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0566\n","Epoch 22/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0655\n","Epoch 23/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0627\n","Epoch 24/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0650\n","Epoch 25/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0647\n","Epoch 26/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0586\n","Epoch 27/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0630\n","Epoch 28/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0591\n","Epoch 29/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0578\n","Epoch 30/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0588\n","Epoch 31/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0612\n","Epoch 32/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0584\n","Epoch 33/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0589\n","Epoch 34/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0607\n","Epoch 35/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0615\n","Epoch 36/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0604\n","Epoch 37/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0549\n","Epoch 38/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0569\n","Epoch 39/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0654\n","Epoch 40/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0555\n","Epoch 41/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0574\n","Epoch 42/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0601\n","Epoch 43/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0548\n","Epoch 44/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0555\n","Epoch 45/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0568\n","Epoch 46/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0566\n","Epoch 47/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0582\n","Epoch 48/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0586\n","Epoch 49/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0559\n","Epoch 50/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0586\n","Epoch 51/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0525\n","Epoch 52/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0535\n","Epoch 53/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0540\n","Epoch 54/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0529\n","Epoch 55/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0545\n","Epoch 56/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0533\n","Epoch 57/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0550\n","Epoch 58/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0538\n","Epoch 59/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0546\n","Epoch 60/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0532\n","Epoch 61/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0577\n","Epoch 62/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0531\n","Epoch 63/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0555\n","Epoch 64/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0502\n","Epoch 65/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0522\n","Epoch 66/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0507\n","Epoch 67/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0519\n","Epoch 68/80\n","98/98 [==============================] - 1s 13ms/step - loss: 0.0509\n","Epoch 69/80\n","98/98 [==============================] - 1s 13ms/step - loss: 0.0489\n","Epoch 70/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0515\n","Epoch 71/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0532\n","Epoch 72/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0504\n","Epoch 73/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0541\n","Epoch 74/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0572\n","Epoch 75/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0578\n","Epoch 76/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0532\n","Epoch 77/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0499\n","Epoch 78/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0556\n","Epoch 79/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0556\n","Epoch 80/80\n","98/98 [==============================] - 1s 12ms/step - loss: 0.0544\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f8a3768ffa0>"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","source":["predicted_stock_price = model12.predict(X_test)\n","log = feature.iloc[:feature.shape[0]-X_test.shape[0], 0].values\n","data_mean = log.mean(axis=0) \n","data_std = log.std(axis=0)\n","original = (predicted_stock_price)*data_std+data_mean\n","\n","y = feature.iloc[feature.shape[0]-X_test.shape[0]:, 1:2].values\n","rmse = np.sqrt(np.mean(((original - y) ** 2)))\n","print(rmse)\n","\n","res.append(round(measure_accuarcy(original, n_days = 15)[0]  * 100,2))\n","print(measure_diff(original, n_days = 15))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yIb42DNWdkbO","executionInfo":{"status":"ok","timestamp":1669954901328,"user_tz":-540,"elapsed":1056,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"a64282e8-3f31-4ece-ccc8-d88575fddce9"},"id":"yIb42DNWdkbO","execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["24/24 [==============================] - 1s 5ms/step\n","2.9447715184333645\n","[25.684278]\n"]}]},{"cell_type":"code","source":["model13 = Sequential()\n","\n","#Adding the first LSTM layer and some Dropout regularisation\n","\n","model13.add(LSTM(units = 100, return_sequences = True, input_shape = (X_train.shape[-2:])))\n","\n","model13.add(LSTM(60))\n","model13.add(Dropout(0.4))\n","\n","\n","# Adding the output layer i \n"," \n","model13.add(Dense(units = 1))\n","\n","# Compiling the RNN\n","\n","model13.compile(optimizer = 'adam' , loss = 'mean_squared_error' )\n","\n","# Fitting the RNN to the Training set\n","\n","model13.fit(X_train, y_train, epochs = 80, batch_size = 32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3vlFzB8Oc8Cm","executionInfo":{"status":"ok","timestamp":1669954956080,"user_tz":-540,"elapsed":54756,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"d11ca1e9-1460-4f3d-b878-370a640496e7"},"id":"3vlFzB8Oc8Cm","execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/80\n","98/98 [==============================] - 3s 7ms/step - loss: 0.0875\n","Epoch 2/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0397\n","Epoch 3/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0364\n","Epoch 4/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0332\n","Epoch 5/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0313\n","Epoch 6/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0302\n","Epoch 7/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0288\n","Epoch 8/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0275\n","Epoch 9/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0277\n","Epoch 10/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0253\n","Epoch 11/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0236\n","Epoch 12/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0239\n","Epoch 13/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0265\n","Epoch 14/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0229\n","Epoch 15/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0219\n","Epoch 16/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0227\n","Epoch 17/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0229\n","Epoch 18/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0223\n","Epoch 19/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0204\n","Epoch 20/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0205\n","Epoch 21/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0195\n","Epoch 22/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0195\n","Epoch 23/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0182\n","Epoch 24/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0194\n","Epoch 25/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0197\n","Epoch 26/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0195\n","Epoch 27/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0192\n","Epoch 28/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0193\n","Epoch 29/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0178\n","Epoch 30/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0179\n","Epoch 31/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0189\n","Epoch 32/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0185\n","Epoch 33/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0174\n","Epoch 34/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0158\n","Epoch 35/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0171\n","Epoch 36/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0168\n","Epoch 37/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0180\n","Epoch 38/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0178\n","Epoch 39/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0165\n","Epoch 40/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0180\n","Epoch 41/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0174\n","Epoch 42/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0177\n","Epoch 43/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0167\n","Epoch 44/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0171\n","Epoch 45/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0167\n","Epoch 46/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0164\n","Epoch 47/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0169\n","Epoch 48/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0157\n","Epoch 49/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0173\n","Epoch 50/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0167\n","Epoch 51/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0160\n","Epoch 52/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0183\n","Epoch 53/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0164\n","Epoch 54/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0164\n","Epoch 55/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0168\n","Epoch 56/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0159\n","Epoch 57/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0169\n","Epoch 58/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0151\n","Epoch 59/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0179\n","Epoch 60/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0177\n","Epoch 61/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0165\n","Epoch 62/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0150\n","Epoch 63/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0155\n","Epoch 64/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0176\n","Epoch 65/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0157\n","Epoch 66/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0151\n","Epoch 67/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0154\n","Epoch 68/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0152\n","Epoch 69/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0165\n","Epoch 70/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0166\n","Epoch 71/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0164\n","Epoch 72/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0160\n","Epoch 73/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0166\n","Epoch 74/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0159\n","Epoch 75/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0154\n","Epoch 76/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0158\n","Epoch 77/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0148\n","Epoch 78/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0162\n","Epoch 79/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0154\n","Epoch 80/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0153\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f8a357b3610>"]},"metadata":{},"execution_count":48}]},{"cell_type":"code","source":["predicted_stock_price = model13.predict(X_test)\n","log = feature.iloc[:feature.shape[0]-X_test.shape[0], 0].values\n","data_mean = log.mean(axis=0) \n","data_std = log.std(axis=0)\n","original = (predicted_stock_price)*data_std+data_mean\n","\n","y = feature.iloc[feature.shape[0]-X_test.shape[0]:, 1:2].values\n","rmse = np.sqrt(np.mean(((original - y) ** 2)))\n","print(rmse)\n","\n","res.append(round(measure_accuarcy(original, n_days = 15)[0]  * 100,2))\n","print(measure_diff(original, n_days = 15))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uk4N1TOjdmQO","executionInfo":{"status":"ok","timestamp":1669954956520,"user_tz":-540,"elapsed":447,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"87342189-f3cd-47f7-c1ec-924119165c7c"},"id":"uk4N1TOjdmQO","execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["24/24 [==============================] - 1s 3ms/step\n","2.888144232218392\n","[53.619232]\n"]}]},{"cell_type":"code","source":["model14 = Sequential()\n","\n","#Adding the first LSTM layer and some Dropout regularisation\n","\n","model14.add(LSTM(units = 100, return_sequences = True, input_shape = (X_train.shape[-2:])))\n","\n","model14.add(LSTM(60))\n","model14.add(Dropout(0.8))\n","\n","\n","# Adding the output layer i \n"," \n","model14.add(Dense(units = 1))\n","\n","# Compiling the RNN\n","\n","model14.compile(optimizer = 'adam' , loss = 'mean_squared_error' )\n","\n","# Fitting the RNN to the Training set\n","\n","model14.fit(X_train, y_train, epochs = 80, batch_size = 32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ALdITVcrdMVP","executionInfo":{"status":"ok","timestamp":1669955011284,"user_tz":-540,"elapsed":54767,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"8f27df51-0713-48f2-8f1e-d425161b9325"},"id":"ALdITVcrdMVP","execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/80\n","98/98 [==============================] - 3s 7ms/step - loss: 0.2107\n","Epoch 2/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1175\n","Epoch 3/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.1024\n","Epoch 4/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1036\n","Epoch 5/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0934\n","Epoch 6/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0904\n","Epoch 7/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0946\n","Epoch 8/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0916\n","Epoch 9/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0880\n","Epoch 10/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0852\n","Epoch 11/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0886\n","Epoch 12/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0826\n","Epoch 13/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0822\n","Epoch 14/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0837\n","Epoch 15/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0801\n","Epoch 16/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0926\n","Epoch 17/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0860\n","Epoch 18/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0788\n","Epoch 19/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0886\n","Epoch 20/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0790\n","Epoch 21/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0763\n","Epoch 22/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0776\n","Epoch 23/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0823\n","Epoch 24/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0789\n","Epoch 25/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0784\n","Epoch 26/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0776\n","Epoch 27/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0732\n","Epoch 28/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0773\n","Epoch 29/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0759\n","Epoch 30/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0757\n","Epoch 31/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0724\n","Epoch 32/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0798\n","Epoch 33/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0798\n","Epoch 34/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0747\n","Epoch 35/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0787\n","Epoch 36/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0734\n","Epoch 37/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0760\n","Epoch 38/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0799\n","Epoch 39/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0774\n","Epoch 40/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0760\n","Epoch 41/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0756\n","Epoch 42/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0742\n","Epoch 43/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0786\n","Epoch 44/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0777\n","Epoch 45/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0772\n","Epoch 46/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0724\n","Epoch 47/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0728\n","Epoch 48/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0695\n","Epoch 49/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0779\n","Epoch 50/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0735\n","Epoch 51/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0717\n","Epoch 52/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0761\n","Epoch 53/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0778\n","Epoch 54/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0740\n","Epoch 55/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0663\n","Epoch 56/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0729\n","Epoch 57/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0730\n","Epoch 58/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0739\n","Epoch 59/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0775\n","Epoch 60/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0808\n","Epoch 61/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0705\n","Epoch 62/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0740\n","Epoch 63/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0681\n","Epoch 64/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0693\n","Epoch 65/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0712\n","Epoch 66/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0711\n","Epoch 67/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0743\n","Epoch 68/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0704\n","Epoch 69/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0688\n","Epoch 70/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0722\n","Epoch 71/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0745\n","Epoch 72/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0692\n","Epoch 73/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0664\n","Epoch 74/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0727\n","Epoch 75/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0687\n","Epoch 76/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0725\n","Epoch 77/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0713\n","Epoch 78/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0705\n","Epoch 79/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0694\n","Epoch 80/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0703\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f8a31eea490>"]},"metadata":{},"execution_count":50}]},{"cell_type":"code","source":["predicted_stock_price = model14.predict(X_test)\n","log = feature.iloc[:feature.shape[0]-X_test.shape[0], 0].values\n","data_mean = log.mean(axis=0) \n","data_std = log.std(axis=0)\n","original = (predicted_stock_price)*data_std+data_mean\n","\n","y = feature.iloc[feature.shape[0]-X_test.shape[0]:, 1:2].values\n","rmse = np.sqrt(np.mean(((original - y) ** 2)))\n","print(rmse)\n","\n","res.append(round(measure_accuarcy(original, n_days = 15)[0]  * 100,2))\n","print(measure_diff(original, n_days = 15))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"suNhl98wdnv8","executionInfo":{"status":"ok","timestamp":1669955011886,"user_tz":-540,"elapsed":612,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"3c902a39-1210-4ffa-bbf7-881840193574"},"id":"suNhl98wdnv8","execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["24/24 [==============================] - 1s 3ms/step\n","2.966072589624404\n","[20.362581]\n"]}]},{"cell_type":"code","source":["model15 = Sequential()\n","\n","#Adding the first LSTM layer and some Dropout regularisation\n","\n","model15.add(LSTM(units = 100, return_sequences = True, input_shape = (X_train.shape[-2:])))\n","\n","model15.add(LSTM(100))\n","model15.add(Dropout(0.4))\n","\n","\n","# Adding the output layer i \n"," \n","model15.add(Dense(units = 1))\n","\n","# Compiling the RNN\n","\n","model15.compile(optimizer = 'adam' , loss = 'mean_squared_error' )\n","\n","# Fitting the RNN to the Training set\n","\n","model15.fit(X_train, y_train, epochs = 80, batch_size = 32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RV8SyzYxdSGc","executionInfo":{"status":"ok","timestamp":1669955068335,"user_tz":-540,"elapsed":56451,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"dd5c89ee-ffca-490b-f643-4895f26d2182"},"id":"RV8SyzYxdSGc","execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/80\n","98/98 [==============================] - 4s 7ms/step - loss: 0.0829\n","Epoch 2/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0380\n","Epoch 3/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0316\n","Epoch 4/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0298\n","Epoch 5/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0267\n","Epoch 6/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0263\n","Epoch 7/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0244\n","Epoch 8/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0233\n","Epoch 9/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0223\n","Epoch 10/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0245\n","Epoch 11/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0224\n","Epoch 12/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0198\n","Epoch 13/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0196\n","Epoch 14/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0191\n","Epoch 15/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0200\n","Epoch 16/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0189\n","Epoch 17/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0187\n","Epoch 18/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0167\n","Epoch 19/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0177\n","Epoch 20/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0171\n","Epoch 21/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0176\n","Epoch 22/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0146\n","Epoch 23/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0172\n","Epoch 24/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0154\n","Epoch 25/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0156\n","Epoch 26/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0150\n","Epoch 27/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0149\n","Epoch 28/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0152\n","Epoch 29/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0141\n","Epoch 30/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0145\n","Epoch 31/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0135\n","Epoch 32/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0140\n","Epoch 33/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0132\n","Epoch 34/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0154\n","Epoch 35/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0136\n","Epoch 36/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0120\n","Epoch 37/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0132\n","Epoch 38/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0134\n","Epoch 39/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0133\n","Epoch 40/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0116\n","Epoch 41/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0119\n","Epoch 42/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0136\n","Epoch 43/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0143\n","Epoch 44/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0119\n","Epoch 45/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0121\n","Epoch 46/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0116\n","Epoch 47/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0119\n","Epoch 48/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0119\n","Epoch 49/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0115\n","Epoch 50/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0112\n","Epoch 51/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0112\n","Epoch 52/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0116\n","Epoch 53/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0122\n","Epoch 54/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0126\n","Epoch 55/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0119\n","Epoch 56/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0114\n","Epoch 57/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0118\n","Epoch 58/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0110\n","Epoch 59/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0113\n","Epoch 60/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0110\n","Epoch 61/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0116\n","Epoch 62/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0107\n","Epoch 63/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0105\n","Epoch 64/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0115\n","Epoch 65/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0112\n","Epoch 66/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0110\n","Epoch 67/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0110\n","Epoch 68/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0111\n","Epoch 69/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0105\n","Epoch 70/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0103\n","Epoch 71/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0114\n","Epoch 72/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0096\n","Epoch 73/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0107\n","Epoch 74/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0106\n","Epoch 75/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0111\n","Epoch 76/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0104\n","Epoch 77/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0107\n","Epoch 78/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0119\n","Epoch 79/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0110\n","Epoch 80/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0104\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f8a301da6a0>"]},"metadata":{},"execution_count":52}]},{"cell_type":"code","source":["predicted_stock_price = model15.predict(X_test)\n","log = feature.iloc[:feature.shape[0]-X_test.shape[0], 0].values\n","data_mean = log.mean(axis=0) \n","data_std = log.std(axis=0)\n","original = (predicted_stock_price)*data_std+data_mean\n","\n","y = feature.iloc[feature.shape[0]-X_test.shape[0]:, 1:2].values\n","rmse = np.sqrt(np.mean(((original - y) ** 2)))\n","print(rmse)\n","\n","res.append(round(measure_accuarcy(original, n_days = 15)[0]  * 100,2))\n","print(measure_diff(original, n_days = 15))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l4ug1q37dpIC","executionInfo":{"status":"ok","timestamp":1669955068775,"user_tz":-540,"elapsed":466,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"46383923-11b9-43ce-dc33-a5d1b04bd0f0"},"id":"l4ug1q37dpIC","execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["24/24 [==============================] - 1s 3ms/step\n","2.8679730079821377\n","[47.919365]\n"]}]},{"cell_type":"code","source":["model16 = Sequential()\n","\n","#Adding the first LSTM layer and some Dropout regularisation\n","\n","model16.add(LSTM(units = 100, return_sequences = True, input_shape = (X_train.shape[-2:])))\n","\n","model16.add(LSTM(100))\n","model16.add(Dropout(0.8))\n","\n","\n","# Adding the output layer i \n"," \n","model16.add(Dense(units = 1))\n","\n","# Compiling the RNN\n","\n","model16.compile(optimizer = 'adam' , loss = 'mean_squared_error' )\n","\n","# Fitting the RNN to the Training set\n","\n","model16.fit(X_train, y_train, epochs = 80, batch_size = 32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"chzqNpYmdReT","executionInfo":{"status":"ok","timestamp":1669955124143,"user_tz":-540,"elapsed":55373,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"bba5e2bc-2457-4829-bf51-555fcb3d2758"},"id":"chzqNpYmdReT","execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/80\n","98/98 [==============================] - 3s 7ms/step - loss: 0.1757\n","Epoch 2/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0907\n","Epoch 3/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0809\n","Epoch 4/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0753\n","Epoch 5/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0744\n","Epoch 6/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0745\n","Epoch 7/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0680\n","Epoch 8/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0678\n","Epoch 9/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0659\n","Epoch 10/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0647\n","Epoch 11/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0669\n","Epoch 12/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0641\n","Epoch 13/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0580\n","Epoch 14/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0609\n","Epoch 15/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0619\n","Epoch 16/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0577\n","Epoch 17/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0630\n","Epoch 18/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0594\n","Epoch 19/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0585\n","Epoch 20/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0561\n","Epoch 21/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0546\n","Epoch 22/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0550\n","Epoch 23/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0578\n","Epoch 24/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0546\n","Epoch 25/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0545\n","Epoch 26/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0535\n","Epoch 27/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0557\n","Epoch 28/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0566\n","Epoch 29/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0535\n","Epoch 30/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0547\n","Epoch 31/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0535\n","Epoch 32/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0500\n","Epoch 33/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0545\n","Epoch 34/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0506\n","Epoch 35/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0516\n","Epoch 36/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0532\n","Epoch 37/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0519\n","Epoch 38/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0479\n","Epoch 39/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0490\n","Epoch 40/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0493\n","Epoch 41/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0495\n","Epoch 42/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0504\n","Epoch 43/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0517\n","Epoch 44/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0488\n","Epoch 45/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0522\n","Epoch 46/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0509\n","Epoch 47/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0507\n","Epoch 48/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0480\n","Epoch 49/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0490\n","Epoch 50/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0486\n","Epoch 51/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0490\n","Epoch 52/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0508\n","Epoch 53/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0495\n","Epoch 54/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0505\n","Epoch 55/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0485\n","Epoch 56/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0504\n","Epoch 57/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0482\n","Epoch 58/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0483\n","Epoch 59/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0461\n","Epoch 60/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0487\n","Epoch 61/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0439\n","Epoch 62/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0485\n","Epoch 63/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0467\n","Epoch 64/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0490\n","Epoch 65/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0478\n","Epoch 66/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0493\n","Epoch 67/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0526\n","Epoch 68/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0496\n","Epoch 69/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0479\n","Epoch 70/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0455\n","Epoch 71/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0467\n","Epoch 72/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0452\n","Epoch 73/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0441\n","Epoch 74/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0465\n","Epoch 75/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0462\n","Epoch 76/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0469\n","Epoch 77/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0460\n","Epoch 78/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0499\n","Epoch 79/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0504\n","Epoch 80/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0482\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f8a375c1820>"]},"metadata":{},"execution_count":54}]},{"cell_type":"code","source":["predicted_stock_price = model16.predict(X_test)\n","log = feature.iloc[:feature.shape[0]-X_test.shape[0], 0].values\n","data_mean = log.mean(axis=0) \n","data_std = log.std(axis=0)\n","original = (predicted_stock_price)*data_std+data_mean\n","\n","y = feature.iloc[feature.shape[0]-X_test.shape[0]:, 1:2].values\n","rmse = np.sqrt(np.mean(((original - y) ** 2)))\n","print(rmse)\n","\n","res.append(round(measure_accuarcy(original, n_days = 15)[0]  * 100,2))\n","print(measure_diff(original, n_days = 15))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nT-fDrD0dqx5","executionInfo":{"status":"ok","timestamp":1669955124614,"user_tz":-540,"elapsed":477,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"f94acb18-308a-428f-9f60-079248da69e5"},"id":"nT-fDrD0dqx5","execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["24/24 [==============================] - 1s 3ms/step\n","2.9111831912646795\n","[50.94186]\n"]}]},{"cell_type":"code","source":["model17 = Sequential()\n","\n","#Adding the first LSTM layer and some Dropout regularisation\n","\n","model17.add(LSTM(units = 60, return_sequences = True, input_shape = (X_train.shape[-2:])))\n","\n","model17.add(LSTM(60))\n","model17.add(Dropout(0.8))\n","\n","\n","# Adding the output layer i \n"," \n","model17.add(Dense(units = 1))\n","\n","# Compiling the RNN\n","\n","model17.compile(optimizer = 'adam' , loss = 'mean_squared_error' )\n","\n","# Fitting the RNN to the Training set\n","\n","model17.fit(X_train, y_train, epochs = 80, batch_size = 32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v4uEh0rCg5pP","executionInfo":{"status":"ok","timestamp":1669955177484,"user_tz":-540,"elapsed":52872,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"26ece0cf-2874-4e11-bc4e-96064787248a"},"id":"v4uEh0rCg5pP","execution_count":56,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/80\n","98/98 [==============================] - 3s 6ms/step - loss: 0.2146\n","Epoch 2/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1122\n","Epoch 3/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1006\n","Epoch 4/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0928\n","Epoch 5/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0988\n","Epoch 6/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0960\n","Epoch 7/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0889\n","Epoch 8/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0854\n","Epoch 9/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0900\n","Epoch 10/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0934\n","Epoch 11/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0884\n","Epoch 12/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0899\n","Epoch 13/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0889\n","Epoch 14/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0822\n","Epoch 15/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0822\n","Epoch 16/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0864\n","Epoch 17/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0807\n","Epoch 18/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0774\n","Epoch 19/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0798\n","Epoch 20/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0811\n","Epoch 21/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0802\n","Epoch 22/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0824\n","Epoch 23/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0784\n","Epoch 24/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0772\n","Epoch 25/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0753\n","Epoch 26/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0778\n","Epoch 27/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0829\n","Epoch 28/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0783\n","Epoch 29/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0775\n","Epoch 30/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0783\n","Epoch 31/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0774\n","Epoch 32/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0838\n","Epoch 33/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0759\n","Epoch 34/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0741\n","Epoch 35/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0745\n","Epoch 36/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0771\n","Epoch 37/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0794\n","Epoch 38/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0793\n","Epoch 39/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0765\n","Epoch 40/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0764\n","Epoch 41/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0765\n","Epoch 42/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0795\n","Epoch 43/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0760\n","Epoch 44/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0721\n","Epoch 45/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0734\n","Epoch 46/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0728\n","Epoch 47/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0732\n","Epoch 48/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0742\n","Epoch 49/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0772\n","Epoch 50/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0727\n","Epoch 51/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0685\n","Epoch 52/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0737\n","Epoch 53/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0728\n","Epoch 54/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0702\n","Epoch 55/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0739\n","Epoch 56/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0729\n","Epoch 57/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0803\n","Epoch 58/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0686\n","Epoch 59/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0693\n","Epoch 60/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0770\n","Epoch 61/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0716\n","Epoch 62/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0709\n","Epoch 63/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0767\n","Epoch 64/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0710\n","Epoch 65/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0754\n","Epoch 66/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0725\n","Epoch 67/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0788\n","Epoch 68/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0697\n","Epoch 69/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0703\n","Epoch 70/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0721\n","Epoch 71/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0738\n","Epoch 72/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0688\n","Epoch 73/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0743\n","Epoch 74/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0728\n","Epoch 75/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0745\n","Epoch 76/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0666\n","Epoch 77/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0683\n","Epoch 78/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0708\n","Epoch 79/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0738\n","Epoch 80/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0700\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f8a2d94dc70>"]},"metadata":{},"execution_count":56}]},{"cell_type":"code","source":["predicted_stock_price = model17.predict(X_test)\n","log = feature.iloc[:feature.shape[0]-X_test.shape[0], 0].values\n","data_mean = log.mean(axis=0) \n","data_std = log.std(axis=0)\n","original = (predicted_stock_price)*data_std+data_mean\n","\n","y = feature.iloc[feature.shape[0]-X_test.shape[0]:, 1:2].values\n","rmse = np.sqrt(np.mean(((original - y) ** 2)))\n","print(rmse)\n","\n","res.append(round(measure_accuarcy(original, n_days = 15)[0]  * 100,2))\n","print(measure_diff(original, n_days = 15))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QpJ8rNK3mTMF","executionInfo":{"status":"ok","timestamp":1669955178551,"user_tz":-540,"elapsed":1090,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"6c186a58-3b28-4f4b-95c9-f7eb5c9e0716"},"id":"QpJ8rNK3mTMF","execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["24/24 [==============================] - 1s 3ms/step\n","2.9848400523950134\n","[31.020945]\n"]}]},{"cell_type":"code","source":["model18 = Sequential()\n","\n","#Adding the first LSTM layer and some Dropout regularisation\n","\n","model18.add(LSTM(units = 60, return_sequences = True, input_shape = (X_train.shape[-2:])))\n","\n","model18.add(LSTM(40))\n","model18.add(Dropout(0.8))\n","\n","\n","# Adding the output layer i \n"," \n","model18.add(Dense(units = 1))\n","\n","# Compiling the RNN\n","\n","model18.compile(optimizer = 'adam' , loss = 'mean_squared_error' )\n","\n","# Fitting the RNN to the Training set\n","\n","model18.fit(X_train, y_train, epochs = 80, batch_size = 32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-GoFsYE-lxjX","executionInfo":{"status":"ok","timestamp":1669955230021,"user_tz":-540,"elapsed":51487,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"c27be535-fefb-4890-f0b4-56aec9f9b2a1"},"id":"-GoFsYE-lxjX","execution_count":58,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/80\n","98/98 [==============================] - 3s 6ms/step - loss: 0.2541\n","Epoch 2/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1508\n","Epoch 3/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1366\n","Epoch 4/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1318\n","Epoch 5/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1276\n","Epoch 6/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1207\n","Epoch 7/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1122\n","Epoch 8/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1207\n","Epoch 9/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1143\n","Epoch 10/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1236\n","Epoch 11/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1089\n","Epoch 12/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1099\n","Epoch 13/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1134\n","Epoch 14/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1138\n","Epoch 15/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1162\n","Epoch 16/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1126\n","Epoch 17/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1099\n","Epoch 18/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1108\n","Epoch 19/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1129\n","Epoch 20/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1120\n","Epoch 21/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1056\n","Epoch 22/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1020\n","Epoch 23/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1088\n","Epoch 24/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1069\n","Epoch 25/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1063\n","Epoch 26/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1058\n","Epoch 27/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1105\n","Epoch 28/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1048\n","Epoch 29/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1113\n","Epoch 30/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1012\n","Epoch 31/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1042\n","Epoch 32/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1103\n","Epoch 33/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1003\n","Epoch 34/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1050\n","Epoch 35/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1038\n","Epoch 36/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1008\n","Epoch 37/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1018\n","Epoch 38/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1029\n","Epoch 39/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1020\n","Epoch 40/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0940\n","Epoch 41/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1067\n","Epoch 42/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1078\n","Epoch 43/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1046\n","Epoch 44/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1054\n","Epoch 45/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1045\n","Epoch 46/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1001\n","Epoch 47/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1033\n","Epoch 48/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1010\n","Epoch 49/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0999\n","Epoch 50/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1006\n","Epoch 51/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1042\n","Epoch 52/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1033\n","Epoch 53/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0984\n","Epoch 54/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1039\n","Epoch 55/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1034\n","Epoch 56/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1023\n","Epoch 57/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1002\n","Epoch 58/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0970\n","Epoch 59/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1049\n","Epoch 60/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1052\n","Epoch 61/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0979\n","Epoch 62/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0995\n","Epoch 63/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1025\n","Epoch 64/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0996\n","Epoch 65/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0962\n","Epoch 66/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1066\n","Epoch 67/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1011\n","Epoch 68/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0981\n","Epoch 69/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1053\n","Epoch 70/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0940\n","Epoch 71/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1027\n","Epoch 72/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0997\n","Epoch 73/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0944\n","Epoch 74/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0975\n","Epoch 75/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1036\n","Epoch 76/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0924\n","Epoch 77/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1003\n","Epoch 78/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0970\n","Epoch 79/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1067\n","Epoch 80/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0985\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f8a2b75bd30>"]},"metadata":{},"execution_count":58}]},{"cell_type":"code","source":["predicted_stock_price = model18.predict(X_test)\n","log = feature.iloc[:feature.shape[0]-X_test.shape[0], 0].values\n","data_mean = log.mean(axis=0) \n","data_std = log.std(axis=0)\n","original = (predicted_stock_price)*data_std+data_mean\n","\n","y = feature.iloc[feature.shape[0]-X_test.shape[0]:, 1:2].values\n","rmse = np.sqrt(np.mean(((original - y) ** 2)))\n","print(rmse)\n","\n","res.append(round(measure_accuarcy(original, n_days = 15)[0]  * 100,2))\n","print(measure_diff(original, n_days = 15))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oSAb5w55mVs6","executionInfo":{"status":"ok","timestamp":1669955230539,"user_tz":-540,"elapsed":527,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"742c8fb5-25d4-4be5-e37e-97c1acff54c8"},"id":"oSAb5w55mVs6","execution_count":59,"outputs":[{"output_type":"stream","name":"stdout","text":["24/24 [==============================] - 1s 3ms/step\n","3.0294778336414026\n","[33.910713]\n"]}]},{"cell_type":"code","source":["model19 = Sequential()\n","\n","#Adding the first LSTM layer and some Dropout regularisation\n","\n","model19.add(LSTM(units = 40, return_sequences = True, input_shape = (X_train.shape[-2:])))\n","\n","model19.add(LSTM(60))\n","model19.add(Dropout(0.8))\n","\n","\n","# Adding the output layer i \n"," \n","model19.add(Dense(units = 1))\n","\n","# Compiling the RNN\n","\n","model19.compile(optimizer = 'adam' , loss = 'mean_squared_error' )\n","\n","# Fitting the RNN to the Training set\n","\n","model19.fit(X_train, y_train, epochs = 80, batch_size = 32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-ugI-xfTlsJh","executionInfo":{"status":"ok","timestamp":1669955282629,"user_tz":-540,"elapsed":52094,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"7c434e89-b227-424f-9559-e0b4604ebabe"},"id":"-ugI-xfTlsJh","execution_count":60,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/80\n","98/98 [==============================] - 3s 6ms/step - loss: 0.2361\n","Epoch 2/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1243\n","Epoch 3/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1050\n","Epoch 4/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0975\n","Epoch 5/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0922\n","Epoch 6/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0927\n","Epoch 7/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0890\n","Epoch 8/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0877\n","Epoch 9/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0855\n","Epoch 10/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0893\n","Epoch 11/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0828\n","Epoch 12/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0865\n","Epoch 13/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0829\n","Epoch 14/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0866\n","Epoch 15/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0843\n","Epoch 16/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0851\n","Epoch 17/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0795\n","Epoch 18/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0828\n","Epoch 19/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0849\n","Epoch 20/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0777\n","Epoch 21/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0769\n","Epoch 22/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0810\n","Epoch 23/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0818\n","Epoch 24/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0787\n","Epoch 25/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0808\n","Epoch 26/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0768\n","Epoch 27/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0737\n","Epoch 28/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0806\n","Epoch 29/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0763\n","Epoch 30/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0792\n","Epoch 31/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0770\n","Epoch 32/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0764\n","Epoch 33/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0758\n","Epoch 34/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0755\n","Epoch 35/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0705\n","Epoch 36/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0803\n","Epoch 37/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0813\n","Epoch 38/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0762\n","Epoch 39/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0769\n","Epoch 40/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0778\n","Epoch 41/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0748\n","Epoch 42/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0735\n","Epoch 43/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0733\n","Epoch 44/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0769\n","Epoch 45/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0805\n","Epoch 46/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0754\n","Epoch 47/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0786\n","Epoch 48/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0732\n","Epoch 49/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0727\n","Epoch 50/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0770\n","Epoch 51/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0716\n","Epoch 52/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0695\n","Epoch 53/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0705\n","Epoch 54/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0746\n","Epoch 55/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0747\n","Epoch 56/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0739\n","Epoch 57/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0746\n","Epoch 58/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0760\n","Epoch 59/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0674\n","Epoch 60/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0711\n","Epoch 61/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0753\n","Epoch 62/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0742\n","Epoch 63/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0722\n","Epoch 64/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0694\n","Epoch 65/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0756\n","Epoch 66/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0720\n","Epoch 67/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0717\n","Epoch 68/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0761\n","Epoch 69/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0727\n","Epoch 70/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0673\n","Epoch 71/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0707\n","Epoch 72/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0735\n","Epoch 73/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0735\n","Epoch 74/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0775\n","Epoch 75/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0701\n","Epoch 76/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0733\n","Epoch 77/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0724\n","Epoch 78/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0746\n","Epoch 79/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0714\n","Epoch 80/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0720\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f8a2ac1e490>"]},"metadata":{},"execution_count":60}]},{"cell_type":"code","source":["predicted_stock_price = model19.predict(X_test)\n","log = feature.iloc[:feature.shape[0]-X_test.shape[0], 0].values\n","data_mean = log.mean(axis=0) \n","data_std = log.std(axis=0)\n","original = (predicted_stock_price)*data_std+data_mean\n","\n","y = feature.iloc[feature.shape[0]-X_test.shape[0]:, 1:2].values\n","rmse = np.sqrt(np.mean(((original - y) ** 2)))\n","print(rmse)\n","\n","res.append(round(measure_accuarcy(original, n_days = 15)[0]  * 100,2))\n","print(measure_diff(original, n_days = 15))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xM5nhkpWmX7i","executionInfo":{"status":"ok","timestamp":1669955283066,"user_tz":-540,"elapsed":442,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"d87b6de1-432e-4a9c-8762-7c5aec54a6c1"},"id":"xM5nhkpWmX7i","execution_count":61,"outputs":[{"output_type":"stream","name":"stdout","text":["24/24 [==============================] - 1s 3ms/step\n","2.946223510827274\n","[12.816397]\n"]}]},{"cell_type":"code","source":["model20 = Sequential()\n","\n","#Adding the first LSTM layer and some Dropout regularisation\n","\n","model20.add(LSTM(units = 40, return_sequences = True, input_shape = (X_train.shape[-2:])))\n","\n","model20.add(LSTM(40))\n","model20.add(Dropout(0.8))\n","\n","\n","# Adding the output layer i \n"," \n","model20.add(Dense(units = 1))\n","\n","# Compiling the RNN\n","\n","model20.compile(optimizer = 'adam' , loss = 'mean_squared_error' )\n","\n","# Fitting the RNN to the Training set\n","\n","model20.fit(X_train, y_train, epochs = 80, batch_size = 32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"riWka8fYl5B2","executionInfo":{"status":"ok","timestamp":1669955334751,"user_tz":-540,"elapsed":51689,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"e37107c1-9e81-4e64-c875-45b14ae4612f"},"id":"riWka8fYl5B2","execution_count":62,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/80\n","98/98 [==============================] - 3s 6ms/step - loss: 0.2763\n","Epoch 2/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1591\n","Epoch 3/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1361\n","Epoch 4/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1226\n","Epoch 5/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1223\n","Epoch 6/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1202\n","Epoch 7/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1178\n","Epoch 8/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1142\n","Epoch 9/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1120\n","Epoch 10/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1158\n","Epoch 11/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1180\n","Epoch 12/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1086\n","Epoch 13/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1133\n","Epoch 14/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1092\n","Epoch 15/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1082\n","Epoch 16/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1083\n","Epoch 17/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1079\n","Epoch 18/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1104\n","Epoch 19/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1063\n","Epoch 20/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1109\n","Epoch 21/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1086\n","Epoch 22/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1038\n","Epoch 23/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1070\n","Epoch 24/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1067\n","Epoch 25/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1091\n","Epoch 26/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1116\n","Epoch 27/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1089\n","Epoch 28/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1094\n","Epoch 29/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1060\n","Epoch 30/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1157\n","Epoch 31/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1072\n","Epoch 32/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1096\n","Epoch 33/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1058\n","Epoch 34/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0951\n","Epoch 35/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1168\n","Epoch 36/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1020\n","Epoch 37/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1049\n","Epoch 38/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1024\n","Epoch 39/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0974\n","Epoch 40/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1017\n","Epoch 41/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0984\n","Epoch 42/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1085\n","Epoch 43/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1034\n","Epoch 44/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1049\n","Epoch 45/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0978\n","Epoch 46/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1071\n","Epoch 47/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1018\n","Epoch 48/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1007\n","Epoch 49/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0963\n","Epoch 50/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1041\n","Epoch 51/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1074\n","Epoch 52/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0966\n","Epoch 53/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1069\n","Epoch 54/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0993\n","Epoch 55/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1081\n","Epoch 56/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0951\n","Epoch 57/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1052\n","Epoch 58/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1009\n","Epoch 59/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0912\n","Epoch 60/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1040\n","Epoch 61/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1011\n","Epoch 62/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1075\n","Epoch 63/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0994\n","Epoch 64/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1024\n","Epoch 65/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1015\n","Epoch 66/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1003\n","Epoch 67/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1056\n","Epoch 68/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1008\n","Epoch 69/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1019\n","Epoch 70/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1035\n","Epoch 71/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1011\n","Epoch 72/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1021\n","Epoch 73/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0999\n","Epoch 74/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0977\n","Epoch 75/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1001\n","Epoch 76/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0974\n","Epoch 77/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1052\n","Epoch 78/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0932\n","Epoch 79/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0961\n","Epoch 80/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1023\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f8a27319e20>"]},"metadata":{},"execution_count":62}]},{"cell_type":"code","source":["predicted_stock_price = model20.predict(X_test)\n","log = feature.iloc[:feature.shape[0]-X_test.shape[0], 0].values\n","data_mean = log.mean(axis=0) \n","data_std = log.std(axis=0)\n","original = (predicted_stock_price)*data_std+data_mean\n","\n","y = feature.iloc[feature.shape[0]-X_test.shape[0]:, 1:2].values\n","rmse = np.sqrt(np.mean(((original - y) ** 2)))\n","print(rmse)\n","\n","res.append(round(measure_accuarcy(original, n_days = 15)[0]  * 100,2))\n","print(measure_diff(original, n_days = 15))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wTQhtH-pmAfy","executionInfo":{"status":"ok","timestamp":1669955335571,"user_tz":-540,"elapsed":826,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"f0e3f2a5-a826-43dc-87e3-ae5789b9344c"},"id":"wTQhtH-pmAfy","execution_count":63,"outputs":[{"output_type":"stream","name":"stdout","text":["24/24 [==============================] - 1s 3ms/step\n","3.0152580051100926\n","[33.43798]\n"]}]},{"cell_type":"code","source":["model21 = Sequential()\n","\n","#Adding the first LSTM layer and some Dropout regularisation\n","\n","model21.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[-2:])))\n","\n","model21.add(LSTM(50))\n","model21.add(Dropout(0.8))\n","\n","\n","# Adding the output layer i \n"," \n","model21.add(Dense(units = 1))\n","\n","# Compiling the RNN\n","\n","model21.compile(optimizer = 'adam' , loss = 'mean_squared_error' )\n","\n","# Fitting the RNN to the Training set\n","\n","model21.fit(X_train, y_train, epochs = 80, batch_size = 32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zwSU0ZV7ma10","executionInfo":{"status":"ok","timestamp":1669955391233,"user_tz":-540,"elapsed":55667,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"cd294828-9634-4f6a-fd1b-24624a002829"},"id":"zwSU0ZV7ma10","execution_count":64,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/80\n","98/98 [==============================] - 3s 7ms/step - loss: 0.2602\n","Epoch 2/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.1420\n","Epoch 3/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.1175\n","Epoch 4/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.1115\n","Epoch 5/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.1031\n","Epoch 6/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.1051\n","Epoch 7/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.1060\n","Epoch 8/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0993\n","Epoch 9/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.1019\n","Epoch 10/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.1049\n","Epoch 11/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.1003\n","Epoch 12/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.1006\n","Epoch 13/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0980\n","Epoch 14/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0989\n","Epoch 15/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0950\n","Epoch 16/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0921\n","Epoch 17/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0904\n","Epoch 18/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0923\n","Epoch 19/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0949\n","Epoch 20/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0906\n","Epoch 21/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0897\n","Epoch 22/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0926\n","Epoch 23/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0931\n","Epoch 24/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0953\n","Epoch 25/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0905\n","Epoch 26/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0944\n","Epoch 27/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0905\n","Epoch 28/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0899\n","Epoch 29/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0912\n","Epoch 30/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0928\n","Epoch 31/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0923\n","Epoch 32/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0882\n","Epoch 33/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0815\n","Epoch 34/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0915\n","Epoch 35/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0842\n","Epoch 36/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0916\n","Epoch 37/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0886\n","Epoch 38/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0844\n","Epoch 39/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0879\n","Epoch 40/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0884\n","Epoch 41/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0892\n","Epoch 42/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0903\n","Epoch 43/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0912\n","Epoch 44/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0889\n","Epoch 45/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0828\n","Epoch 46/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0889\n","Epoch 47/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0868\n","Epoch 48/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0820\n","Epoch 49/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0785\n","Epoch 50/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0866\n","Epoch 51/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0855\n","Epoch 52/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0822\n","Epoch 53/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0882\n","Epoch 54/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0886\n","Epoch 55/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0814\n","Epoch 56/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0850\n","Epoch 57/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0817\n","Epoch 58/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0857\n","Epoch 59/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0865\n","Epoch 60/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0831\n","Epoch 61/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0817\n","Epoch 62/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0809\n","Epoch 63/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0871\n","Epoch 64/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0785\n","Epoch 65/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0832\n","Epoch 66/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0883\n","Epoch 67/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0911\n","Epoch 68/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0810\n","Epoch 69/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0903\n","Epoch 70/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0844\n","Epoch 71/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0891\n","Epoch 72/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0835\n","Epoch 73/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0817\n","Epoch 74/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0821\n","Epoch 75/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0853\n","Epoch 76/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0803\n","Epoch 77/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0829\n","Epoch 78/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0854\n","Epoch 79/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0783\n","Epoch 80/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0833\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f8a2630f3d0>"]},"metadata":{},"execution_count":64}]},{"cell_type":"code","source":["predicted_stock_price = model21.predict(X_test)\n","log = feature.iloc[:feature.shape[0]-X_test.shape[0], 0].values\n","data_mean = log.mean(axis=0) \n","data_std = log.std(axis=0)\n","original = (predicted_stock_price)*data_std+data_mean\n","\n","y = feature.iloc[feature.shape[0]-X_test.shape[0]:, 1:2].values\n","rmse = np.sqrt(np.mean(((original - y) ** 2)))\n","print(rmse)\n","\n","res.append(round(measure_accuarcy(original, n_days = 15)[0]  * 100,2))\n","print(measure_diff(original, n_days = 15))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yC_4fwKfnhzh","executionInfo":{"status":"ok","timestamp":1669955392059,"user_tz":-540,"elapsed":830,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"8e452ef6-d694-48ba-f75f-d4fad5ac25b2"},"id":"yC_4fwKfnhzh","execution_count":65,"outputs":[{"output_type":"stream","name":"stdout","text":["24/24 [==============================] - 1s 3ms/step\n","2.9805487542630287\n","[40.402023]\n"]}]},{"cell_type":"code","source":["score = pd.DataFrame(res)\n","score"],"metadata":{"id":"aZYBvhcUnkTd","colab":{"base_uri":"https://localhost:8080/","height":700},"executionInfo":{"status":"ok","timestamp":1669955392060,"user_tz":-540,"elapsed":17,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"a5c8c70a-b7a5-49f5-b719-0dbccc8a30a8"},"id":"aZYBvhcUnkTd","execution_count":66,"outputs":[{"output_type":"execute_result","data":{"text/plain":["        0\n","0   60.43\n","1   61.23\n","2   59.63\n","3   69.12\n","4   59.36\n","5   68.98\n","6   55.48\n","7   67.25\n","8   58.69\n","9   65.78\n","10  63.10\n","11  67.38\n","12  69.65\n","13  71.66\n","14  69.92\n","15  73.93\n","16  74.20\n","17  68.98\n","18  69.25\n","19  69.65\n","20  75.00"],"text/html":["\n","  <div id=\"df-c69a94ff-1069-4330-add7-a493453164d7\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>60.43</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>61.23</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>59.63</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>69.12</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>59.36</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>68.98</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>55.48</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>67.25</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>58.69</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>65.78</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>63.10</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>67.38</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>69.65</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>71.66</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>69.92</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>73.93</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>74.20</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>68.98</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>69.25</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>69.65</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>75.00</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c69a94ff-1069-4330-add7-a493453164d7')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c69a94ff-1069-4330-add7-a493453164d7 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c69a94ff-1069-4330-add7-a493453164d7');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":66}]},{"cell_type":"code","source":["score.to_csv('res_3.csv', index=False)"],"metadata":{"id":"jaodNUGU4Wul","executionInfo":{"status":"ok","timestamp":1669955392061,"user_tz":-540,"elapsed":14,"user":{"displayName":"구태형","userId":"12113658638621684006"}}},"id":"jaodNUGU4Wul","execution_count":67,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"A3iqPuXG5HhD","executionInfo":{"status":"ok","timestamp":1669955392061,"user_tz":-540,"elapsed":13,"user":{"displayName":"구태형","userId":"12113658638621684006"}}},"id":"A3iqPuXG5HhD","execution_count":67,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"provenance":[]},"accelerator":"GPU","gpuClass":"premium"},"nbformat":4,"nbformat_minor":5}