{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eoUg8l58jQ6A","executionInfo":{"status":"ok","timestamp":1669958014183,"user_tz":-540,"elapsed":24938,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"c20e078f-7144-4284-810a-6fc2f85078cc"},"id":"eoUg8l58jQ6A","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":2,"id":"e31618f6","metadata":{"id":"e31618f6","executionInfo":{"status":"ok","timestamp":1669958017285,"user_tz":-540,"elapsed":3111,"user":{"displayName":"구태형","userId":"12113658638621684006"}}},"outputs":[],"source":["import math\n","\n","import sys\n","\n","import numpy as np\n","\n","import matplotlib.pyplot as plt\n","\n","import keras\n","\n","import pandas as pd\n","\n","import numpy as np\n","\n","from keras.models import Sequential\n","\n","from keras.layers import Dense\n","\n","from keras.layers import LSTM\n","\n","from keras.layers import Dropout\n","\n","from keras.layers import *\n","\n","from sklearn.preprocessing import MinMaxScaler\n","\n","from sklearn.preprocessing import StandardScaler\n","\n","from sklearn.metrics import mean_squared_error\n","\n","from sklearn.metrics import mean_absolute_error\n","\n","from sklearn.model_selection import train_test_split\n","\n","from keras.callbacks import EarlyStopping"]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/학교/3학년2학기/소프트웨어융합개론/coin/indicator"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pL_c18W0jo2h","executionInfo":{"status":"ok","timestamp":1669958018182,"user_tz":-540,"elapsed":904,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"10b0c4e5-5005-42df-ce01-2fc068299ce8"},"id":"pL_c18W0jo2h","execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/학교/3학년2학기/소프트웨어융합개론/coin/indicator\n"]}]},{"cell_type":"code","execution_count":4,"id":"764ecdc5","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":500},"id":"764ecdc5","executionInfo":{"status":"ok","timestamp":1669958020087,"user_tz":-540,"elapsed":1910,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"8d5d2c66-a2a8-45e3-a967-6f73f13149b1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of rows and columns: (3962, 25)\n"]},{"output_type":"execute_result","data":{"text/plain":["           close  close_log        nvi         pvi        ma_5       ma_10  \\\n","0      3091000.0  14.944005   1.163482   3063000.0   3084200.0   3170200.0   \n","1      3087000.0  14.942710   1.163482   3087000.0   3088600.0   3137500.0   \n","2      3071000.0  14.937514   1.157451   3087000.0   3085200.0   3106200.0   \n","3      3050000.0  14.930652   1.157451   3050000.0   3072400.0   3086100.0   \n","4      3003000.0  14.915122   1.139615   3050000.0   3060400.0   3063700.0   \n","...          ...        ...        ...         ...         ...         ...   \n","3957  22320000.0  16.920994  19.407960  22320000.0  22490200.0  22593100.0   \n","3958  22403000.0  16.924705  19.480131  22320000.0  22430800.0  22571300.0   \n","3959  23004000.0  16.951179  19.480131  23004000.0  22496800.0  22612900.0   \n","3960  22790000.0  16.941832  19.298913  23004000.0  22581400.0  22618800.0   \n","3961  23097000.0  16.955213  19.298913  23097000.0  22722800.0  22648600.0   \n","\n","           ma_20         ma_60        rsi           vpt  ...        mfi  \\\n","0      3289500.0  3.215300e+06  24.735450 -50913.192669  ...  53.117928   \n","1      3279000.0  3.216817e+06  25.546448 -50921.710773  ...  54.027715   \n","2      3262700.0  3.216783e+06  25.304465 -50942.230512  ...  52.648713   \n","3      3243350.0  3.215633e+06  26.044568 -50979.943691  ...  53.324172   \n","4      3223000.0  3.214083e+06  25.442177 -51042.834596  ...  54.476339   \n","...          ...           ...        ...           ...  ...        ...   \n","3957  22691850.0  2.493500e+07  46.624136   2341.093255  ...  53.458386   \n","3958  22662550.0  2.482275e+07  48.006214   2346.997775  ...  53.335951   \n","3959  22660250.0  2.472663e+07  51.684312   2391.934249  ...  43.927284   \n","3960  22651250.0  2.462907e+07  47.797063   2377.924759  ...  45.856043   \n","3961  22682950.0  2.453300e+07  51.084237   2402.135900  ...  45.480344   \n","\n","             ema_5        ema_10        ema_20        ema_60            fi  \\\n","0     3.101464e+06  3.154992e+06  3.207830e+06  3.195372e+06 -2.058452e+09   \n","1     3.096642e+06  3.142630e+06  3.196323e+06  3.191819e+06 -2.356487e+09   \n","2     3.088095e+06  3.129606e+06  3.184387e+06  3.187857e+06 -1.445045e+09   \n","3     3.075397e+06  3.115132e+06  3.171588e+06  3.183338e+06 -1.897196e+09   \n","4     3.051264e+06  3.094745e+06  3.155532e+06  3.177425e+06 -1.473320e+09   \n","...            ...           ...           ...           ...           ...   \n","3957  2.245848e+07  2.256368e+07  2.277992e+07  2.431527e+07 -2.116684e+08   \n","3958  2.243999e+07  2.253446e+07  2.274402e+07  2.425257e+07 -1.222620e+08   \n","3959  2.262799e+07  2.261983e+07  2.276878e+07  2.421164e+07  1.172543e+08   \n","3960  2.268200e+07  2.265077e+07  2.277080e+07  2.416503e+07 -1.490895e+08   \n","3961  2.282033e+07  2.273190e+07  2.280187e+07  2.413001e+07  9.345974e+07   \n","\n","               ubb         mbb           lbb       volume  \n","0     3.610062e+06   3289500.0  2.968938e+06  5388.617973  \n","1     3.612042e+06   3279000.0  2.945958e+06  6582.364759  \n","2     3.603251e+06   3262700.0  2.922149e+06  3959.027066  \n","3     3.586173e+06   3243350.0  2.900527e+06  5515.103573  \n","4     3.572426e+06   3223000.0  2.873574e+06  4081.218313  \n","...            ...         ...           ...          ...  \n","3957  2.316037e+07  22691850.0  2.222333e+07  1666.680241  \n","3958  2.312610e+07  22662550.0  2.219900e+07  1587.817986  \n","3959  2.311609e+07  22660250.0  2.220441e+07  1675.061266  \n","3960  2.308805e+07  22651250.0  2.221445e+07  1505.954700  \n","3961  2.315299e+07  22682950.0  2.221291e+07  1797.302637  \n","\n","[3962 rows x 25 columns]"],"text/html":["\n","  <div id=\"df-9adbc50e-7a93-4ee9-83c9-f5330b67152b\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>close</th>\n","      <th>close_log</th>\n","      <th>nvi</th>\n","      <th>pvi</th>\n","      <th>ma_5</th>\n","      <th>ma_10</th>\n","      <th>ma_20</th>\n","      <th>ma_60</th>\n","      <th>rsi</th>\n","      <th>vpt</th>\n","      <th>...</th>\n","      <th>mfi</th>\n","      <th>ema_5</th>\n","      <th>ema_10</th>\n","      <th>ema_20</th>\n","      <th>ema_60</th>\n","      <th>fi</th>\n","      <th>ubb</th>\n","      <th>mbb</th>\n","      <th>lbb</th>\n","      <th>volume</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3091000.0</td>\n","      <td>14.944005</td>\n","      <td>1.163482</td>\n","      <td>3063000.0</td>\n","      <td>3084200.0</td>\n","      <td>3170200.0</td>\n","      <td>3289500.0</td>\n","      <td>3.215300e+06</td>\n","      <td>24.735450</td>\n","      <td>-50913.192669</td>\n","      <td>...</td>\n","      <td>53.117928</td>\n","      <td>3.101464e+06</td>\n","      <td>3.154992e+06</td>\n","      <td>3.207830e+06</td>\n","      <td>3.195372e+06</td>\n","      <td>-2.058452e+09</td>\n","      <td>3.610062e+06</td>\n","      <td>3289500.0</td>\n","      <td>2.968938e+06</td>\n","      <td>5388.617973</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3087000.0</td>\n","      <td>14.942710</td>\n","      <td>1.163482</td>\n","      <td>3087000.0</td>\n","      <td>3088600.0</td>\n","      <td>3137500.0</td>\n","      <td>3279000.0</td>\n","      <td>3.216817e+06</td>\n","      <td>25.546448</td>\n","      <td>-50921.710773</td>\n","      <td>...</td>\n","      <td>54.027715</td>\n","      <td>3.096642e+06</td>\n","      <td>3.142630e+06</td>\n","      <td>3.196323e+06</td>\n","      <td>3.191819e+06</td>\n","      <td>-2.356487e+09</td>\n","      <td>3.612042e+06</td>\n","      <td>3279000.0</td>\n","      <td>2.945958e+06</td>\n","      <td>6582.364759</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3071000.0</td>\n","      <td>14.937514</td>\n","      <td>1.157451</td>\n","      <td>3087000.0</td>\n","      <td>3085200.0</td>\n","      <td>3106200.0</td>\n","      <td>3262700.0</td>\n","      <td>3.216783e+06</td>\n","      <td>25.304465</td>\n","      <td>-50942.230512</td>\n","      <td>...</td>\n","      <td>52.648713</td>\n","      <td>3.088095e+06</td>\n","      <td>3.129606e+06</td>\n","      <td>3.184387e+06</td>\n","      <td>3.187857e+06</td>\n","      <td>-1.445045e+09</td>\n","      <td>3.603251e+06</td>\n","      <td>3262700.0</td>\n","      <td>2.922149e+06</td>\n","      <td>3959.027066</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3050000.0</td>\n","      <td>14.930652</td>\n","      <td>1.157451</td>\n","      <td>3050000.0</td>\n","      <td>3072400.0</td>\n","      <td>3086100.0</td>\n","      <td>3243350.0</td>\n","      <td>3.215633e+06</td>\n","      <td>26.044568</td>\n","      <td>-50979.943691</td>\n","      <td>...</td>\n","      <td>53.324172</td>\n","      <td>3.075397e+06</td>\n","      <td>3.115132e+06</td>\n","      <td>3.171588e+06</td>\n","      <td>3.183338e+06</td>\n","      <td>-1.897196e+09</td>\n","      <td>3.586173e+06</td>\n","      <td>3243350.0</td>\n","      <td>2.900527e+06</td>\n","      <td>5515.103573</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>3003000.0</td>\n","      <td>14.915122</td>\n","      <td>1.139615</td>\n","      <td>3050000.0</td>\n","      <td>3060400.0</td>\n","      <td>3063700.0</td>\n","      <td>3223000.0</td>\n","      <td>3.214083e+06</td>\n","      <td>25.442177</td>\n","      <td>-51042.834596</td>\n","      <td>...</td>\n","      <td>54.476339</td>\n","      <td>3.051264e+06</td>\n","      <td>3.094745e+06</td>\n","      <td>3.155532e+06</td>\n","      <td>3.177425e+06</td>\n","      <td>-1.473320e+09</td>\n","      <td>3.572426e+06</td>\n","      <td>3223000.0</td>\n","      <td>2.873574e+06</td>\n","      <td>4081.218313</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>3957</th>\n","      <td>22320000.0</td>\n","      <td>16.920994</td>\n","      <td>19.407960</td>\n","      <td>22320000.0</td>\n","      <td>22490200.0</td>\n","      <td>22593100.0</td>\n","      <td>22691850.0</td>\n","      <td>2.493500e+07</td>\n","      <td>46.624136</td>\n","      <td>2341.093255</td>\n","      <td>...</td>\n","      <td>53.458386</td>\n","      <td>2.245848e+07</td>\n","      <td>2.256368e+07</td>\n","      <td>2.277992e+07</td>\n","      <td>2.431527e+07</td>\n","      <td>-2.116684e+08</td>\n","      <td>2.316037e+07</td>\n","      <td>22691850.0</td>\n","      <td>2.222333e+07</td>\n","      <td>1666.680241</td>\n","    </tr>\n","    <tr>\n","      <th>3958</th>\n","      <td>22403000.0</td>\n","      <td>16.924705</td>\n","      <td>19.480131</td>\n","      <td>22320000.0</td>\n","      <td>22430800.0</td>\n","      <td>22571300.0</td>\n","      <td>22662550.0</td>\n","      <td>2.482275e+07</td>\n","      <td>48.006214</td>\n","      <td>2346.997775</td>\n","      <td>...</td>\n","      <td>53.335951</td>\n","      <td>2.243999e+07</td>\n","      <td>2.253446e+07</td>\n","      <td>2.274402e+07</td>\n","      <td>2.425257e+07</td>\n","      <td>-1.222620e+08</td>\n","      <td>2.312610e+07</td>\n","      <td>22662550.0</td>\n","      <td>2.219900e+07</td>\n","      <td>1587.817986</td>\n","    </tr>\n","    <tr>\n","      <th>3959</th>\n","      <td>23004000.0</td>\n","      <td>16.951179</td>\n","      <td>19.480131</td>\n","      <td>23004000.0</td>\n","      <td>22496800.0</td>\n","      <td>22612900.0</td>\n","      <td>22660250.0</td>\n","      <td>2.472663e+07</td>\n","      <td>51.684312</td>\n","      <td>2391.934249</td>\n","      <td>...</td>\n","      <td>43.927284</td>\n","      <td>2.262799e+07</td>\n","      <td>2.261983e+07</td>\n","      <td>2.276878e+07</td>\n","      <td>2.421164e+07</td>\n","      <td>1.172543e+08</td>\n","      <td>2.311609e+07</td>\n","      <td>22660250.0</td>\n","      <td>2.220441e+07</td>\n","      <td>1675.061266</td>\n","    </tr>\n","    <tr>\n","      <th>3960</th>\n","      <td>22790000.0</td>\n","      <td>16.941832</td>\n","      <td>19.298913</td>\n","      <td>23004000.0</td>\n","      <td>22581400.0</td>\n","      <td>22618800.0</td>\n","      <td>22651250.0</td>\n","      <td>2.462907e+07</td>\n","      <td>47.797063</td>\n","      <td>2377.924759</td>\n","      <td>...</td>\n","      <td>45.856043</td>\n","      <td>2.268200e+07</td>\n","      <td>2.265077e+07</td>\n","      <td>2.277080e+07</td>\n","      <td>2.416503e+07</td>\n","      <td>-1.490895e+08</td>\n","      <td>2.308805e+07</td>\n","      <td>22651250.0</td>\n","      <td>2.221445e+07</td>\n","      <td>1505.954700</td>\n","    </tr>\n","    <tr>\n","      <th>3961</th>\n","      <td>23097000.0</td>\n","      <td>16.955213</td>\n","      <td>19.298913</td>\n","      <td>23097000.0</td>\n","      <td>22722800.0</td>\n","      <td>22648600.0</td>\n","      <td>22682950.0</td>\n","      <td>2.453300e+07</td>\n","      <td>51.084237</td>\n","      <td>2402.135900</td>\n","      <td>...</td>\n","      <td>45.480344</td>\n","      <td>2.282033e+07</td>\n","      <td>2.273190e+07</td>\n","      <td>2.280187e+07</td>\n","      <td>2.413001e+07</td>\n","      <td>9.345974e+07</td>\n","      <td>2.315299e+07</td>\n","      <td>22682950.0</td>\n","      <td>2.221291e+07</td>\n","      <td>1797.302637</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3962 rows × 25 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9adbc50e-7a93-4ee9-83c9-f5330b67152b')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-9adbc50e-7a93-4ee9-83c9-f5330b67152b button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-9adbc50e-7a93-4ee9-83c9-f5330b67152b');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":4}],"source":["df=pd.read_csv(\"bitcoin_indicator.csv\")\n","df_time = pd.read_csv(\"time.csv\")\n","print('Number of rows and columns:', df.shape)\n","\n","time_step = 30\n","index_rsi = 14\n","n_days = 15\n","\n","df"]},{"cell_type":"code","execution_count":5,"id":"a7df70f9","metadata":{"id":"a7df70f9","executionInfo":{"status":"ok","timestamp":1669958020088,"user_tz":-540,"elapsed":68,"user":{"displayName":"구태형","userId":"12113658638621684006"}}},"outputs":[],"source":["df_time = df_time.iloc[:,0]"]},{"cell_type":"code","execution_count":6,"id":"c97a1fe6","metadata":{"id":"c97a1fe6","executionInfo":{"status":"ok","timestamp":1669958020089,"user_tz":-540,"elapsed":67,"user":{"displayName":"구태형","userId":"12113658638621684006"}}},"outputs":[],"source":["df_time = df_time.str[:10]"]},{"cell_type":"code","source":["res = []"],"metadata":{"id":"ZyQ-jsXKoupq","executionInfo":{"status":"ok","timestamp":1669958020089,"user_tz":-540,"elapsed":66,"user":{"displayName":"구태형","userId":"12113658638621684006"}}},"id":"ZyQ-jsXKoupq","execution_count":7,"outputs":[]},{"cell_type":"markdown","id":"c3e84c6b","metadata":{"id":"c3e84c6b"},"source":["# training set/ test set"]},{"cell_type":"code","execution_count":8,"id":"37574682","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"37574682","executionInfo":{"status":"ok","timestamp":1669958020090,"user_tz":-540,"elapsed":66,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"addd96f1-304e-45e8-c6a0-8c7c80110a75"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3169, 24)"]},"metadata":{},"execution_count":8}],"source":["feature = df.iloc[:,1:]\n","\n","idx = int(feature.shape[0]*0.8)\n","\n","training_set = feature.iloc[:idx].values\n","test_set = feature.iloc[idx:].values\n","training_set.shape"]},{"cell_type":"code","execution_count":9,"id":"664f1c48","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"664f1c48","executionInfo":{"status":"ok","timestamp":1669958020090,"user_tz":-540,"elapsed":52,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"baf4cf2d-e869-4c63-9944-594b7af1d378"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1.49440052e+01, 1.16348160e+00, 3.06300000e+06, ...,\n","        3.28950000e+06, 2.96893767e+06, 5.38861797e+03],\n","       [1.49427103e+01, 1.16348160e+00, 3.08700000e+06, ...,\n","        3.27900000e+06, 2.94595788e+06, 6.58236476e+03],\n","       [1.49375138e+01, 1.15745125e+00, 3.08700000e+06, ...,\n","        3.26270000e+06, 2.92214868e+06, 3.95902707e+03],\n","       ...,\n","       [1.81156490e+01, 2.14693282e+01, 7.37100000e+07, ...,\n","        7.54120500e+07, 7.09528907e+07, 2.58543345e+03],\n","       [1.81241328e+01, 2.16522442e+01, 7.37100000e+07, ...,\n","        7.52044000e+07, 7.09676991e+07, 2.22946506e+03],\n","       [1.81121971e+01, 2.13953462e+01, 7.37100000e+07, ...,\n","        7.48318500e+07, 7.14908085e+07, 1.95423116e+03]])"]},"metadata":{},"execution_count":9}],"source":["training_set"]},{"cell_type":"code","execution_count":10,"id":"fed35bac","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fed35bac","executionInfo":{"status":"ok","timestamp":1669958020090,"user_tz":-540,"elapsed":39,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"7006d8cb-ade0-4a29-b1a8-f57f9b77c9a9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([-1.66957522, -1.66488984, -1.67506461, ...,  2.15800037,\n","        2.16822929,  2.15383842])"]},"metadata":{},"execution_count":10}],"source":["# 정규화\n","ss = StandardScaler()\n","\n","training_set_scaled = ss.fit_transform(training_set)\n","\n","X_train = []\n","\n","y_train = []\n","\n","for i in range(time_step, idx-n_days):\n","    X_train.append(training_set_scaled[i-time_step:i])\n","\n","    y_train.append(training_set_scaled[i+n_days, 0])\n","\n","X_train, y_train = np.array(X_train), np.array(y_train)\n","y_train"]},{"cell_type":"code","execution_count":11,"id":"6db2ea61","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6db2ea61","executionInfo":{"status":"ok","timestamp":1669958020091,"user_tz":-540,"elapsed":28,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"7d97d13d-f82f-4411-c792-657184d49dae"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3124, 30, 24)"]},"metadata":{},"execution_count":11}],"source":["X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], X_train.shape[2]))\n","X_train.shape"]},{"cell_type":"code","execution_count":12,"id":"a210853a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a210853a","executionInfo":{"status":"ok","timestamp":1669958020091,"user_tz":-540,"elapsed":20,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"69b9b7af-c711-4f1a-e923-6128c74a00e4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3124,)"]},"metadata":{},"execution_count":12}],"source":["y_train.shape"]},{"cell_type":"markdown","id":"0e0265a7","metadata":{"id":"0e0265a7"},"source":["# 모델 학습"]},{"cell_type":"code","execution_count":13,"id":"b3a399d2","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b3a399d2","executionInfo":{"status":"ok","timestamp":1669958188177,"user_tz":-540,"elapsed":168098,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"f4456fe0-b12c-4db2-e9c0-adac0526a72b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/80\n","98/98 [==============================] - 17s 19ms/step - loss: 0.1493\n","Epoch 2/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0544\n","Epoch 3/80\n","98/98 [==============================] - 2s 18ms/step - loss: 0.0525\n","Epoch 4/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0424\n","Epoch 5/80\n","98/98 [==============================] - 2s 18ms/step - loss: 0.0409\n","Epoch 6/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0382\n","Epoch 7/80\n","98/98 [==============================] - 2s 18ms/step - loss: 0.0361\n","Epoch 8/80\n","98/98 [==============================] - 2s 18ms/step - loss: 0.0352\n","Epoch 9/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0351\n","Epoch 10/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0319\n","Epoch 11/80\n","98/98 [==============================] - 2s 18ms/step - loss: 0.0312\n","Epoch 12/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0288\n","Epoch 13/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0268\n","Epoch 14/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0268\n","Epoch 15/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0260\n","Epoch 16/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0258\n","Epoch 17/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0234\n","Epoch 18/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0254\n","Epoch 19/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0228\n","Epoch 20/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0238\n","Epoch 21/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0235\n","Epoch 22/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0234\n","Epoch 23/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0232\n","Epoch 24/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0209\n","Epoch 25/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0213\n","Epoch 26/80\n","98/98 [==============================] - 2s 18ms/step - loss: 0.0237\n","Epoch 27/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0226\n","Epoch 28/80\n","98/98 [==============================] - 2s 18ms/step - loss: 0.0220\n","Epoch 29/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0207\n","Epoch 30/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0233\n","Epoch 31/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0200\n","Epoch 32/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0221\n","Epoch 33/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0203\n","Epoch 34/80\n","98/98 [==============================] - 2s 18ms/step - loss: 0.0201\n","Epoch 35/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0184\n","Epoch 36/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0205\n","Epoch 37/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0197\n","Epoch 38/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0194\n","Epoch 39/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0178\n","Epoch 40/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0183\n","Epoch 41/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0216\n","Epoch 42/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0191\n","Epoch 43/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0197\n","Epoch 44/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0185\n","Epoch 45/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0194\n","Epoch 46/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0198\n","Epoch 47/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0190\n","Epoch 48/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0183\n","Epoch 49/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0184\n","Epoch 50/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0184\n","Epoch 51/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0182\n","Epoch 52/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0189\n","Epoch 53/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0201\n","Epoch 54/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0163\n","Epoch 55/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0184\n","Epoch 56/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0194\n","Epoch 57/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0176\n","Epoch 58/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0188\n","Epoch 59/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0186\n","Epoch 60/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0191\n","Epoch 61/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0198\n","Epoch 62/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0180\n","Epoch 63/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0185\n","Epoch 64/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0181\n","Epoch 65/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0171\n","Epoch 66/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0173\n","Epoch 67/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0172\n","Epoch 68/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0175\n","Epoch 69/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0172\n","Epoch 70/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0166\n","Epoch 71/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0163\n","Epoch 72/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0191\n","Epoch 73/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0164\n","Epoch 74/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0186\n","Epoch 75/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0167\n","Epoch 76/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0169\n","Epoch 77/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0167\n","Epoch 78/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0169\n","Epoch 79/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0182\n","Epoch 80/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0157\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f55c4553d60>"]},"metadata":{},"execution_count":13}],"source":["model = Sequential()\n","\n","#Adding the first LSTM layer and some Dropout regularisation\n","\n","model.add(LSTM(units = 100, return_sequences = True, input_shape = (X_train.shape[-2:])))\n","\n","model.add(LSTM(100, return_sequences=True))\n","model.add(Dropout(0.4))\n","\n","\n","model.add(LSTM(100, return_sequences=True))\n","model.add(Dropout(0.4))\n","\n","#model.add(RepeatVector(time_step))\n","\n","# Adding a second LSTM layer and some Dropout regularisation\n","\n","model.add(LSTM(units = 100, return_sequences = True))\n","model.add(Dropout(0.4))\n","\n","# Adding a third LSTM layer and some Dropout regularisation\n","\n","model.add(LSTM(units = 60, return_sequences = True))\n","model.add(Dropout(0.4))\n","\n","model.add(LSTM(units = 60, return_sequences = True))\n","model.add(Dropout(0.4))\n","\n","\n","model.add(LSTM(units = 60, return_sequences = True))\n","model.add(Dropout(0.4))\n","\n","# Adding a fourth LSTM layer and some Dropout regularisation\n","\n","model.add(LSTM(units = 60))\n","model.add(Dropout(0.4))\n","\n","\n","# Adding the output layer i \n"," \n","model.add(Dense(units = 1))\n","\n","# Compiling the RNN\n","\n","model.compile(optimizer = 'adam' , loss = 'mean_squared_error' )\n","\n","# Fitting the RNN to the Training set\n","\n","model.fit(X_train, y_train, epochs = 80, batch_size = 32)"]},{"cell_type":"code","execution_count":14,"id":"1a56d4a2","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1a56d4a2","executionInfo":{"status":"ok","timestamp":1669958188696,"user_tz":-540,"elapsed":535,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"6a8f8de9-8274-4734-c42c-b2e4bf7cf7f2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm (LSTM)                 (None, 30, 100)           50000     \n","                                                                 \n"," lstm_1 (LSTM)               (None, 30, 100)           80400     \n","                                                                 \n"," dropout (Dropout)           (None, 30, 100)           0         \n","                                                                 \n"," lstm_2 (LSTM)               (None, 30, 100)           80400     \n","                                                                 \n"," dropout_1 (Dropout)         (None, 30, 100)           0         \n","                                                                 \n"," lstm_3 (LSTM)               (None, 30, 100)           80400     \n","                                                                 \n"," dropout_2 (Dropout)         (None, 30, 100)           0         \n","                                                                 \n"," lstm_4 (LSTM)               (None, 30, 60)            38640     \n","                                                                 \n"," dropout_3 (Dropout)         (None, 30, 60)            0         \n","                                                                 \n"," lstm_5 (LSTM)               (None, 30, 60)            29040     \n","                                                                 \n"," dropout_4 (Dropout)         (None, 30, 60)            0         \n","                                                                 \n"," lstm_6 (LSTM)               (None, 30, 60)            29040     \n","                                                                 \n"," dropout_5 (Dropout)         (None, 30, 60)            0         \n","                                                                 \n"," lstm_7 (LSTM)               (None, 60)                29040     \n","                                                                 \n"," dropout_6 (Dropout)         (None, 60)                0         \n","                                                                 \n"," dense (Dense)               (None, 1)                 61        \n","                                                                 \n","=================================================================\n","Total params: 417,021\n","Trainable params: 417,021\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"markdown","id":"9573b370","metadata":{"id":"9573b370"},"source":["# 모델이 예상한 값 불러오기"]},{"cell_type":"code","execution_count":15,"id":"068ce98a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"068ce98a","executionInfo":{"status":"ok","timestamp":1669958188697,"user_tz":-540,"elapsed":14,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"4ae4e7f4-9f74-4b94-867a-73a288c5e7e8"},"outputs":[{"output_type":"stream","name":"stdout","text":["(763, 30, 24)\n"]}],"source":["dataset_train = feature.iloc[:idx] \n","\n","dataset_test = feature.iloc[idx:]\n","\n","dataset_total = pd.concat((dataset_train, dataset_test), axis = 0)\n","\n","inputs = dataset_total[len(dataset_total) - len(dataset_test) - time_step:].values\n","\n","#inputs = inputs.reshape(-1,n_features)\n","\n","inputs = ss.transform(inputs)\n","\n","X_test = []\n","for i in range(time_step, dataset_test.shape[0]):\n","\n","    X_test.append(inputs[i-time_step:i])\n","\n","X_test = np.array(X_test)\n","\n","X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], X_test.shape[2]))\n","\n","print(X_test.shape)"]},{"cell_type":"code","execution_count":16,"id":"d501d596","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d501d596","executionInfo":{"status":"ok","timestamp":1669958191467,"user_tz":-540,"elapsed":2774,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"bb24db0b-a746-49b7-9964-4486d8ef1f8d"},"outputs":[{"output_type":"stream","name":"stdout","text":["24/24 [==============================] - 3s 8ms/step\n"]}],"source":["predicted_stock_price = model.predict(X_test)"]},{"cell_type":"code","execution_count":17,"id":"c1a86e14","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c1a86e14","executionInfo":{"status":"ok","timestamp":1669958191467,"user_tz":-540,"elapsed":35,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"bb243721-829d-44e0-b67c-644c8bea70e1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["763"]},"metadata":{},"execution_count":17}],"source":["X_test.shape[0]"]},{"cell_type":"code","execution_count":18,"id":"e3b635e6","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":483},"id":"e3b635e6","executionInfo":{"status":"ok","timestamp":1669958191468,"user_tz":-540,"elapsed":34,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"a9eafd08-0e80-4ba6-c4cb-731f17a0fe9d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["      close_log        nvi         pvi        ma_5       ma_10       ma_20  \\\n","0     14.944005   1.163482   3063000.0   3084200.0   3170200.0   3289500.0   \n","1     14.942710   1.163482   3087000.0   3088600.0   3137500.0   3279000.0   \n","2     14.937514   1.157451   3087000.0   3085200.0   3106200.0   3262700.0   \n","3     14.930652   1.157451   3050000.0   3072400.0   3086100.0   3243350.0   \n","4     14.915122   1.139615   3050000.0   3060400.0   3063700.0   3223000.0   \n","...         ...        ...         ...         ...         ...         ...   \n","3957  16.920994  19.407960  22320000.0  22490200.0  22593100.0  22691850.0   \n","3958  16.924705  19.480131  22320000.0  22430800.0  22571300.0  22662550.0   \n","3959  16.951179  19.480131  23004000.0  22496800.0  22612900.0  22660250.0   \n","3960  16.941832  19.298913  23004000.0  22581400.0  22618800.0  22651250.0   \n","3961  16.955213  19.298913  23097000.0  22722800.0  22648600.0  22682950.0   \n","\n","             ma_60        rsi           vpt           obv  ...        mfi  \\\n","0     3.215300e+06  24.735450 -50913.192669  7.758012e+04  ...  53.117928   \n","1     3.216817e+06  25.546448 -50921.710773  7.099776e+04  ...  54.027715   \n","2     3.216783e+06  25.304465 -50942.230512  6.703873e+04  ...  52.648713   \n","3     3.215633e+06  26.044568 -50979.943691  6.152363e+04  ...  53.324172   \n","4     3.214083e+06  25.442177 -51042.834596  5.744241e+04  ...  54.476339   \n","...            ...        ...           ...           ...  ...        ...   \n","3957  2.493500e+07  46.624136   2341.093255  1.475735e+06  ...  53.458386   \n","3958  2.482275e+07  48.006214   2346.997775  1.477323e+06  ...  53.335951   \n","3959  2.472663e+07  51.684312   2391.934249  1.478998e+06  ...  43.927284   \n","3960  2.462907e+07  47.797063   2377.924759  1.477492e+06  ...  45.856043   \n","3961  2.453300e+07  51.084237   2402.135900  1.479290e+06  ...  45.480344   \n","\n","             ema_5        ema_10        ema_20        ema_60            fi  \\\n","0     3.101464e+06  3.154992e+06  3.207830e+06  3.195372e+06 -2.058452e+09   \n","1     3.096642e+06  3.142630e+06  3.196323e+06  3.191819e+06 -2.356487e+09   \n","2     3.088095e+06  3.129606e+06  3.184387e+06  3.187857e+06 -1.445045e+09   \n","3     3.075397e+06  3.115132e+06  3.171588e+06  3.183338e+06 -1.897196e+09   \n","4     3.051264e+06  3.094745e+06  3.155532e+06  3.177425e+06 -1.473320e+09   \n","...            ...           ...           ...           ...           ...   \n","3957  2.245848e+07  2.256368e+07  2.277992e+07  2.431527e+07 -2.116684e+08   \n","3958  2.243999e+07  2.253446e+07  2.274402e+07  2.425257e+07 -1.222620e+08   \n","3959  2.262799e+07  2.261983e+07  2.276878e+07  2.421164e+07  1.172543e+08   \n","3960  2.268200e+07  2.265077e+07  2.277080e+07  2.416503e+07 -1.490895e+08   \n","3961  2.282033e+07  2.273190e+07  2.280187e+07  2.413001e+07  9.345974e+07   \n","\n","               ubb         mbb           lbb       volume  \n","0     3.610062e+06   3289500.0  2.968938e+06  5388.617973  \n","1     3.612042e+06   3279000.0  2.945958e+06  6582.364759  \n","2     3.603251e+06   3262700.0  2.922149e+06  3959.027066  \n","3     3.586173e+06   3243350.0  2.900527e+06  5515.103573  \n","4     3.572426e+06   3223000.0  2.873574e+06  4081.218313  \n","...            ...         ...           ...          ...  \n","3957  2.316037e+07  22691850.0  2.222333e+07  1666.680241  \n","3958  2.312610e+07  22662550.0  2.219900e+07  1587.817986  \n","3959  2.311609e+07  22660250.0  2.220441e+07  1675.061266  \n","3960  2.308805e+07  22651250.0  2.221445e+07  1505.954700  \n","3961  2.315299e+07  22682950.0  2.221291e+07  1797.302637  \n","\n","[3962 rows x 24 columns]"],"text/html":["\n","  <div id=\"df-827d08ac-bbe7-49d4-a66f-739eac949d51\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>close_log</th>\n","      <th>nvi</th>\n","      <th>pvi</th>\n","      <th>ma_5</th>\n","      <th>ma_10</th>\n","      <th>ma_20</th>\n","      <th>ma_60</th>\n","      <th>rsi</th>\n","      <th>vpt</th>\n","      <th>obv</th>\n","      <th>...</th>\n","      <th>mfi</th>\n","      <th>ema_5</th>\n","      <th>ema_10</th>\n","      <th>ema_20</th>\n","      <th>ema_60</th>\n","      <th>fi</th>\n","      <th>ubb</th>\n","      <th>mbb</th>\n","      <th>lbb</th>\n","      <th>volume</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>14.944005</td>\n","      <td>1.163482</td>\n","      <td>3063000.0</td>\n","      <td>3084200.0</td>\n","      <td>3170200.0</td>\n","      <td>3289500.0</td>\n","      <td>3.215300e+06</td>\n","      <td>24.735450</td>\n","      <td>-50913.192669</td>\n","      <td>7.758012e+04</td>\n","      <td>...</td>\n","      <td>53.117928</td>\n","      <td>3.101464e+06</td>\n","      <td>3.154992e+06</td>\n","      <td>3.207830e+06</td>\n","      <td>3.195372e+06</td>\n","      <td>-2.058452e+09</td>\n","      <td>3.610062e+06</td>\n","      <td>3289500.0</td>\n","      <td>2.968938e+06</td>\n","      <td>5388.617973</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>14.942710</td>\n","      <td>1.163482</td>\n","      <td>3087000.0</td>\n","      <td>3088600.0</td>\n","      <td>3137500.0</td>\n","      <td>3279000.0</td>\n","      <td>3.216817e+06</td>\n","      <td>25.546448</td>\n","      <td>-50921.710773</td>\n","      <td>7.099776e+04</td>\n","      <td>...</td>\n","      <td>54.027715</td>\n","      <td>3.096642e+06</td>\n","      <td>3.142630e+06</td>\n","      <td>3.196323e+06</td>\n","      <td>3.191819e+06</td>\n","      <td>-2.356487e+09</td>\n","      <td>3.612042e+06</td>\n","      <td>3279000.0</td>\n","      <td>2.945958e+06</td>\n","      <td>6582.364759</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>14.937514</td>\n","      <td>1.157451</td>\n","      <td>3087000.0</td>\n","      <td>3085200.0</td>\n","      <td>3106200.0</td>\n","      <td>3262700.0</td>\n","      <td>3.216783e+06</td>\n","      <td>25.304465</td>\n","      <td>-50942.230512</td>\n","      <td>6.703873e+04</td>\n","      <td>...</td>\n","      <td>52.648713</td>\n","      <td>3.088095e+06</td>\n","      <td>3.129606e+06</td>\n","      <td>3.184387e+06</td>\n","      <td>3.187857e+06</td>\n","      <td>-1.445045e+09</td>\n","      <td>3.603251e+06</td>\n","      <td>3262700.0</td>\n","      <td>2.922149e+06</td>\n","      <td>3959.027066</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>14.930652</td>\n","      <td>1.157451</td>\n","      <td>3050000.0</td>\n","      <td>3072400.0</td>\n","      <td>3086100.0</td>\n","      <td>3243350.0</td>\n","      <td>3.215633e+06</td>\n","      <td>26.044568</td>\n","      <td>-50979.943691</td>\n","      <td>6.152363e+04</td>\n","      <td>...</td>\n","      <td>53.324172</td>\n","      <td>3.075397e+06</td>\n","      <td>3.115132e+06</td>\n","      <td>3.171588e+06</td>\n","      <td>3.183338e+06</td>\n","      <td>-1.897196e+09</td>\n","      <td>3.586173e+06</td>\n","      <td>3243350.0</td>\n","      <td>2.900527e+06</td>\n","      <td>5515.103573</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>14.915122</td>\n","      <td>1.139615</td>\n","      <td>3050000.0</td>\n","      <td>3060400.0</td>\n","      <td>3063700.0</td>\n","      <td>3223000.0</td>\n","      <td>3.214083e+06</td>\n","      <td>25.442177</td>\n","      <td>-51042.834596</td>\n","      <td>5.744241e+04</td>\n","      <td>...</td>\n","      <td>54.476339</td>\n","      <td>3.051264e+06</td>\n","      <td>3.094745e+06</td>\n","      <td>3.155532e+06</td>\n","      <td>3.177425e+06</td>\n","      <td>-1.473320e+09</td>\n","      <td>3.572426e+06</td>\n","      <td>3223000.0</td>\n","      <td>2.873574e+06</td>\n","      <td>4081.218313</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>3957</th>\n","      <td>16.920994</td>\n","      <td>19.407960</td>\n","      <td>22320000.0</td>\n","      <td>22490200.0</td>\n","      <td>22593100.0</td>\n","      <td>22691850.0</td>\n","      <td>2.493500e+07</td>\n","      <td>46.624136</td>\n","      <td>2341.093255</td>\n","      <td>1.475735e+06</td>\n","      <td>...</td>\n","      <td>53.458386</td>\n","      <td>2.245848e+07</td>\n","      <td>2.256368e+07</td>\n","      <td>2.277992e+07</td>\n","      <td>2.431527e+07</td>\n","      <td>-2.116684e+08</td>\n","      <td>2.316037e+07</td>\n","      <td>22691850.0</td>\n","      <td>2.222333e+07</td>\n","      <td>1666.680241</td>\n","    </tr>\n","    <tr>\n","      <th>3958</th>\n","      <td>16.924705</td>\n","      <td>19.480131</td>\n","      <td>22320000.0</td>\n","      <td>22430800.0</td>\n","      <td>22571300.0</td>\n","      <td>22662550.0</td>\n","      <td>2.482275e+07</td>\n","      <td>48.006214</td>\n","      <td>2346.997775</td>\n","      <td>1.477323e+06</td>\n","      <td>...</td>\n","      <td>53.335951</td>\n","      <td>2.243999e+07</td>\n","      <td>2.253446e+07</td>\n","      <td>2.274402e+07</td>\n","      <td>2.425257e+07</td>\n","      <td>-1.222620e+08</td>\n","      <td>2.312610e+07</td>\n","      <td>22662550.0</td>\n","      <td>2.219900e+07</td>\n","      <td>1587.817986</td>\n","    </tr>\n","    <tr>\n","      <th>3959</th>\n","      <td>16.951179</td>\n","      <td>19.480131</td>\n","      <td>23004000.0</td>\n","      <td>22496800.0</td>\n","      <td>22612900.0</td>\n","      <td>22660250.0</td>\n","      <td>2.472663e+07</td>\n","      <td>51.684312</td>\n","      <td>2391.934249</td>\n","      <td>1.478998e+06</td>\n","      <td>...</td>\n","      <td>43.927284</td>\n","      <td>2.262799e+07</td>\n","      <td>2.261983e+07</td>\n","      <td>2.276878e+07</td>\n","      <td>2.421164e+07</td>\n","      <td>1.172543e+08</td>\n","      <td>2.311609e+07</td>\n","      <td>22660250.0</td>\n","      <td>2.220441e+07</td>\n","      <td>1675.061266</td>\n","    </tr>\n","    <tr>\n","      <th>3960</th>\n","      <td>16.941832</td>\n","      <td>19.298913</td>\n","      <td>23004000.0</td>\n","      <td>22581400.0</td>\n","      <td>22618800.0</td>\n","      <td>22651250.0</td>\n","      <td>2.462907e+07</td>\n","      <td>47.797063</td>\n","      <td>2377.924759</td>\n","      <td>1.477492e+06</td>\n","      <td>...</td>\n","      <td>45.856043</td>\n","      <td>2.268200e+07</td>\n","      <td>2.265077e+07</td>\n","      <td>2.277080e+07</td>\n","      <td>2.416503e+07</td>\n","      <td>-1.490895e+08</td>\n","      <td>2.308805e+07</td>\n","      <td>22651250.0</td>\n","      <td>2.221445e+07</td>\n","      <td>1505.954700</td>\n","    </tr>\n","    <tr>\n","      <th>3961</th>\n","      <td>16.955213</td>\n","      <td>19.298913</td>\n","      <td>23097000.0</td>\n","      <td>22722800.0</td>\n","      <td>22648600.0</td>\n","      <td>22682950.0</td>\n","      <td>2.453300e+07</td>\n","      <td>51.084237</td>\n","      <td>2402.135900</td>\n","      <td>1.479290e+06</td>\n","      <td>...</td>\n","      <td>45.480344</td>\n","      <td>2.282033e+07</td>\n","      <td>2.273190e+07</td>\n","      <td>2.280187e+07</td>\n","      <td>2.413001e+07</td>\n","      <td>9.345974e+07</td>\n","      <td>2.315299e+07</td>\n","      <td>22682950.0</td>\n","      <td>2.221291e+07</td>\n","      <td>1797.302637</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3962 rows × 24 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-827d08ac-bbe7-49d4-a66f-739eac949d51')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-827d08ac-bbe7-49d4-a66f-739eac949d51 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-827d08ac-bbe7-49d4-a66f-739eac949d51');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":18}],"source":["feature"]},{"cell_type":"markdown","id":"19a7d92d","metadata":{"id":"19a7d92d"},"source":["# 표준화했던 값을 원래 값으로 되돌림"]},{"cell_type":"code","execution_count":19,"id":"d215843a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d215843a","executionInfo":{"status":"ok","timestamp":1669958191468,"user_tz":-540,"elapsed":32,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"8f3cd5e8-7738-492e-8d30-75fd62da4b9a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(763, 1)"]},"metadata":{},"execution_count":19}],"source":["log = feature.iloc[:feature.shape[0]-X_test.shape[0], 0].values\n","data_mean = log.mean(axis=0) \n","data_std = log.std(axis=0)\n","original = (predicted_stock_price)*data_std+data_mean\n","original.shape"]},{"cell_type":"code","execution_count":20,"id":"a17b1190","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a17b1190","executionInfo":{"status":"ok","timestamp":1669958191469,"user_tz":-540,"elapsed":31,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"bf2e814d-9366-4c39-b708-2b3f6ecc6401"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["3199"]},"metadata":{},"execution_count":20}],"source":["index = df.shape[0] - original.shape[0]\n","index"]},{"cell_type":"code","execution_count":21,"id":"fd7a4d8e","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fd7a4d8e","executionInfo":{"status":"ok","timestamp":1669958191470,"user_tz":-540,"elapsed":21,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"44f19c70-3ffd-4cd6-efbe-d04ed6c39cf0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["2.9325077649954987"]},"metadata":{},"execution_count":21}],"source":["y = feature.iloc[feature.shape[0]-X_test.shape[0]:, 1:2].values\n","rmse = np.sqrt(np.mean(((original - y) ** 2)))\n","rmse"]},{"cell_type":"code","execution_count":22,"id":"247bceb7","metadata":{"id":"247bceb7","executionInfo":{"status":"ok","timestamp":1669958191470,"user_tz":-540,"elapsed":11,"user":{"displayName":"구태형","userId":"12113658638621684006"}}},"outputs":[],"source":["def measure_accuarcy(predict, real = dataset_test.values[:,0], n_days=1):\n","    predict_result = []\n","    real_result = []\n","    count = 0\n","    result = 0\n","    correct_up = 0\n","    correct_down = 0\n","    real_up = 0\n","    real_down = 0\n","    \n","    n_predicting_days = predict.shape[0]-n_days\n","    \n","    for i in range(0,n_predicting_days):\n","        if predict[i] > predict[i+n_days]:\n","            result = 1\n","        else:\n","            result = 0\n","        predict_result.append(result)\n","    \n","    for i in range(0,n_predicting_days):\n","        if real[i] > real[i+n_days]:\n","            result = 1\n","        else:\n","            result = 0\n","        real_result.append(result)\n","        \n","    for i in range(0,n_predicting_days):\n","        if real_result[i]==1:\n","            real_up += 1\n","            if predict_result[i] ==1:\n","                correct_up += 1\n","        elif real_result[i]==0:\n","            if predict_result[i] == 0:\n","                correct_down += 1\n","                \n","    count = correct_up + correct_down\n","    \n","    return (count/n_predicting_days,correct_up,correct_down)"]},{"cell_type":"code","execution_count":23,"id":"5fa7acd2","metadata":{"id":"5fa7acd2","executionInfo":{"status":"ok","timestamp":1669958191936,"user_tz":-540,"elapsed":476,"user":{"displayName":"구태형","userId":"12113658638621684006"}}},"outputs":[],"source":["res.append(round(measure_accuarcy(original, n_days = 15)[0]  * 100,2))"]},{"cell_type":"code","execution_count":24,"id":"39180870","metadata":{"id":"39180870","executionInfo":{"status":"ok","timestamp":1669958191936,"user_tz":-540,"elapsed":7,"user":{"displayName":"구태형","userId":"12113658638621684006"}}},"outputs":[],"source":["def measure_diff(predict, real = dataset_test.values[:,0], n_days=1):\n","    \n","    predict_result = []\n","    real_result = []\n","    result = 0\n","    predict_diff = 0\n","    \n","    n_predicting_days = predict.shape[0]-n_days\n","    \n","    for i in range(0,n_predicting_days):\n","        if predict[i] > predict[i+n_days]:\n","            result = 1\n","        else:\n","            result = 0\n","        predict_result.append(result)\n","    \n","    for i in range(0,n_predicting_days):\n","        if real[i] > real[i+n_days]:\n","            result = 1\n","        else:\n","            result = 0\n","        real_result.append(result)\n","        \n","    for i in range(0,n_predicting_days):\n","        if real_result[i]==predict_result[i]:\n","            predict_diff += abs(predict[i]-real[i])\n","        else:\n","            predict_diff -= abs(predict[i]-real[i])\n","    \n","    return predict_diff"]},{"cell_type":"code","execution_count":25,"id":"582943e7","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"582943e7","executionInfo":{"status":"ok","timestamp":1669958191937,"user_tz":-540,"elapsed":8,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"d4685597-c903-461f-c339-ab65156d91d3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([17.290388], dtype=float32)"]},"metadata":{},"execution_count":25}],"source":["measure_diff(original, n_days = 15)"]},{"cell_type":"code","source":["model2 = Sequential()\n","\n","#Adding the first LSTM layer and some Dropout regularisation\n","\n","model2.add(LSTM(units = 100, return_sequences = True, input_shape = (X_train.shape[-2:])))\n","\n","model2.add(LSTM(100, return_sequences=True))\n","model2.add(Dropout(0.8))\n","\n","\n","model2.add(LSTM(100, return_sequences=True))\n","model2.add(Dropout(0.8))\n","\n","#model2.add(RepeatVector(time_step))\n","\n","# Adding a second LSTM layer and some Dropout regularisation\n","\n","model2.add(LSTM(units = 100, return_sequences = True))\n","model2.add(Dropout(0.8))\n","\n","# Adding a third LSTM layer and some Dropout regularisation\n","\n","model2.add(LSTM(units = 60, return_sequences = True))\n","model2.add(Dropout(0.8))\n","\n","model2.add(LSTM(units = 60, return_sequences = True))\n","model2.add(Dropout(0.8))\n","\n","\n","model2.add(LSTM(units = 60, return_sequences = True))\n","model2.add(Dropout(0.8))\n","\n","# Adding a fourth LSTM layer and some Dropout regularisation\n","\n","model2.add(LSTM(units = 60))\n","model2.add(Dropout(0.8))\n","\n","\n","# Adding the output layer i \n"," \n","model2.add(Dense(units = 1))\n","\n","# Compiling the RNN\n","\n","model2.compile(optimizer = 'adam' , loss = 'mean_squared_error' )\n","\n","# Fitting the RNN to the Training set\n","\n","model2.fit(X_train, y_train, epochs = 80, batch_size = 32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vDMdXROao0UC","executionInfo":{"status":"ok","timestamp":1669958353648,"user_tz":-540,"elapsed":161717,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"ef787172-b4b8-4a4e-9b4e-a319f4208af1"},"id":"vDMdXROao0UC","execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/80\n","98/98 [==============================] - 12s 19ms/step - loss: 0.2848\n","Epoch 2/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.1652\n","Epoch 3/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.1429\n","Epoch 4/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.1392\n","Epoch 5/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.1213\n","Epoch 6/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.1125\n","Epoch 7/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.1166\n","Epoch 8/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.1082\n","Epoch 9/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.1081\n","Epoch 10/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.1090\n","Epoch 11/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.1060\n","Epoch 12/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.1060\n","Epoch 13/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0991\n","Epoch 14/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0988\n","Epoch 15/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0924\n","Epoch 16/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.1026\n","Epoch 17/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0980\n","Epoch 18/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0976\n","Epoch 19/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0919\n","Epoch 20/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0941\n","Epoch 21/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0937\n","Epoch 22/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0916\n","Epoch 23/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0844\n","Epoch 24/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0898\n","Epoch 25/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0861\n","Epoch 26/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0916\n","Epoch 27/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0879\n","Epoch 28/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0861\n","Epoch 29/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0859\n","Epoch 30/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0904\n","Epoch 31/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0872\n","Epoch 32/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0822\n","Epoch 33/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0841\n","Epoch 34/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0879\n","Epoch 35/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0833\n","Epoch 36/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0887\n","Epoch 37/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0929\n","Epoch 38/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0832\n","Epoch 39/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0873\n","Epoch 40/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0832\n","Epoch 41/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0826\n","Epoch 42/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0831\n","Epoch 43/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0813\n","Epoch 44/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0801\n","Epoch 45/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0894\n","Epoch 46/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0838\n","Epoch 47/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0884\n","Epoch 48/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0837\n","Epoch 49/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0872\n","Epoch 50/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0792\n","Epoch 51/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0824\n","Epoch 52/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0798\n","Epoch 53/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0847\n","Epoch 54/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0806\n","Epoch 55/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0849\n","Epoch 56/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0847\n","Epoch 57/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0825\n","Epoch 58/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0773\n","Epoch 59/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0805\n","Epoch 60/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0837\n","Epoch 61/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0826\n","Epoch 62/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0788\n","Epoch 63/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0830\n","Epoch 64/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0792\n","Epoch 65/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0759\n","Epoch 66/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0846\n","Epoch 67/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0871\n","Epoch 68/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0791\n","Epoch 69/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0786\n","Epoch 70/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0840\n","Epoch 71/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0793\n","Epoch 72/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0800\n","Epoch 73/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0745\n","Epoch 74/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0781\n","Epoch 75/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0764\n","Epoch 76/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0775\n","Epoch 77/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0803\n","Epoch 78/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0826\n","Epoch 79/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0838\n","Epoch 80/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0773\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f55938281c0>"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["predicted_stock_price = model2.predict(X_test)\n","log = feature.iloc[:feature.shape[0]-X_test.shape[0], 0].values\n","data_mean = log.mean(axis=0) \n","data_std = log.std(axis=0)\n","original = (predicted_stock_price)*data_std+data_mean\n","\n","y = feature.iloc[feature.shape[0]-X_test.shape[0]:, 1:2].values\n","rmse = np.sqrt(np.mean(((original - y) ** 2)))\n","print(rmse)\n","\n","res.append(round(measure_accuarcy(original, n_days = 15)[0]  * 100,2))\n","print(measure_diff(original, n_days = 15))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ogi_-BlGocGM","executionInfo":{"status":"ok","timestamp":1669958356402,"user_tz":-540,"elapsed":2759,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"3f2d2d40-5372-4418-a599-11eea679075b"},"id":"ogi_-BlGocGM","execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["24/24 [==============================] - 2s 8ms/step\n","2.8892639856584084\n","[28.809021]\n"]}]},{"cell_type":"code","source":["model3 = Sequential()\n","\n","#Adding the first LSTM layer and some Dropout regularisation\n","\n","model3.add(LSTM(units = 100, return_sequences = True, input_shape = (X_train.shape[-2:])))\n","\n","model3.add(LSTM(100, return_sequences=True))\n","model3.add(Dropout(0.4))\n","\n","\n","model3.add(LSTM(100, return_sequences=True))\n","model3.add(Dropout(0.4))\n","\n","#model3.add(RepeatVector(time_step))\n","\n","# Adding a second LSTM layer and some Dropout regularisation\n","\n","model3.add(LSTM(units = 100, return_sequences = True))\n","model3.add(Dropout(0.4))\n","\n","# Adding a third LSTM layer and some Dropout regularisation\n","\n","model3.add(LSTM(units = 100, return_sequences = True))\n","model3.add(Dropout(0.4))\n","\n","model3.add(LSTM(units = 100, return_sequences = True))\n","model3.add(Dropout(0.4))\n","\n","\n","model3.add(LSTM(units = 100, return_sequences = True))\n","model3.add(Dropout(0.4))\n","\n","# Adding a fourth LSTM layer and some Dropout regularisation\n","\n","model3.add(LSTM(units = 100))\n","model3.add(Dropout(0.4))\n","\n","\n","# Adding the output layer i \n"," \n","model3.add(Dense(units = 1))\n","\n","# Compiling the RNN\n","\n","model3.compile(optimizer = 'adam' , loss = 'mean_squared_error' )\n","\n","# Fitting the RNN to the Training set\n","\n","model3.fit(X_train, y_train, epochs = 80, batch_size = 32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QHT0GA8Jl-2N","executionInfo":{"status":"ok","timestamp":1669958523027,"user_tz":-540,"elapsed":166628,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"e262850a-0633-4317-81b1-157f68b9aead"},"id":"QHT0GA8Jl-2N","execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/80\n","98/98 [==============================] - 12s 20ms/step - loss: 0.1245\n","Epoch 2/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0577\n","Epoch 3/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0466\n","Epoch 4/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0429\n","Epoch 5/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0379\n","Epoch 6/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0339\n","Epoch 7/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0306\n","Epoch 8/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0292\n","Epoch 9/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0316\n","Epoch 10/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0274\n","Epoch 11/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0268\n","Epoch 12/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0257\n","Epoch 13/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0247\n","Epoch 14/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0233\n","Epoch 15/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0216\n","Epoch 16/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0239\n","Epoch 17/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0195\n","Epoch 18/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0190\n","Epoch 19/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0191\n","Epoch 20/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0196\n","Epoch 21/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0170\n","Epoch 22/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0183\n","Epoch 23/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0174\n","Epoch 24/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0184\n","Epoch 25/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0174\n","Epoch 26/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0193\n","Epoch 27/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0172\n","Epoch 28/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0165\n","Epoch 29/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0162\n","Epoch 30/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0161\n","Epoch 31/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0163\n","Epoch 32/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0167\n","Epoch 33/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0153\n","Epoch 34/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0156\n","Epoch 35/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0154\n","Epoch 36/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0162\n","Epoch 37/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0172\n","Epoch 38/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0166\n","Epoch 39/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0161\n","Epoch 40/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0152\n","Epoch 41/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0140\n","Epoch 42/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0144\n","Epoch 43/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0141\n","Epoch 44/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0148\n","Epoch 45/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0139\n","Epoch 46/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0145\n","Epoch 47/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0147\n","Epoch 48/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0137\n","Epoch 49/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0137\n","Epoch 50/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0142\n","Epoch 51/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0159\n","Epoch 52/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0128\n","Epoch 53/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0131\n","Epoch 54/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0199\n","Epoch 55/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0155\n","Epoch 56/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0150\n","Epoch 57/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0139\n","Epoch 58/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0137\n","Epoch 59/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0144\n","Epoch 60/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0145\n","Epoch 61/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0133\n","Epoch 62/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0127\n","Epoch 63/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0126\n","Epoch 64/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0141\n","Epoch 65/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0148\n","Epoch 66/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0149\n","Epoch 67/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0139\n","Epoch 68/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0147\n","Epoch 69/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0132\n","Epoch 70/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0128\n","Epoch 71/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0129\n","Epoch 72/80\n","98/98 [==============================] - 2s 21ms/step - loss: 0.0116\n","Epoch 73/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0122\n","Epoch 74/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0132\n","Epoch 75/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0133\n","Epoch 76/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0132\n","Epoch 77/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0152\n","Epoch 78/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0140\n","Epoch 79/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0128\n","Epoch 80/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0126\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f55934df040>"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["predicted_stock_price = model3.predict(X_test)\n","log = feature.iloc[:feature.shape[0]-X_test.shape[0], 0].values\n","data_mean = log.mean(axis=0) \n","data_std = log.std(axis=0)\n","original = (predicted_stock_price)*data_std+data_mean\n","\n","y = feature.iloc[feature.shape[0]-X_test.shape[0]:, 1:2].values\n","rmse = np.sqrt(np.mean(((original - y) ** 2)))\n","print(rmse)\n","\n","res.append(round(measure_accuarcy(original, n_days = 15)[0]  * 100,2))\n","print(measure_diff(original, n_days = 15))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TbwYo0tEpJ1K","executionInfo":{"status":"ok","timestamp":1669958525380,"user_tz":-540,"elapsed":2359,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"4d2b35da-a14b-4181-b585-a87f51932787"},"id":"TbwYo0tEpJ1K","execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["24/24 [==============================] - 2s 8ms/step\n","2.8358246729206904\n","[35.618885]\n"]}]},{"cell_type":"code","source":["model4 = Sequential()\n","\n","#Adding the first LSTM layer and some Dropout regularisation\n","\n","model4.add(LSTM(units = 100, return_sequences = True, input_shape = (X_train.shape[-2:])))\n","\n","model4.add(LSTM(100, return_sequences=True))\n","model4.add(Dropout(0.8))\n","\n","\n","model4.add(LSTM(100, return_sequences=True))\n","model4.add(Dropout(0.8))\n","\n","#model4.add(RepeatVector(time_step))\n","\n","# Adding a second LSTM layer and some Dropout regularisation\n","\n","model4.add(LSTM(units = 100, return_sequences = True))\n","model4.add(Dropout(0.8))\n","\n","# Adding a third LSTM layer and some Dropout regularisation\n","\n","model4.add(LSTM(units = 100, return_sequences = True))\n","model4.add(Dropout(0.8))\n","\n","model4.add(LSTM(units = 100, return_sequences = True))\n","model4.add(Dropout(0.8))\n","\n","\n","model4.add(LSTM(units = 100, return_sequences = True))\n","model4.add(Dropout(0.8))\n","\n","# Adding a fourth LSTM layer and some Dropout regularisation\n","\n","model4.add(LSTM(units = 100))\n","model4.add(Dropout(0.8))\n","\n","\n","# Adding the output layer i \n"," \n","model4.add(Dense(units = 1))\n","\n","# Compiling the RNN\n","\n","model4.compile(optimizer = 'adam' , loss = 'mean_squared_error' )\n","\n","# Fitting the RNN to the Training set\n","\n","model4.fit(X_train, y_train, epochs = 80, batch_size = 32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ctnFEGs9pKuH","executionInfo":{"status":"ok","timestamp":1669958691187,"user_tz":-540,"elapsed":165310,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"ca452943-b3a3-4749-c098-f24f22ff7656"},"id":"ctnFEGs9pKuH","execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/80\n","98/98 [==============================] - 12s 20ms/step - loss: 0.2473\n","Epoch 2/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.1447\n","Epoch 3/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.1156\n","Epoch 4/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.1009\n","Epoch 5/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0983\n","Epoch 6/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0973\n","Epoch 7/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0970\n","Epoch 8/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0853\n","Epoch 9/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0792\n","Epoch 10/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0845\n","Epoch 11/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0815\n","Epoch 12/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0743\n","Epoch 13/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0794\n","Epoch 14/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0700\n","Epoch 15/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0739\n","Epoch 16/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0675\n","Epoch 17/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0673\n","Epoch 18/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0694\n","Epoch 19/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0659\n","Epoch 20/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0673\n","Epoch 21/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0705\n","Epoch 22/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0663\n","Epoch 23/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0689\n","Epoch 24/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0704\n","Epoch 25/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0643\n","Epoch 26/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0701\n","Epoch 27/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0657\n","Epoch 28/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0660\n","Epoch 29/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0654\n","Epoch 30/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0635\n","Epoch 31/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0641\n","Epoch 32/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0634\n","Epoch 33/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0597\n","Epoch 34/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0618\n","Epoch 35/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0642\n","Epoch 36/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0623\n","Epoch 37/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0592\n","Epoch 38/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0587\n","Epoch 39/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0601\n","Epoch 40/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0648\n","Epoch 41/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0527\n","Epoch 42/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0595\n","Epoch 43/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0599\n","Epoch 44/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0597\n","Epoch 45/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0607\n","Epoch 46/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0546\n","Epoch 47/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0603\n","Epoch 48/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0538\n","Epoch 49/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0527\n","Epoch 50/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0575\n","Epoch 51/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0589\n","Epoch 52/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0588\n","Epoch 53/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0579\n","Epoch 54/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0597\n","Epoch 55/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0587\n","Epoch 56/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0554\n","Epoch 57/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0569\n","Epoch 58/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0556\n","Epoch 59/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0591\n","Epoch 60/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0547\n","Epoch 61/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0540\n","Epoch 62/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0528\n","Epoch 63/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0548\n","Epoch 64/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0549\n","Epoch 65/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0591\n","Epoch 66/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0625\n","Epoch 67/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0541\n","Epoch 68/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0598\n","Epoch 69/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0518\n","Epoch 70/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0557\n","Epoch 71/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0494\n","Epoch 72/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0535\n","Epoch 73/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0530\n","Epoch 74/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0536\n","Epoch 75/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0566\n","Epoch 76/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0581\n","Epoch 77/80\n","98/98 [==============================] - 2s 19ms/step - loss: 0.0555\n","Epoch 78/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0576\n","Epoch 79/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0558\n","Epoch 80/80\n","98/98 [==============================] - 2s 20ms/step - loss: 0.0541\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f55931099a0>"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["predicted_stock_price = model4.predict(X_test)\n","log = feature.iloc[:feature.shape[0]-X_test.shape[0], 0].values\n","data_mean = log.mean(axis=0) \n","data_std = log.std(axis=0)\n","original = (predicted_stock_price)*data_std+data_mean\n","\n","y = feature.iloc[feature.shape[0]-X_test.shape[0]:, 1:2].values\n","rmse = np.sqrt(np.mean(((original - y) ** 2)))\n","print(rmse)\n","\n","res.append(round(measure_accuarcy(original, n_days = 15)[0]  * 100,2))\n","print(measure_diff(original, n_days = 15))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jLwhAHLgpMTR","executionInfo":{"status":"ok","timestamp":1669958693673,"user_tz":-540,"elapsed":2490,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"4e0be511-9d29-4334-e50a-f8297c358267"},"id":"jLwhAHLgpMTR","execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["24/24 [==============================] - 2s 8ms/step\n","2.918148628651311\n","[1.2399864]\n"]}]},{"cell_type":"code","source":["model5 = Sequential()\n","\n","#Adding the first LSTM layer and some Dropout regularisation\n","\n","model5.add(LSTM(units = 100, return_sequences = True, input_shape = (X_train.shape[-2:])))\n","\n","model5.add(LSTM(100, return_sequences=True))\n","model5.add(Dropout(0.4))\n","\n","#model5.add(RepeatVector(time_step))\n","\n","# Adding a second LSTM layer and some Dropout regularisation\n","\n","model5.add(LSTM(units = 100, return_sequences = True))\n","model5.add(Dropout(0.4))\n","\n","# Adding a third LSTM layer and some Dropout regularisation\n","\n","model5.add(LSTM(units = 60, return_sequences = True))\n","model5.add(Dropout(0.4))\n","\n","model5.add(LSTM(units = 60, return_sequences = True))\n","model5.add(Dropout(0.4))\n","\n","# Adding a fourth LSTM layer and some Dropout regularisation\n","\n","model5.add(LSTM(units = 60))\n","model5.add(Dropout(0.4))\n","\n","# Adding the output layer i \n"," \n","model5.add(Dense(units = 1))\n","\n","# Compiling the RNN\n","\n","model5.compile(optimizer = 'adam' , loss = 'mean_squared_error' )\n","\n","# Fitting the RNN to the Training set\n","\n","model5.fit(X_train, y_train, epochs = 80, batch_size = 32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kO6GLkFfpbML","executionInfo":{"status":"ok","timestamp":1669958815989,"user_tz":-540,"elapsed":122320,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"bbe56df5-580f-418d-a290-fdb833eaaf9d"},"id":"kO6GLkFfpbML","execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/80\n","98/98 [==============================] - 9s 15ms/step - loss: 0.1086\n","Epoch 2/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0534\n","Epoch 3/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0427\n","Epoch 4/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0398\n","Epoch 5/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0356\n","Epoch 6/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0334\n","Epoch 7/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0328\n","Epoch 8/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0308\n","Epoch 9/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0323\n","Epoch 10/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0282\n","Epoch 11/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0304\n","Epoch 12/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0266\n","Epoch 13/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0276\n","Epoch 14/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0251\n","Epoch 15/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0264\n","Epoch 16/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0247\n","Epoch 17/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0220\n","Epoch 18/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0224\n","Epoch 19/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0243\n","Epoch 20/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0229\n","Epoch 21/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0223\n","Epoch 22/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0225\n","Epoch 23/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0223\n","Epoch 24/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0206\n","Epoch 25/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0212\n","Epoch 26/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0226\n","Epoch 27/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0214\n","Epoch 28/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0201\n","Epoch 29/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0196\n","Epoch 30/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0221\n","Epoch 31/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0199\n","Epoch 32/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0206\n","Epoch 33/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0190\n","Epoch 34/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0191\n","Epoch 35/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0213\n","Epoch 36/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0195\n","Epoch 37/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0189\n","Epoch 38/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0191\n","Epoch 39/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0201\n","Epoch 40/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0191\n","Epoch 41/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0199\n","Epoch 42/80\n","98/98 [==============================] - 2s 15ms/step - loss: 0.0185\n","Epoch 43/80\n","98/98 [==============================] - 2s 15ms/step - loss: 0.0171\n","Epoch 44/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0177\n","Epoch 45/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0193\n","Epoch 46/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0186\n","Epoch 47/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0172\n","Epoch 48/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0178\n","Epoch 49/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0198\n","Epoch 50/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0179\n","Epoch 51/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0188\n","Epoch 52/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0184\n","Epoch 53/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0164\n","Epoch 54/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0177\n","Epoch 55/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0180\n","Epoch 56/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0163\n","Epoch 57/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0186\n","Epoch 58/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0174\n","Epoch 59/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0169\n","Epoch 60/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0167\n","Epoch 61/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0189\n","Epoch 62/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0175\n","Epoch 63/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0161\n","Epoch 64/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0171\n","Epoch 65/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0157\n","Epoch 66/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0179\n","Epoch 67/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0166\n","Epoch 68/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0167\n","Epoch 69/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0181\n","Epoch 70/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0153\n","Epoch 71/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0182\n","Epoch 72/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0176\n","Epoch 73/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0170\n","Epoch 74/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0153\n","Epoch 75/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0168\n","Epoch 76/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0166\n","Epoch 77/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0153\n","Epoch 78/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0165\n","Epoch 79/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0154\n","Epoch 80/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0167\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f558fd14430>"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["predicted_stock_price = model5.predict(X_test)\n","log = feature.iloc[:feature.shape[0]-X_test.shape[0], 0].values\n","data_mean = log.mean(axis=0) \n","data_std = log.std(axis=0)\n","original = (predicted_stock_price)*data_std+data_mean\n","\n","y = feature.iloc[feature.shape[0]-X_test.shape[0]:, 1:2].values\n","rmse = np.sqrt(np.mean(((original - y) ** 2)))\n","print(rmse)\n","\n","res.append(round(measure_accuarcy(original, n_days = 15)[0]  * 100,2))\n","print(measure_diff(original, n_days = 15))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wq7tPxaYpOyC","executionInfo":{"status":"ok","timestamp":1669958818334,"user_tz":-540,"elapsed":2352,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"594e0262-afff-445f-c66b-32f4754ca07b"},"id":"Wq7tPxaYpOyC","execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["24/24 [==============================] - 2s 6ms/step\n","2.920311683913218\n","[45.448383]\n"]}]},{"cell_type":"code","source":["model6 = Sequential()\n","\n","#Adding the first LSTM layer and some Dropout regularisation\n","\n","model6.add(LSTM(units = 100, return_sequences = True, input_shape = (X_train.shape[-2:])))\n","\n","model6.add(LSTM(100, return_sequences=True))\n","model6.add(Dropout(0.8))\n","\n","#model6.add(RepeatVector(time_step))\n","\n","# Adding a second LSTM layer and some Dropout regularisation\n","\n","model6.add(LSTM(units = 100, return_sequences = True))\n","model6.add(Dropout(0.8))\n","\n","# Adding a third LSTM layer and some Dropout regularisation\n","\n","model6.add(LSTM(units = 60, return_sequences = True))\n","model6.add(Dropout(0.8))\n","\n","model6.add(LSTM(units = 60, return_sequences = True))\n","model6.add(Dropout(0.8))\n","\n","# Adding a fourth LSTM layer and some Dropout regularisation\n","\n","model6.add(LSTM(units = 60))\n","model6.add(Dropout(0.8))\n","\n","# Adding the output layer i \n"," \n","model6.add(Dense(units = 1))\n","\n","# Compiling the RNN\n","\n","model6.compile(optimizer = 'adam' , loss = 'mean_squared_error' )\n","\n","# Fitting the RNN to the Training set\n","\n","model6.fit(X_train, y_train, epochs = 80, batch_size = 32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ns1HZyLBmbye","executionInfo":{"status":"ok","timestamp":1669958945186,"user_tz":-540,"elapsed":126855,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"3cae934e-86dd-4d08-a932-c8e7edd631d5"},"id":"Ns1HZyLBmbye","execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/80\n","98/98 [==============================] - 9s 14ms/step - loss: 0.2497\n","Epoch 2/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.1542\n","Epoch 3/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.1316\n","Epoch 4/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.1142\n","Epoch 5/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.1127\n","Epoch 6/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.1046\n","Epoch 7/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.1026\n","Epoch 8/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.1045\n","Epoch 9/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.1073\n","Epoch 10/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.1029\n","Epoch 11/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.1044\n","Epoch 12/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.1043\n","Epoch 13/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0955\n","Epoch 14/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0924\n","Epoch 15/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0887\n","Epoch 16/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0924\n","Epoch 17/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0933\n","Epoch 18/80\n","98/98 [==============================] - 1s 14ms/step - loss: 0.0871\n","Epoch 19/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0898\n","Epoch 20/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0917\n","Epoch 21/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0864\n","Epoch 22/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0869\n","Epoch 23/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0863\n","Epoch 24/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0860\n","Epoch 25/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0858\n","Epoch 26/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0890\n","Epoch 27/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0907\n","Epoch 28/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0948\n","Epoch 29/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0891\n","Epoch 30/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0880\n","Epoch 31/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0855\n","Epoch 32/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0874\n","Epoch 33/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0840\n","Epoch 34/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0851\n","Epoch 35/80\n","98/98 [==============================] - 2s 15ms/step - loss: 0.0848\n","Epoch 36/80\n","98/98 [==============================] - 2s 15ms/step - loss: 0.0805\n","Epoch 37/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0813\n","Epoch 38/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0826\n","Epoch 39/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0852\n","Epoch 40/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0786\n","Epoch 41/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0804\n","Epoch 42/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0802\n","Epoch 43/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0851\n","Epoch 44/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0860\n","Epoch 45/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0878\n","Epoch 46/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0827\n","Epoch 47/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0799\n","Epoch 48/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0852\n","Epoch 49/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0804\n","Epoch 50/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0838\n","Epoch 51/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0750\n","Epoch 52/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0809\n","Epoch 53/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0780\n","Epoch 54/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0814\n","Epoch 55/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0740\n","Epoch 56/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0745\n","Epoch 57/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0789\n","Epoch 58/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0760\n","Epoch 59/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0774\n","Epoch 60/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0742\n","Epoch 61/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0875\n","Epoch 62/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0768\n","Epoch 63/80\n","98/98 [==============================] - 2s 15ms/step - loss: 0.0740\n","Epoch 64/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0831\n","Epoch 65/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0796\n","Epoch 66/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0862\n","Epoch 67/80\n","98/98 [==============================] - 2s 15ms/step - loss: 0.0791\n","Epoch 68/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0791\n","Epoch 69/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0777\n","Epoch 70/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0781\n","Epoch 71/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0804\n","Epoch 72/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0769\n","Epoch 73/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0803\n","Epoch 74/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0787\n","Epoch 75/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0739\n","Epoch 76/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0835\n","Epoch 77/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0758\n","Epoch 78/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0798\n","Epoch 79/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0755\n","Epoch 80/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0848\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f558fad5820>"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["predicted_stock_price = model6.predict(X_test)\n","log = feature.iloc[:feature.shape[0]-X_test.shape[0], 0].values\n","data_mean = log.mean(axis=0) \n","data_std = log.std(axis=0)\n","original = (predicted_stock_price)*data_std+data_mean\n","\n","y = feature.iloc[feature.shape[0]-X_test.shape[0]:, 1:2].values\n","rmse = np.sqrt(np.mean(((original - y) ** 2)))\n","print(rmse)\n","\n","res.append(round(measure_accuarcy(original, n_days = 15)[0]  * 100,2))\n","print(measure_diff(original, n_days = 15))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yATUUjsopQmt","executionInfo":{"status":"ok","timestamp":1669958947184,"user_tz":-540,"elapsed":2009,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"3d336fee-e26b-4b13-b28c-60e7b3ef6fde"},"id":"yATUUjsopQmt","execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["24/24 [==============================] - 2s 6ms/step\n","2.986405803738902\n","[12.6847515]\n"]}]},{"cell_type":"code","source":["model7 = Sequential()\n","\n","#Adding the first LSTM layer and some Dropout regularisation\n","\n","model7.add(LSTM(units = 100, return_sequences = True, input_shape = (X_train.shape[-2:])))\n","\n","model7.add(LSTM(100, return_sequences=True))\n","model7.add(Dropout(0.4))\n","\n","#model7.add(RepeatVector(time_step))\n","\n","# Adding a second LSTM layer and some Dropout regularisation\n","\n","model7.add(LSTM(units = 100, return_sequences = True))\n","model7.add(Dropout(0.4))\n","\n","# Adding a third LSTM layer and some Dropout regularisation\n","\n","model7.add(LSTM(units = 100, return_sequences = True))\n","model7.add(Dropout(0.4))\n","\n","model7.add(LSTM(units = 100, return_sequences = True))\n","model7.add(Dropout(0.4))\n","\n","# Adding a fourth LSTM layer and some Dropout regularisation\n","\n","model7.add(LSTM(units = 100))\n","model7.add(Dropout(0.4))\n","\n","# Adding the output layer i \n"," \n","model7.add(Dense(units = 1))\n","\n","# Compiling the RNN\n","\n","model7.compile(optimizer = 'adam' , loss = 'mean_squared_error' )\n","\n","# Fitting the RNN to the Training set\n","\n","model7.fit(X_train, y_train, epochs = 80, batch_size = 32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dL7f0ZjYp2F2","executionInfo":{"status":"ok","timestamp":1669959078638,"user_tz":-540,"elapsed":131459,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"29d6f79f-33bc-4d9f-a727-5a8a805c7e81"},"id":"dL7f0ZjYp2F2","execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/80\n","98/98 [==============================] - 9s 16ms/step - loss: 0.1164\n","Epoch 2/80\n","98/98 [==============================] - 2s 15ms/step - loss: 0.0472\n","Epoch 3/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0404\n","Epoch 4/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0371\n","Epoch 5/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0335\n","Epoch 6/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0336\n","Epoch 7/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0272\n","Epoch 8/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0281\n","Epoch 9/80\n","98/98 [==============================] - 2s 15ms/step - loss: 0.0240\n","Epoch 10/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0247\n","Epoch 11/80\n","98/98 [==============================] - 2s 15ms/step - loss: 0.0254\n","Epoch 12/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0217\n","Epoch 13/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0231\n","Epoch 14/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0215\n","Epoch 15/80\n","98/98 [==============================] - 2s 15ms/step - loss: 0.0211\n","Epoch 16/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0196\n","Epoch 17/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0189\n","Epoch 18/80\n","98/98 [==============================] - 2s 15ms/step - loss: 0.0181\n","Epoch 19/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0175\n","Epoch 20/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0175\n","Epoch 21/80\n","98/98 [==============================] - 2s 15ms/step - loss: 0.0173\n","Epoch 22/80\n","98/98 [==============================] - 2s 15ms/step - loss: 0.0185\n","Epoch 23/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0166\n","Epoch 24/80\n","98/98 [==============================] - 2s 15ms/step - loss: 0.0156\n","Epoch 25/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0182\n","Epoch 26/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0165\n","Epoch 27/80\n","98/98 [==============================] - 2s 15ms/step - loss: 0.0155\n","Epoch 28/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0178\n","Epoch 29/80\n","98/98 [==============================] - 2s 15ms/step - loss: 0.0165\n","Epoch 30/80\n","98/98 [==============================] - 2s 15ms/step - loss: 0.0157\n","Epoch 31/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0147\n","Epoch 32/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0151\n","Epoch 33/80\n","98/98 [==============================] - 2s 15ms/step - loss: 0.0141\n","Epoch 34/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0158\n","Epoch 35/80\n","98/98 [==============================] - 2s 15ms/step - loss: 0.0157\n","Epoch 36/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0159\n","Epoch 37/80\n","98/98 [==============================] - 2s 15ms/step - loss: 0.0139\n","Epoch 38/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0160\n","Epoch 39/80\n","98/98 [==============================] - 2s 15ms/step - loss: 0.0133\n","Epoch 40/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0145\n","Epoch 41/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0139\n","Epoch 42/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0128\n","Epoch 43/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0142\n","Epoch 44/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0138\n","Epoch 45/80\n","98/98 [==============================] - 2s 15ms/step - loss: 0.0143\n","Epoch 46/80\n","98/98 [==============================] - 2s 15ms/step - loss: 0.0149\n","Epoch 47/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0126\n","Epoch 48/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0111\n","Epoch 49/80\n","98/98 [==============================] - 2s 15ms/step - loss: 0.0121\n","Epoch 50/80\n","98/98 [==============================] - 2s 15ms/step - loss: 0.0136\n","Epoch 51/80\n","98/98 [==============================] - 2s 15ms/step - loss: 0.0127\n","Epoch 52/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0126\n","Epoch 53/80\n","98/98 [==============================] - 2s 15ms/step - loss: 0.0126\n","Epoch 54/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0123\n","Epoch 55/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0145\n","Epoch 56/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0129\n","Epoch 57/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0127\n","Epoch 58/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0145\n","Epoch 59/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0144\n","Epoch 60/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0139\n","Epoch 61/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0122\n","Epoch 62/80\n","98/98 [==============================] - 2s 15ms/step - loss: 0.0114\n","Epoch 63/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0123\n","Epoch 64/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0121\n","Epoch 65/80\n","98/98 [==============================] - 2s 15ms/step - loss: 0.0129\n","Epoch 66/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0127\n","Epoch 67/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0129\n","Epoch 68/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0115\n","Epoch 69/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0115\n","Epoch 70/80\n","98/98 [==============================] - 2s 17ms/step - loss: 0.0113\n","Epoch 71/80\n","98/98 [==============================] - 2s 15ms/step - loss: 0.0126\n","Epoch 72/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0134\n","Epoch 73/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0116\n","Epoch 74/80\n","98/98 [==============================] - 2s 15ms/step - loss: 0.0108\n","Epoch 75/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0133\n","Epoch 76/80\n","98/98 [==============================] - 2s 15ms/step - loss: 0.0121\n","Epoch 77/80\n","98/98 [==============================] - 2s 15ms/step - loss: 0.0123\n","Epoch 78/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0158\n","Epoch 79/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0135\n","Epoch 80/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0128\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f558f6ab130>"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":["predicted_stock_price = model7.predict(X_test)\n","log = feature.iloc[:feature.shape[0]-X_test.shape[0], 0].values\n","data_mean = log.mean(axis=0) \n","data_std = log.std(axis=0)\n","original = (predicted_stock_price)*data_std+data_mean\n","\n","y = feature.iloc[feature.shape[0]-X_test.shape[0]:, 1:2].values\n","rmse = np.sqrt(np.mean(((original - y) ** 2)))\n","print(rmse)\n","\n","res.append(round(measure_accuarcy(original, n_days = 15)[0]  * 100,2))\n","print(measure_diff(original, n_days = 15))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8md7FX03pTK6","executionInfo":{"status":"ok","timestamp":1669959080073,"user_tz":-540,"elapsed":1442,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"beac0670-d56b-43ba-9eb5-6bca466dd2f4"},"id":"8md7FX03pTK6","execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["24/24 [==============================] - 2s 6ms/step\n","2.892589331581533\n","[8.5868225]\n"]}]},{"cell_type":"code","source":["model8 = Sequential()\n","\n","#Adding the first LSTM layer and some Dropout regularisation\n","\n","model8.add(LSTM(units = 100, return_sequences = True, input_shape = (X_train.shape[-2:])))\n","\n","model8.add(LSTM(100, return_sequences=True))\n","model8.add(Dropout(0.8))\n","\n","#model8.add(RepeatVector(time_step))\n","\n","# Adding a second LSTM layer and some Dropout regularisation\n","\n","model8.add(LSTM(units = 100, return_sequences = True))\n","model8.add(Dropout(0.8))\n","\n","# Adding a third LSTM layer and some Dropout regularisation\n","\n","model8.add(LSTM(units = 100, return_sequences = True))\n","model8.add(Dropout(0.8))\n","\n","model8.add(LSTM(units = 100, return_sequences = True))\n","model8.add(Dropout(0.8))\n","\n","# Adding a fourth LSTM layer and some Dropout regularisation\n","\n","model8.add(LSTM(units = 100))\n","model8.add(Dropout(0.8))\n","\n","# Adding the output layer i \n"," \n","model8.add(Dense(units = 1))\n","\n","# Compiling the RNN\n","\n","model8.compile(optimizer = 'adam' , loss = 'mean_squared_error' )\n","\n","# Fitting the RNN to the Training set\n","\n","model8.fit(X_train, y_train, epochs = 80, batch_size = 32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UgfuXRWXmwXm","executionInfo":{"status":"ok","timestamp":1669959208581,"user_tz":-540,"elapsed":128512,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"d4f8211a-fc64-4c38-af5e-5b4b4d789004"},"id":"UgfuXRWXmwXm","execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/80\n","98/98 [==============================] - 9s 15ms/step - loss: 0.2089\n","Epoch 2/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.1214\n","Epoch 3/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.1006\n","Epoch 4/80\n","98/98 [==============================] - 2s 15ms/step - loss: 0.0985\n","Epoch 5/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0877\n","Epoch 6/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0856\n","Epoch 7/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0772\n","Epoch 8/80\n","98/98 [==============================] - 2s 15ms/step - loss: 0.0778\n","Epoch 9/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0788\n","Epoch 10/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0749\n","Epoch 11/80\n","98/98 [==============================] - 2s 15ms/step - loss: 0.0722\n","Epoch 12/80\n","98/98 [==============================] - 2s 15ms/step - loss: 0.0748\n","Epoch 13/80\n","98/98 [==============================] - 2s 15ms/step - loss: 0.0637\n","Epoch 14/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0725\n","Epoch 15/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0686\n","Epoch 16/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0687\n","Epoch 17/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0667\n","Epoch 18/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0651\n","Epoch 19/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0644\n","Epoch 20/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0651\n","Epoch 21/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0678\n","Epoch 22/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0646\n","Epoch 23/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0620\n","Epoch 24/80\n","98/98 [==============================] - 2s 15ms/step - loss: 0.0656\n","Epoch 25/80\n","98/98 [==============================] - 2s 15ms/step - loss: 0.0583\n","Epoch 26/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0624\n","Epoch 27/80\n","98/98 [==============================] - 2s 15ms/step - loss: 0.0621\n","Epoch 28/80\n","98/98 [==============================] - 2s 15ms/step - loss: 0.0645\n","Epoch 29/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0605\n","Epoch 30/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0609\n","Epoch 31/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0638\n","Epoch 32/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0585\n","Epoch 33/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0603\n","Epoch 34/80\n","98/98 [==============================] - 2s 15ms/step - loss: 0.0586\n","Epoch 35/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0576\n","Epoch 36/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0541\n","Epoch 37/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0609\n","Epoch 38/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0601\n","Epoch 39/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0649\n","Epoch 40/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0568\n","Epoch 41/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0592\n","Epoch 42/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0546\n","Epoch 43/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0581\n","Epoch 44/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0597\n","Epoch 45/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0658\n","Epoch 46/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0558\n","Epoch 47/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0586\n","Epoch 48/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0546\n","Epoch 49/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0565\n","Epoch 50/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0547\n","Epoch 51/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0544\n","Epoch 52/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0520\n","Epoch 53/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0550\n","Epoch 54/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0541\n","Epoch 55/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0567\n","Epoch 56/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0551\n","Epoch 57/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0543\n","Epoch 58/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0578\n","Epoch 59/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0599\n","Epoch 60/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0536\n","Epoch 61/80\n","98/98 [==============================] - 2s 15ms/step - loss: 0.0531\n","Epoch 62/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0546\n","Epoch 63/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0590\n","Epoch 64/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0548\n","Epoch 65/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0566\n","Epoch 66/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0553\n","Epoch 67/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0526\n","Epoch 68/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0541\n","Epoch 69/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0532\n","Epoch 70/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0546\n","Epoch 71/80\n","98/98 [==============================] - 2s 15ms/step - loss: 0.0523\n","Epoch 72/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0539\n","Epoch 73/80\n","98/98 [==============================] - 2s 16ms/step - loss: 0.0524\n","Epoch 74/80\n","98/98 [==============================] - 2s 15ms/step - loss: 0.0566\n","Epoch 75/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0557\n","Epoch 76/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0543\n","Epoch 77/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0535\n","Epoch 78/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0542\n","Epoch 79/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0539\n","Epoch 80/80\n","98/98 [==============================] - 1s 15ms/step - loss: 0.0545\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f558f39c0d0>"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["predicted_stock_price = model8.predict(X_test)\n","log = feature.iloc[:feature.shape[0]-X_test.shape[0], 0].values\n","data_mean = log.mean(axis=0) \n","data_std = log.std(axis=0)\n","original = (predicted_stock_price)*data_std+data_mean\n","\n","y = feature.iloc[feature.shape[0]-X_test.shape[0]:, 1:2].values\n","rmse = np.sqrt(np.mean(((original - y) ** 2)))\n","print(rmse)\n","\n","res.append(round(measure_accuarcy(original, n_days = 15)[0]  * 100,2))\n","print(measure_diff(original, n_days = 15))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CnmEC4-vpU6e","executionInfo":{"status":"ok","timestamp":1669959210320,"user_tz":-540,"elapsed":1744,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"3e47f002-b1e6-46a7-8f58-7df085081ef9"},"id":"CnmEC4-vpU6e","execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["24/24 [==============================] - 2s 6ms/step\n","2.9395730932374176\n","[46.433178]\n"]}]},{"cell_type":"code","source":["model9 = Sequential()\n","\n","#Adding the first LSTM layer and some Dropout regularisation\n","\n","model9.add(LSTM(units = 100, return_sequences = True, input_shape = (X_train.shape[-2:])))\n","\n","model9.add(LSTM(100, return_sequences=True))\n","model9.add(Dropout(0.4))\n","\n","\n","model9.add(LSTM(60, return_sequences=True))\n","model9.add(Dropout(0.4))\n","\n","#model9.add(RepeatVector(time_step))\n","\n","# Adding a second LSTM layer and some Dropout regularisation\n","\n","model9.add(LSTM(60))\n","model9.add(Dropout(0.4))\n","\n","# Adding the output layer i \n"," \n","model9.add(Dense(units = 1))\n","\n","# Compiling the RNN\n","\n","model9.compile(optimizer = 'adam' , loss = 'mean_squared_error' )\n","\n","# Fitting the RNN to the Training set\n","\n","model9.fit(X_train, y_train, epochs = 80, batch_size = 32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lPzXnBr2clj8","executionInfo":{"status":"ok","timestamp":1669959297371,"user_tz":-540,"elapsed":87055,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"b4bd95d6-2341-4133-dfbf-73df173d8b3f"},"id":"lPzXnBr2clj8","execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/80\n","98/98 [==============================] - 6s 10ms/step - loss: 0.0854\n","Epoch 2/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0481\n","Epoch 3/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0409\n","Epoch 4/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0400\n","Epoch 5/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0334\n","Epoch 6/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0346\n","Epoch 7/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0309\n","Epoch 8/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0302\n","Epoch 9/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0292\n","Epoch 10/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0277\n","Epoch 11/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0276\n","Epoch 12/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0268\n","Epoch 13/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0240\n","Epoch 14/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0241\n","Epoch 15/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0239\n","Epoch 16/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0239\n","Epoch 17/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0229\n","Epoch 18/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0236\n","Epoch 19/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0230\n","Epoch 20/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0223\n","Epoch 21/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0217\n","Epoch 22/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0233\n","Epoch 23/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0205\n","Epoch 24/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0206\n","Epoch 25/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0215\n","Epoch 26/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0205\n","Epoch 27/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0216\n","Epoch 28/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0222\n","Epoch 29/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0205\n","Epoch 30/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0197\n","Epoch 31/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0196\n","Epoch 32/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0174\n","Epoch 33/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0174\n","Epoch 34/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0182\n","Epoch 35/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0190\n","Epoch 36/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0193\n","Epoch 37/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0178\n","Epoch 38/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0185\n","Epoch 39/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0179\n","Epoch 40/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0179\n","Epoch 41/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0196\n","Epoch 42/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0177\n","Epoch 43/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0178\n","Epoch 44/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0175\n","Epoch 45/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0174\n","Epoch 46/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0168\n","Epoch 47/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0191\n","Epoch 48/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0167\n","Epoch 49/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0172\n","Epoch 50/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0159\n","Epoch 51/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0167\n","Epoch 52/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0161\n","Epoch 53/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0179\n","Epoch 54/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0166\n","Epoch 55/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0181\n","Epoch 56/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0170\n","Epoch 57/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0163\n","Epoch 58/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0163\n","Epoch 59/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0164\n","Epoch 60/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0178\n","Epoch 61/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0184\n","Epoch 62/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0180\n","Epoch 63/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0167\n","Epoch 64/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0165\n","Epoch 65/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0177\n","Epoch 66/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0162\n","Epoch 67/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0174\n","Epoch 68/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0161\n","Epoch 69/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0175\n","Epoch 70/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0165\n","Epoch 71/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0146\n","Epoch 72/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0170\n","Epoch 73/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0158\n","Epoch 74/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0148\n","Epoch 75/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0159\n","Epoch 76/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0158\n","Epoch 77/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0156\n","Epoch 78/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0151\n","Epoch 79/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0155\n","Epoch 80/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0155\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f558c8f7730>"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["predicted_stock_price = model9.predict(X_test)\n","log = feature.iloc[:feature.shape[0]-X_test.shape[0], 0].values\n","data_mean = log.mean(axis=0) \n","data_std = log.std(axis=0)\n","original = (predicted_stock_price)*data_std+data_mean\n","\n","y = feature.iloc[feature.shape[0]-X_test.shape[0]:, 1:2].values\n","rmse = np.sqrt(np.mean(((original - y) ** 2)))\n","print(rmse)\n","\n","res.append(round(measure_accuarcy(original, n_days = 15)[0]  * 100,2))\n","print(measure_diff(original, n_days = 15))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fk-Km9E1dZUy","executionInfo":{"status":"ok","timestamp":1669959298653,"user_tz":-540,"elapsed":1294,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"1f9d33fe-91a2-4084-c23d-879b554ccce9"},"id":"fk-Km9E1dZUy","execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["24/24 [==============================] - 1s 5ms/step\n","2.8542923503522846\n","[9.012686]\n"]}]},{"cell_type":"code","source":["model10 = Sequential()\n","\n","#Adding the first LSTM layer and some Dropout regularisation\n","\n","model10.add(LSTM(units = 100, return_sequences = True, input_shape = (X_train.shape[-2:])))\n","\n","model10.add(LSTM(100, return_sequences=True))\n","model10.add(Dropout(0.8))\n","\n","\n","model10.add(LSTM(60, return_sequences=True))\n","model10.add(Dropout(0.8))\n","\n","#model10.add(RepeatVector(time_step))\n","\n","# Adding a second LSTM layer and some Dropout regularisation\n","\n","model10.add(LSTM(60))\n","model10.add(Dropout(0.8))\n","\n","# Adding the output layer i \n"," \n","model10.add(Dense(units = 1))\n","\n","# Compiling the RNN\n","\n","model10.compile(optimizer = 'adam' , loss = 'mean_squared_error' )\n","\n","# Fitting the RNN to the Training set\n","\n","model10.fit(X_train, y_train, epochs = 80, batch_size = 32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SDxJpS9McmUg","executionInfo":{"status":"ok","timestamp":1669959387370,"user_tz":-540,"elapsed":88724,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"6cf59c08-0d28-4c0c-caea-549feb386de6"},"id":"SDxJpS9McmUg","execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/80\n","98/98 [==============================] - 7s 10ms/step - loss: 0.2664\n","Epoch 2/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.1363\n","Epoch 3/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.1243\n","Epoch 4/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.1031\n","Epoch 5/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.1099\n","Epoch 6/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.1064\n","Epoch 7/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.1028\n","Epoch 8/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0978\n","Epoch 9/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0971\n","Epoch 10/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0965\n","Epoch 11/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0919\n","Epoch 12/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0910\n","Epoch 13/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0912\n","Epoch 14/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0900\n","Epoch 15/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0985\n","Epoch 16/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0902\n","Epoch 17/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0844\n","Epoch 18/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0960\n","Epoch 19/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0877\n","Epoch 20/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0856\n","Epoch 21/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0864\n","Epoch 22/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0856\n","Epoch 23/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0810\n","Epoch 24/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0806\n","Epoch 25/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0835\n","Epoch 26/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0833\n","Epoch 27/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0862\n","Epoch 28/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0822\n","Epoch 29/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0907\n","Epoch 30/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0806\n","Epoch 31/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0820\n","Epoch 32/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0850\n","Epoch 33/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0803\n","Epoch 34/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0822\n","Epoch 35/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0753\n","Epoch 36/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0816\n","Epoch 37/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0814\n","Epoch 38/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0796\n","Epoch 39/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0840\n","Epoch 40/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0801\n","Epoch 41/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0785\n","Epoch 42/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0787\n","Epoch 43/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0825\n","Epoch 44/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0785\n","Epoch 45/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0791\n","Epoch 46/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0760\n","Epoch 47/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0845\n","Epoch 48/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0773\n","Epoch 49/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0785\n","Epoch 50/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0810\n","Epoch 51/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0866\n","Epoch 52/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0842\n","Epoch 53/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0826\n","Epoch 54/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0834\n","Epoch 55/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0790\n","Epoch 56/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0742\n","Epoch 57/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0724\n","Epoch 58/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0741\n","Epoch 59/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0749\n","Epoch 60/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0753\n","Epoch 61/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0803\n","Epoch 62/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0723\n","Epoch 63/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0764\n","Epoch 64/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0792\n","Epoch 65/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0793\n","Epoch 66/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0796\n","Epoch 67/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0776\n","Epoch 68/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0724\n","Epoch 69/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0742\n","Epoch 70/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0782\n","Epoch 71/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0763\n","Epoch 72/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0750\n","Epoch 73/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0747\n","Epoch 74/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0829\n","Epoch 75/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0726\n","Epoch 76/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0822\n","Epoch 77/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0737\n","Epoch 78/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0781\n","Epoch 79/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0770\n","Epoch 80/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0753\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f5589ac76d0>"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","source":["predicted_stock_price = model10.predict(X_test)\n","log = feature.iloc[:feature.shape[0]-X_test.shape[0], 0].values\n","data_mean = log.mean(axis=0) \n","data_std = log.std(axis=0)\n","original = (predicted_stock_price)*data_std+data_mean\n","\n","y = feature.iloc[feature.shape[0]-X_test.shape[0]:, 1:2].values\n","rmse = np.sqrt(np.mean(((original - y) ** 2)))\n","print(rmse)\n","\n","res.append(round(measure_accuarcy(original, n_days = 15)[0]  * 100,2))\n","print(measure_diff(original, n_days = 15))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jjzwT_IYdbWs","executionInfo":{"status":"ok","timestamp":1669959388700,"user_tz":-540,"elapsed":1335,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"21ba5d10-9d22-4ebd-ae91-52d0d250e2b7"},"id":"jjzwT_IYdbWs","execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["24/24 [==============================] - 1s 5ms/step\n","2.9463290966548787\n","[21.344585]\n"]}]},{"cell_type":"code","source":["model11 = Sequential()\n","\n","#Adding the first LSTM layer and some Dropout regularisation\n","\n","model11.add(LSTM(units = 100, return_sequences = True, input_shape = (X_train.shape[-2:])))\n","\n","model11.add(LSTM(100, return_sequences=True))\n","model11.add(Dropout(0.4))\n","\n","\n","model11.add(LSTM(100, return_sequences=True))\n","model11.add(Dropout(0.4))\n","\n","#model11.add(RepeatVector(time_step))\n","\n","# Adding a second LSTM layer and some Dropout regularisation\n","\n","model11.add(LSTM(100))\n","model11.add(Dropout(0.4))\n","\n","# Adding the output layer i \n"," \n","model11.add(Dense(units = 1))\n","\n","# Compiling the RNN\n","\n","model11.compile(optimizer = 'adam' , loss = 'mean_squared_error' )\n","\n","# Fitting the RNN to the Training set\n","\n","model11.fit(X_train, y_train, epochs = 80, batch_size = 32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u179ijuAc1wT","executionInfo":{"status":"ok","timestamp":1669959477200,"user_tz":-540,"elapsed":88504,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"ed2b6b55-98aa-4817-cc04-846d9242d238"},"id":"u179ijuAc1wT","execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/80\n","98/98 [==============================] - 6s 11ms/step - loss: 0.0829\n","Epoch 2/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0394\n","Epoch 3/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0344\n","Epoch 4/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0322\n","Epoch 5/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0287\n","Epoch 6/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0305\n","Epoch 7/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0252\n","Epoch 8/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0272\n","Epoch 9/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0246\n","Epoch 10/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0221\n","Epoch 11/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0246\n","Epoch 12/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0210\n","Epoch 13/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0206\n","Epoch 14/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0198\n","Epoch 15/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0176\n","Epoch 16/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0177\n","Epoch 17/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0189\n","Epoch 18/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0190\n","Epoch 19/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0173\n","Epoch 20/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0178\n","Epoch 21/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0193\n","Epoch 22/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0193\n","Epoch 23/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0168\n","Epoch 24/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0157\n","Epoch 25/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0159\n","Epoch 26/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0160\n","Epoch 27/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0161\n","Epoch 28/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0149\n","Epoch 29/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0157\n","Epoch 30/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0157\n","Epoch 31/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0150\n","Epoch 32/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0133\n","Epoch 33/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0141\n","Epoch 34/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0153\n","Epoch 35/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0133\n","Epoch 36/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0138\n","Epoch 37/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0137\n","Epoch 38/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0138\n","Epoch 39/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0143\n","Epoch 40/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0138\n","Epoch 41/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0127\n","Epoch 42/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0121\n","Epoch 43/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0130\n","Epoch 44/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0122\n","Epoch 45/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0140\n","Epoch 46/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0134\n","Epoch 47/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0133\n","Epoch 48/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0135\n","Epoch 49/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0132\n","Epoch 50/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0139\n","Epoch 51/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0137\n","Epoch 52/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0136\n","Epoch 53/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0131\n","Epoch 54/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0131\n","Epoch 55/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0124\n","Epoch 56/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0129\n","Epoch 57/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0126\n","Epoch 58/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0115\n","Epoch 59/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0122\n","Epoch 60/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0114\n","Epoch 61/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0120\n","Epoch 62/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0120\n","Epoch 63/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0133\n","Epoch 64/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0118\n","Epoch 65/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0125\n","Epoch 66/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0113\n","Epoch 67/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0122\n","Epoch 68/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0120\n","Epoch 69/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0122\n","Epoch 70/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0121\n","Epoch 71/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0140\n","Epoch 72/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0129\n","Epoch 73/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0128\n","Epoch 74/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0131\n","Epoch 75/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0124\n","Epoch 76/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0117\n","Epoch 77/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0116\n","Epoch 78/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0118\n","Epoch 79/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0113\n","Epoch 80/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0114\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f5522e3a7c0>"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["predicted_stock_price = model11.predict(X_test)\n","log = feature.iloc[:feature.shape[0]-X_test.shape[0], 0].values\n","data_mean = log.mean(axis=0) \n","data_std = log.std(axis=0)\n","original = (predicted_stock_price)*data_std+data_mean\n","\n","y = feature.iloc[feature.shape[0]-X_test.shape[0]:, 1:2].values\n","rmse = np.sqrt(np.mean(((original - y) ** 2)))\n","print(rmse)\n","\n","res.append(round(measure_accuarcy(original, n_days = 15)[0]  * 100,2))\n","print(measure_diff(original, n_days = 15))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O7oE3Qjtdi3f","executionInfo":{"status":"ok","timestamp":1669959478356,"user_tz":-540,"elapsed":1166,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"21e3086a-2946-4888-cb41-c7dd0a9dcfdf"},"id":"O7oE3Qjtdi3f","execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["24/24 [==============================] - 1s 5ms/step\n","2.935279096884328\n","[5.754219]\n"]}]},{"cell_type":"code","source":["model12 = Sequential()\n","\n","#Adding the first LSTM layer and some Dropout regularisation\n","\n","model12.add(LSTM(units = 100, return_sequences = True, input_shape = (X_train.shape[-2:])))\n","\n","model12.add(LSTM(100, return_sequences=True))\n","model12.add(Dropout(0.8))\n","\n","\n","model12.add(LSTM(100, return_sequences=True))\n","model12.add(Dropout(0.8))\n","\n","#model12.add(RepeatVector(time_step))\n","\n","# Adding a second LSTM layer and some Dropout regularisation\n","\n","model12.add(LSTM(100))\n","model12.add(Dropout(0.8))\n","\n","# Adding the output layer i \n"," \n","model12.add(Dense(units = 1))\n","\n","# Compiling the RNN\n","\n","model12.compile(optimizer = 'adam' , loss = 'mean_squared_error' )\n","\n","# Fitting the RNN to the Training set\n","\n","model12.fit(X_train, y_train, epochs = 80, batch_size = 32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iT6kPIuRcshm","executionInfo":{"status":"ok","timestamp":1669959568625,"user_tz":-540,"elapsed":90273,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"ebc4d6a9-51b6-4851-c8a0-3b3823a8d420"},"id":"iT6kPIuRcshm","execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/80\n","98/98 [==============================] - 6s 11ms/step - loss: 0.2126\n","Epoch 2/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.1142\n","Epoch 3/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.1016\n","Epoch 4/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0921\n","Epoch 5/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0864\n","Epoch 6/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0769\n","Epoch 7/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0776\n","Epoch 8/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0716\n","Epoch 9/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0666\n","Epoch 10/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0702\n","Epoch 11/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0688\n","Epoch 12/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0737\n","Epoch 13/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0694\n","Epoch 14/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0695\n","Epoch 15/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0689\n","Epoch 16/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0653\n","Epoch 17/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0642\n","Epoch 18/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0671\n","Epoch 19/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0584\n","Epoch 20/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0600\n","Epoch 21/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0629\n","Epoch 22/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0635\n","Epoch 23/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0624\n","Epoch 24/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0660\n","Epoch 25/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0604\n","Epoch 26/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0591\n","Epoch 27/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0594\n","Epoch 28/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0599\n","Epoch 29/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0584\n","Epoch 30/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0606\n","Epoch 31/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0576\n","Epoch 32/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0597\n","Epoch 33/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0600\n","Epoch 34/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0550\n","Epoch 35/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0571\n","Epoch 36/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0574\n","Epoch 37/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0598\n","Epoch 38/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0563\n","Epoch 39/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0590\n","Epoch 40/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0567\n","Epoch 41/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0616\n","Epoch 42/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0580\n","Epoch 43/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0565\n","Epoch 44/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0567\n","Epoch 45/80\n","98/98 [==============================] - 1s 10ms/step - loss: 0.0536\n","Epoch 46/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0561\n","Epoch 47/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0521\n","Epoch 48/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0565\n","Epoch 49/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0560\n","Epoch 50/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0525\n","Epoch 51/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0543\n","Epoch 52/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0581\n","Epoch 53/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0561\n","Epoch 54/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0577\n","Epoch 55/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0550\n","Epoch 56/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0546\n","Epoch 57/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0528\n","Epoch 58/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0529\n","Epoch 59/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0534\n","Epoch 60/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0533\n","Epoch 61/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0578\n","Epoch 62/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0548\n","Epoch 63/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0540\n","Epoch 64/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0507\n","Epoch 65/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0512\n","Epoch 66/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0527\n","Epoch 67/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0566\n","Epoch 68/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0533\n","Epoch 69/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0555\n","Epoch 70/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0549\n","Epoch 71/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0555\n","Epoch 72/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0535\n","Epoch 73/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0525\n","Epoch 74/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0540\n","Epoch 75/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0493\n","Epoch 76/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0504\n","Epoch 77/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0518\n","Epoch 78/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0562\n","Epoch 79/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0514\n","Epoch 80/80\n","98/98 [==============================] - 1s 11ms/step - loss: 0.0521\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f5520cbdb80>"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","source":["predicted_stock_price = model12.predict(X_test)\n","log = feature.iloc[:feature.shape[0]-X_test.shape[0], 0].values\n","data_mean = log.mean(axis=0) \n","data_std = log.std(axis=0)\n","original = (predicted_stock_price)*data_std+data_mean\n","\n","y = feature.iloc[feature.shape[0]-X_test.shape[0]:, 1:2].values\n","rmse = np.sqrt(np.mean(((original - y) ** 2)))\n","print(rmse)\n","\n","res.append(round(measure_accuarcy(original, n_days = 15)[0]  * 100,2))\n","print(measure_diff(original, n_days = 15))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yIb42DNWdkbO","executionInfo":{"status":"ok","timestamp":1669959570048,"user_tz":-540,"elapsed":1431,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"9e939bb4-3c95-4f11-ad2c-80ee40d18ae2"},"id":"yIb42DNWdkbO","execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["24/24 [==============================] - 1s 5ms/step\n","2.992910387300827\n","[30.489231]\n"]}]},{"cell_type":"code","source":["model13 = Sequential()\n","\n","#Adding the first LSTM layer and some Dropout regularisation\n","\n","model13.add(LSTM(units = 100, return_sequences = True, input_shape = (X_train.shape[-2:])))\n","\n","model13.add(LSTM(60))\n","model13.add(Dropout(0.4))\n","\n","\n","# Adding the output layer i \n"," \n","model13.add(Dense(units = 1))\n","\n","# Compiling the RNN\n","\n","model13.compile(optimizer = 'adam' , loss = 'mean_squared_error' )\n","\n","# Fitting the RNN to the Training set\n","\n","model13.fit(X_train, y_train, epochs = 80, batch_size = 32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3vlFzB8Oc8Cm","executionInfo":{"status":"ok","timestamp":1669959622550,"user_tz":-540,"elapsed":52506,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"bafa6273-770e-4879-9877-82afc086b471"},"id":"3vlFzB8Oc8Cm","execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/80\n","98/98 [==============================] - 3s 6ms/step - loss: 0.0878\n","Epoch 2/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0450\n","Epoch 3/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0386\n","Epoch 4/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0352\n","Epoch 5/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0323\n","Epoch 6/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0312\n","Epoch 7/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0314\n","Epoch 8/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0293\n","Epoch 9/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0283\n","Epoch 10/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0279\n","Epoch 11/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0261\n","Epoch 12/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0262\n","Epoch 13/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0272\n","Epoch 14/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0259\n","Epoch 15/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0234\n","Epoch 16/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0237\n","Epoch 17/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0222\n","Epoch 18/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0224\n","Epoch 19/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0229\n","Epoch 20/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0207\n","Epoch 21/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0213\n","Epoch 22/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0211\n","Epoch 23/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0201\n","Epoch 24/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0204\n","Epoch 25/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0194\n","Epoch 26/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0198\n","Epoch 27/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0201\n","Epoch 28/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0206\n","Epoch 29/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0199\n","Epoch 30/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0206\n","Epoch 31/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0202\n","Epoch 32/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0189\n","Epoch 33/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0187\n","Epoch 34/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0190\n","Epoch 35/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0180\n","Epoch 36/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0188\n","Epoch 37/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0186\n","Epoch 38/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0190\n","Epoch 39/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0188\n","Epoch 40/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0189\n","Epoch 41/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0175\n","Epoch 42/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0171\n","Epoch 43/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0176\n","Epoch 44/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0175\n","Epoch 45/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0185\n","Epoch 46/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0182\n","Epoch 47/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0170\n","Epoch 48/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0168\n","Epoch 49/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0172\n","Epoch 50/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0169\n","Epoch 51/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0155\n","Epoch 52/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0155\n","Epoch 53/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0174\n","Epoch 54/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0164\n","Epoch 55/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0163\n","Epoch 56/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0166\n","Epoch 57/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0163\n","Epoch 58/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0158\n","Epoch 59/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0155\n","Epoch 60/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0169\n","Epoch 61/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0160\n","Epoch 62/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0159\n","Epoch 63/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0160\n","Epoch 64/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0159\n","Epoch 65/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0157\n","Epoch 66/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0152\n","Epoch 67/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0154\n","Epoch 68/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0164\n","Epoch 69/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0159\n","Epoch 70/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0154\n","Epoch 71/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0154\n","Epoch 72/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0158\n","Epoch 73/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0162\n","Epoch 74/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0152\n","Epoch 75/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0168\n","Epoch 76/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0150\n","Epoch 77/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0164\n","Epoch 78/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0151\n","Epoch 79/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0144\n","Epoch 80/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0157\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f551d795c40>"]},"metadata":{},"execution_count":48}]},{"cell_type":"code","source":["predicted_stock_price = model13.predict(X_test)\n","log = feature.iloc[:feature.shape[0]-X_test.shape[0], 0].values\n","data_mean = log.mean(axis=0) \n","data_std = log.std(axis=0)\n","original = (predicted_stock_price)*data_std+data_mean\n","\n","y = feature.iloc[feature.shape[0]-X_test.shape[0]:, 1:2].values\n","rmse = np.sqrt(np.mean(((original - y) ** 2)))\n","print(rmse)\n","\n","res.append(round(measure_accuarcy(original, n_days = 15)[0]  * 100,2))\n","print(measure_diff(original, n_days = 15))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uk4N1TOjdmQO","executionInfo":{"status":"ok","timestamp":1669959623430,"user_tz":-540,"elapsed":885,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"f441780e-3cc3-4476-f399-1e4a145e4166"},"id":"uk4N1TOjdmQO","execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["24/24 [==============================] - 1s 3ms/step\n","2.859623818567312\n","[31.88857]\n"]}]},{"cell_type":"code","source":["model14 = Sequential()\n","\n","#Adding the first LSTM layer and some Dropout regularisation\n","\n","model14.add(LSTM(units = 100, return_sequences = True, input_shape = (X_train.shape[-2:])))\n","\n","model14.add(LSTM(60))\n","model14.add(Dropout(0.8))\n","\n","\n","# Adding the output layer i \n"," \n","model14.add(Dense(units = 1))\n","\n","# Compiling the RNN\n","\n","model14.compile(optimizer = 'adam' , loss = 'mean_squared_error' )\n","\n","# Fitting the RNN to the Training set\n","\n","model14.fit(X_train, y_train, epochs = 80, batch_size = 32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ALdITVcrdMVP","executionInfo":{"status":"ok","timestamp":1669959675119,"user_tz":-540,"elapsed":51692,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"084e91a2-7a9c-4f3d-f7a9-62ebefe72e19"},"id":"ALdITVcrdMVP","execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/80\n","98/98 [==============================] - 3s 7ms/step - loss: 0.2267\n","Epoch 2/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1178\n","Epoch 3/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1099\n","Epoch 4/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.1085\n","Epoch 5/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1013\n","Epoch 6/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0957\n","Epoch 7/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0940\n","Epoch 8/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0856\n","Epoch 9/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0931\n","Epoch 10/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0917\n","Epoch 11/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0913\n","Epoch 12/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0878\n","Epoch 13/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0805\n","Epoch 14/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0877\n","Epoch 15/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0803\n","Epoch 16/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0830\n","Epoch 17/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0879\n","Epoch 18/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0876\n","Epoch 19/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0765\n","Epoch 20/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0850\n","Epoch 21/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0884\n","Epoch 22/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0801\n","Epoch 23/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0800\n","Epoch 24/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0802\n","Epoch 25/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0749\n","Epoch 26/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0802\n","Epoch 27/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0777\n","Epoch 28/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0761\n","Epoch 29/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0780\n","Epoch 30/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0781\n","Epoch 31/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0821\n","Epoch 32/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0799\n","Epoch 33/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0756\n","Epoch 34/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0772\n","Epoch 35/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0720\n","Epoch 36/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0789\n","Epoch 37/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0757\n","Epoch 38/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0784\n","Epoch 39/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0790\n","Epoch 40/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0795\n","Epoch 41/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0749\n","Epoch 42/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0763\n","Epoch 43/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0757\n","Epoch 44/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0759\n","Epoch 45/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0712\n","Epoch 46/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0770\n","Epoch 47/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0757\n","Epoch 48/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0699\n","Epoch 49/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0724\n","Epoch 50/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0802\n","Epoch 51/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0708\n","Epoch 52/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0764\n","Epoch 53/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0759\n","Epoch 54/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0779\n","Epoch 55/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0750\n","Epoch 56/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0724\n","Epoch 57/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0715\n","Epoch 58/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0746\n","Epoch 59/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0746\n","Epoch 60/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0739\n","Epoch 61/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0741\n","Epoch 62/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0724\n","Epoch 63/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0709\n","Epoch 64/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0764\n","Epoch 65/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0747\n","Epoch 66/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0731\n","Epoch 67/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0728\n","Epoch 68/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0740\n","Epoch 69/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0752\n","Epoch 70/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0693\n","Epoch 71/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0696\n","Epoch 72/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0749\n","Epoch 73/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0703\n","Epoch 74/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0708\n","Epoch 75/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0712\n","Epoch 76/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0719\n","Epoch 77/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0727\n","Epoch 78/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0699\n","Epoch 79/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0744\n","Epoch 80/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0652\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f551b9e0940>"]},"metadata":{},"execution_count":50}]},{"cell_type":"code","source":["predicted_stock_price = model14.predict(X_test)\n","log = feature.iloc[:feature.shape[0]-X_test.shape[0], 0].values\n","data_mean = log.mean(axis=0) \n","data_std = log.std(axis=0)\n","original = (predicted_stock_price)*data_std+data_mean\n","\n","y = feature.iloc[feature.shape[0]-X_test.shape[0]:, 1:2].values\n","rmse = np.sqrt(np.mean(((original - y) ** 2)))\n","print(rmse)\n","\n","res.append(round(measure_accuarcy(original, n_days = 15)[0]  * 100,2))\n","print(measure_diff(original, n_days = 15))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"suNhl98wdnv8","executionInfo":{"status":"ok","timestamp":1669959676036,"user_tz":-540,"elapsed":923,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"d8679388-3430-486c-fb2d-a8c547e7c101"},"id":"suNhl98wdnv8","execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["24/24 [==============================] - 1s 3ms/step\n","2.971181677179522\n","[23.836319]\n"]}]},{"cell_type":"code","source":["model15 = Sequential()\n","\n","#Adding the first LSTM layer and some Dropout regularisation\n","\n","model15.add(LSTM(units = 100, return_sequences = True, input_shape = (X_train.shape[-2:])))\n","\n","model15.add(LSTM(100))\n","model15.add(Dropout(0.4))\n","\n","\n","# Adding the output layer i \n"," \n","model15.add(Dense(units = 1))\n","\n","# Compiling the RNN\n","\n","model15.compile(optimizer = 'adam' , loss = 'mean_squared_error' )\n","\n","# Fitting the RNN to the Training set\n","\n","model15.fit(X_train, y_train, epochs = 80, batch_size = 32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RV8SyzYxdSGc","executionInfo":{"status":"ok","timestamp":1669959728261,"user_tz":-540,"elapsed":52229,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"5197a88a-0b94-45b5-e935-f4e69ad0feba"},"id":"RV8SyzYxdSGc","execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/80\n","98/98 [==============================] - 3s 6ms/step - loss: 0.0826\n","Epoch 2/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0379\n","Epoch 3/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0334\n","Epoch 4/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0324\n","Epoch 5/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0293\n","Epoch 6/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0274\n","Epoch 7/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0254\n","Epoch 8/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0264\n","Epoch 9/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0236\n","Epoch 10/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0230\n","Epoch 11/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0218\n","Epoch 12/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0213\n","Epoch 13/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0193\n","Epoch 14/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0196\n","Epoch 15/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0181\n","Epoch 16/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0199\n","Epoch 17/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0178\n","Epoch 18/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0175\n","Epoch 19/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0177\n","Epoch 20/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0158\n","Epoch 21/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0158\n","Epoch 22/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0161\n","Epoch 23/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0163\n","Epoch 24/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0155\n","Epoch 25/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0153\n","Epoch 26/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0153\n","Epoch 27/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0170\n","Epoch 28/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0153\n","Epoch 29/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0148\n","Epoch 30/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0129\n","Epoch 31/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0139\n","Epoch 32/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0139\n","Epoch 33/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0147\n","Epoch 34/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0149\n","Epoch 35/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0125\n","Epoch 36/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0138\n","Epoch 37/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0120\n","Epoch 38/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0125\n","Epoch 39/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0119\n","Epoch 40/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0126\n","Epoch 41/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0122\n","Epoch 42/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0126\n","Epoch 43/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0130\n","Epoch 44/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0122\n","Epoch 45/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0125\n","Epoch 46/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0119\n","Epoch 47/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0117\n","Epoch 48/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0119\n","Epoch 49/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0109\n","Epoch 50/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0109\n","Epoch 51/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0109\n","Epoch 52/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0131\n","Epoch 53/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0134\n","Epoch 54/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0111\n","Epoch 55/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0122\n","Epoch 56/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0118\n","Epoch 57/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0121\n","Epoch 58/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0121\n","Epoch 59/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0113\n","Epoch 60/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0115\n","Epoch 61/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0107\n","Epoch 62/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0111\n","Epoch 63/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0107\n","Epoch 64/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0113\n","Epoch 65/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0109\n","Epoch 66/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0107\n","Epoch 67/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0115\n","Epoch 68/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0104\n","Epoch 69/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0115\n","Epoch 70/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0108\n","Epoch 71/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0104\n","Epoch 72/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0103\n","Epoch 73/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0102\n","Epoch 74/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0104\n","Epoch 75/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0118\n","Epoch 76/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0106\n","Epoch 77/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0111\n","Epoch 78/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0101\n","Epoch 79/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0105\n","Epoch 80/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0103\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f551b88f2b0>"]},"metadata":{},"execution_count":52}]},{"cell_type":"code","source":["predicted_stock_price = model15.predict(X_test)\n","log = feature.iloc[:feature.shape[0]-X_test.shape[0], 0].values\n","data_mean = log.mean(axis=0) \n","data_std = log.std(axis=0)\n","original = (predicted_stock_price)*data_std+data_mean\n","\n","y = feature.iloc[feature.shape[0]-X_test.shape[0]:, 1:2].values\n","rmse = np.sqrt(np.mean(((original - y) ** 2)))\n","print(rmse)\n","\n","res.append(round(measure_accuarcy(original, n_days = 15)[0]  * 100,2))\n","print(measure_diff(original, n_days = 15))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l4ug1q37dpIC","executionInfo":{"status":"ok","timestamp":1669959729385,"user_tz":-540,"elapsed":1129,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"62e1eb83-1a9f-4244-9e50-637eb37effaa"},"id":"l4ug1q37dpIC","execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["24/24 [==============================] - 1s 3ms/step\n","2.9262576168084125\n","[26.200932]\n"]}]},{"cell_type":"code","source":["model16 = Sequential()\n","\n","#Adding the first LSTM layer and some Dropout regularisation\n","\n","model16.add(LSTM(units = 100, return_sequences = True, input_shape = (X_train.shape[-2:])))\n","\n","model16.add(LSTM(100))\n","model16.add(Dropout(0.8))\n","\n","\n","# Adding the output layer i \n"," \n","model16.add(Dense(units = 1))\n","\n","# Compiling the RNN\n","\n","model16.compile(optimizer = 'adam' , loss = 'mean_squared_error' )\n","\n","# Fitting the RNN to the Training set\n","\n","model16.fit(X_train, y_train, epochs = 80, batch_size = 32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"chzqNpYmdReT","executionInfo":{"status":"ok","timestamp":1669959782123,"user_tz":-540,"elapsed":52742,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"7a43260a-de94-400b-ac9d-63731097699c"},"id":"chzqNpYmdReT","execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/80\n","98/98 [==============================] - 3s 6ms/step - loss: 0.1683\n","Epoch 2/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0889\n","Epoch 3/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0868\n","Epoch 4/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0740\n","Epoch 5/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0751\n","Epoch 6/80\n","98/98 [==============================] - 1s 7ms/step - loss: 0.0719\n","Epoch 7/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0716\n","Epoch 8/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0750\n","Epoch 9/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0703\n","Epoch 10/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0652\n","Epoch 11/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0640\n","Epoch 12/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0613\n","Epoch 13/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0642\n","Epoch 14/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0611\n","Epoch 15/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0589\n","Epoch 16/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0595\n","Epoch 17/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0642\n","Epoch 18/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0566\n","Epoch 19/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0611\n","Epoch 20/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0604\n","Epoch 21/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0580\n","Epoch 22/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0587\n","Epoch 23/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0574\n","Epoch 24/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0589\n","Epoch 25/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0594\n","Epoch 26/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0543\n","Epoch 27/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0570\n","Epoch 28/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0588\n","Epoch 29/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0549\n","Epoch 30/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0566\n","Epoch 31/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0531\n","Epoch 32/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0526\n","Epoch 33/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0557\n","Epoch 34/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0543\n","Epoch 35/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0540\n","Epoch 36/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0526\n","Epoch 37/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0513\n","Epoch 38/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0529\n","Epoch 39/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0554\n","Epoch 40/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0520\n","Epoch 41/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0497\n","Epoch 42/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0484\n","Epoch 43/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0515\n","Epoch 44/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0479\n","Epoch 45/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0505\n","Epoch 46/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0487\n","Epoch 47/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0486\n","Epoch 48/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0495\n","Epoch 49/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0527\n","Epoch 50/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0502\n","Epoch 51/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0519\n","Epoch 52/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0518\n","Epoch 53/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0483\n","Epoch 54/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0526\n","Epoch 55/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0533\n","Epoch 56/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0532\n","Epoch 57/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0487\n","Epoch 58/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0474\n","Epoch 59/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0471\n","Epoch 60/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0463\n","Epoch 61/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0533\n","Epoch 62/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0498\n","Epoch 63/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0478\n","Epoch 64/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0515\n","Epoch 65/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0463\n","Epoch 66/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0493\n","Epoch 67/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0477\n","Epoch 68/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0442\n","Epoch 69/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0509\n","Epoch 70/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0494\n","Epoch 71/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0509\n","Epoch 72/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0475\n","Epoch 73/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0453\n","Epoch 74/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0480\n","Epoch 75/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0473\n","Epoch 76/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0506\n","Epoch 77/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0503\n","Epoch 78/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0485\n","Epoch 79/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0454\n","Epoch 80/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0469\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f551bad8f40>"]},"metadata":{},"execution_count":54}]},{"cell_type":"code","source":["predicted_stock_price = model16.predict(X_test)\n","log = feature.iloc[:feature.shape[0]-X_test.shape[0], 0].values\n","data_mean = log.mean(axis=0) \n","data_std = log.std(axis=0)\n","original = (predicted_stock_price)*data_std+data_mean\n","\n","y = feature.iloc[feature.shape[0]-X_test.shape[0]:, 1:2].values\n","rmse = np.sqrt(np.mean(((original - y) ** 2)))\n","print(rmse)\n","\n","res.append(round(measure_accuarcy(original, n_days = 15)[0]  * 100,2))\n","print(measure_diff(original, n_days = 15))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nT-fDrD0dqx5","executionInfo":{"status":"ok","timestamp":1669959783165,"user_tz":-540,"elapsed":1048,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"8882eacd-3ea8-4982-b299-1b567d05a677"},"id":"nT-fDrD0dqx5","execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["24/24 [==============================] - 1s 3ms/step\n","2.9548031040983336\n","[15.111841]\n"]}]},{"cell_type":"code","source":["model17 = Sequential()\n","\n","#Adding the first LSTM layer and some Dropout regularisation\n","\n","model17.add(LSTM(units = 60, return_sequences = True, input_shape = (X_train.shape[-2:])))\n","\n","model17.add(LSTM(60))\n","model17.add(Dropout(0.8))\n","\n","\n","# Adding the output layer i \n"," \n","model17.add(Dense(units = 1))\n","\n","# Compiling the RNN\n","\n","model17.compile(optimizer = 'adam' , loss = 'mean_squared_error' )\n","\n","# Fitting the RNN to the Training set\n","\n","model17.fit(X_train, y_train, epochs = 80, batch_size = 32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v4uEh0rCg5pP","executionInfo":{"status":"ok","timestamp":1669959831420,"user_tz":-540,"elapsed":48262,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"fd9ad890-16bf-455d-9bbe-77daf8b5cb40"},"id":"v4uEh0rCg5pP","execution_count":56,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/80\n","98/98 [==============================] - 3s 6ms/step - loss: 0.2222\n","Epoch 2/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1153\n","Epoch 3/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1106\n","Epoch 4/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1015\n","Epoch 5/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0939\n","Epoch 6/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0982\n","Epoch 7/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0867\n","Epoch 8/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0938\n","Epoch 9/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0918\n","Epoch 10/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0919\n","Epoch 11/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0859\n","Epoch 12/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0849\n","Epoch 13/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0871\n","Epoch 14/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0834\n","Epoch 15/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0831\n","Epoch 16/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0875\n","Epoch 17/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0810\n","Epoch 18/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0768\n","Epoch 19/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0868\n","Epoch 20/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0820\n","Epoch 21/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0794\n","Epoch 22/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0788\n","Epoch 23/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0837\n","Epoch 24/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0792\n","Epoch 25/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0828\n","Epoch 26/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0845\n","Epoch 27/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0783\n","Epoch 28/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0758\n","Epoch 29/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0798\n","Epoch 30/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0756\n","Epoch 31/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0767\n","Epoch 32/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0760\n","Epoch 33/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0793\n","Epoch 34/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0758\n","Epoch 35/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0776\n","Epoch 36/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0813\n","Epoch 37/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0733\n","Epoch 38/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0721\n","Epoch 39/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0808\n","Epoch 40/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0750\n","Epoch 41/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0795\n","Epoch 42/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0756\n","Epoch 43/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0753\n","Epoch 44/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0771\n","Epoch 45/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0732\n","Epoch 46/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0698\n","Epoch 47/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0749\n","Epoch 48/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0731\n","Epoch 49/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0715\n","Epoch 50/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0726\n","Epoch 51/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0753\n","Epoch 52/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0735\n","Epoch 53/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0730\n","Epoch 54/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0714\n","Epoch 55/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0717\n","Epoch 56/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0733\n","Epoch 57/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0704\n","Epoch 58/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0743\n","Epoch 59/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0701\n","Epoch 60/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0739\n","Epoch 61/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0725\n","Epoch 62/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0716\n","Epoch 63/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0728\n","Epoch 64/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0738\n","Epoch 65/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0726\n","Epoch 66/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0691\n","Epoch 67/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0709\n","Epoch 68/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0734\n","Epoch 69/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0691\n","Epoch 70/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0697\n","Epoch 71/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0788\n","Epoch 72/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0712\n","Epoch 73/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0737\n","Epoch 74/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0722\n","Epoch 75/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0692\n","Epoch 76/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0763\n","Epoch 77/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0703\n","Epoch 78/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0716\n","Epoch 79/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0742\n","Epoch 80/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0743\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f5518db1820>"]},"metadata":{},"execution_count":56}]},{"cell_type":"code","source":["predicted_stock_price = model17.predict(X_test)\n","log = feature.iloc[:feature.shape[0]-X_test.shape[0], 0].values\n","data_mean = log.mean(axis=0) \n","data_std = log.std(axis=0)\n","original = (predicted_stock_price)*data_std+data_mean\n","\n","y = feature.iloc[feature.shape[0]-X_test.shape[0]:, 1:2].values\n","rmse = np.sqrt(np.mean(((original - y) ** 2)))\n","print(rmse)\n","\n","res.append(round(measure_accuarcy(original, n_days = 15)[0]  * 100,2))\n","print(measure_diff(original, n_days = 15))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QpJ8rNK3mTMF","executionInfo":{"status":"ok","timestamp":1669959831918,"user_tz":-540,"elapsed":503,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"b0ce15a5-63b9-4579-fdac-b171b022124e"},"id":"QpJ8rNK3mTMF","execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["24/24 [==============================] - 1s 3ms/step\n","2.962828392234523\n","[26.648994]\n"]}]},{"cell_type":"code","source":["model18 = Sequential()\n","\n","#Adding the first LSTM layer and some Dropout regularisation\n","\n","model18.add(LSTM(units = 60, return_sequences = True, input_shape = (X_train.shape[-2:])))\n","\n","model18.add(LSTM(40))\n","model18.add(Dropout(0.8))\n","\n","\n","# Adding the output layer i \n"," \n","model18.add(Dense(units = 1))\n","\n","# Compiling the RNN\n","\n","model18.compile(optimizer = 'adam' , loss = 'mean_squared_error' )\n","\n","# Fitting the RNN to the Training set\n","\n","model18.fit(X_train, y_train, epochs = 80, batch_size = 32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-GoFsYE-lxjX","executionInfo":{"status":"ok","timestamp":1669959880216,"user_tz":-540,"elapsed":48302,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"43568e50-19b8-4ea2-b60e-4ccfafbf3b5c"},"id":"-GoFsYE-lxjX","execution_count":58,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/80\n","98/98 [==============================] - 3s 6ms/step - loss: 0.2515\n","Epoch 2/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1475\n","Epoch 3/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1345\n","Epoch 4/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1357\n","Epoch 5/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1303\n","Epoch 6/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1241\n","Epoch 7/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1219\n","Epoch 8/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1261\n","Epoch 9/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1163\n","Epoch 10/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1131\n","Epoch 11/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1089\n","Epoch 12/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1148\n","Epoch 13/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1099\n","Epoch 14/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1071\n","Epoch 15/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1190\n","Epoch 16/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1107\n","Epoch 17/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0970\n","Epoch 18/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1083\n","Epoch 19/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1125\n","Epoch 20/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1080\n","Epoch 21/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1086\n","Epoch 22/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1073\n","Epoch 23/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1139\n","Epoch 24/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1144\n","Epoch 25/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1029\n","Epoch 26/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1072\n","Epoch 27/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1051\n","Epoch 28/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1005\n","Epoch 29/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1113\n","Epoch 30/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1194\n","Epoch 31/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1013\n","Epoch 32/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1018\n","Epoch 33/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1050\n","Epoch 34/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1067\n","Epoch 35/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1043\n","Epoch 36/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0987\n","Epoch 37/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1024\n","Epoch 38/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1049\n","Epoch 39/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1123\n","Epoch 40/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1090\n","Epoch 41/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1065\n","Epoch 42/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1010\n","Epoch 43/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0991\n","Epoch 44/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1113\n","Epoch 45/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1062\n","Epoch 46/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0987\n","Epoch 47/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0986\n","Epoch 48/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1055\n","Epoch 49/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1048\n","Epoch 50/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1001\n","Epoch 51/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1051\n","Epoch 52/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1017\n","Epoch 53/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1041\n","Epoch 54/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1008\n","Epoch 55/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1031\n","Epoch 56/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1029\n","Epoch 57/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0959\n","Epoch 58/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1004\n","Epoch 59/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1016\n","Epoch 60/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0995\n","Epoch 61/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1021\n","Epoch 62/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1032\n","Epoch 63/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1068\n","Epoch 64/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1032\n","Epoch 65/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0975\n","Epoch 66/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1029\n","Epoch 67/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0964\n","Epoch 68/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0986\n","Epoch 69/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0957\n","Epoch 70/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0968\n","Epoch 71/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0936\n","Epoch 72/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0985\n","Epoch 73/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0975\n","Epoch 74/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0983\n","Epoch 75/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1008\n","Epoch 76/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0962\n","Epoch 77/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1029\n","Epoch 78/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0994\n","Epoch 79/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0992\n","Epoch 80/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0990\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f5516735c70>"]},"metadata":{},"execution_count":58}]},{"cell_type":"code","source":["predicted_stock_price = model18.predict(X_test)\n","log = feature.iloc[:feature.shape[0]-X_test.shape[0], 0].values\n","data_mean = log.mean(axis=0) \n","data_std = log.std(axis=0)\n","original = (predicted_stock_price)*data_std+data_mean\n","\n","y = feature.iloc[feature.shape[0]-X_test.shape[0]:, 1:2].values\n","rmse = np.sqrt(np.mean(((original - y) ** 2)))\n","print(rmse)\n","\n","res.append(round(measure_accuarcy(original, n_days = 15)[0]  * 100,2))\n","print(measure_diff(original, n_days = 15))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oSAb5w55mVs6","executionInfo":{"status":"ok","timestamp":1669959881348,"user_tz":-540,"elapsed":1135,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"92ef2ca8-f14c-4c5b-ddf6-2a9cfc66f7f1"},"id":"oSAb5w55mVs6","execution_count":59,"outputs":[{"output_type":"stream","name":"stdout","text":["24/24 [==============================] - 1s 3ms/step\n","3.010308060730538\n","[35.57329]\n"]}]},{"cell_type":"code","source":["model19 = Sequential()\n","\n","#Adding the first LSTM layer and some Dropout regularisation\n","\n","model19.add(LSTM(units = 40, return_sequences = True, input_shape = (X_train.shape[-2:])))\n","\n","model19.add(LSTM(60))\n","model19.add(Dropout(0.8))\n","\n","\n","# Adding the output layer i \n"," \n","model19.add(Dense(units = 1))\n","\n","# Compiling the RNN\n","\n","model19.compile(optimizer = 'adam' , loss = 'mean_squared_error' )\n","\n","# Fitting the RNN to the Training set\n","\n","model19.fit(X_train, y_train, epochs = 80, batch_size = 32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-ugI-xfTlsJh","executionInfo":{"status":"ok","timestamp":1669959929373,"user_tz":-540,"elapsed":48030,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"93bb453c-75f2-435a-a895-a3e2a47a7aad"},"id":"-ugI-xfTlsJh","execution_count":60,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/80\n","98/98 [==============================] - 3s 6ms/step - loss: 0.2146\n","Epoch 2/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1174\n","Epoch 3/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1067\n","Epoch 4/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0948\n","Epoch 5/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0915\n","Epoch 6/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0914\n","Epoch 7/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0904\n","Epoch 8/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0960\n","Epoch 9/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0895\n","Epoch 10/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0877\n","Epoch 11/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0890\n","Epoch 12/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0826\n","Epoch 13/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0827\n","Epoch 14/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0844\n","Epoch 15/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0837\n","Epoch 16/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0858\n","Epoch 17/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0807\n","Epoch 18/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0873\n","Epoch 19/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0792\n","Epoch 20/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0824\n","Epoch 21/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0783\n","Epoch 22/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0827\n","Epoch 23/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0821\n","Epoch 24/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0841\n","Epoch 25/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0772\n","Epoch 26/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0760\n","Epoch 27/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0819\n","Epoch 28/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0786\n","Epoch 29/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0792\n","Epoch 30/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0775\n","Epoch 31/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0753\n","Epoch 32/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0742\n","Epoch 33/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0753\n","Epoch 34/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0767\n","Epoch 35/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0776\n","Epoch 36/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0775\n","Epoch 37/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0761\n","Epoch 38/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0810\n","Epoch 39/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0798\n","Epoch 40/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0731\n","Epoch 41/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0783\n","Epoch 42/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0758\n","Epoch 43/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0817\n","Epoch 44/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0743\n","Epoch 45/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0739\n","Epoch 46/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0744\n","Epoch 47/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0743\n","Epoch 48/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0756\n","Epoch 49/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0742\n","Epoch 50/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0728\n","Epoch 51/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0730\n","Epoch 52/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0722\n","Epoch 53/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0734\n","Epoch 54/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0801\n","Epoch 55/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0736\n","Epoch 56/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0748\n","Epoch 57/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0720\n","Epoch 58/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0748\n","Epoch 59/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0755\n","Epoch 60/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0709\n","Epoch 61/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0696\n","Epoch 62/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0690\n","Epoch 63/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0731\n","Epoch 64/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0699\n","Epoch 65/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0718\n","Epoch 66/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0701\n","Epoch 67/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0772\n","Epoch 68/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0714\n","Epoch 69/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0707\n","Epoch 70/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0685\n","Epoch 71/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0782\n","Epoch 72/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0710\n","Epoch 73/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0705\n","Epoch 74/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0704\n","Epoch 75/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0741\n","Epoch 76/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0743\n","Epoch 77/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0713\n","Epoch 78/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0723\n","Epoch 79/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0716\n","Epoch 80/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0699\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f5514418e50>"]},"metadata":{},"execution_count":60}]},{"cell_type":"code","source":["predicted_stock_price = model19.predict(X_test)\n","log = feature.iloc[:feature.shape[0]-X_test.shape[0], 0].values\n","data_mean = log.mean(axis=0) \n","data_std = log.std(axis=0)\n","original = (predicted_stock_price)*data_std+data_mean\n","\n","y = feature.iloc[feature.shape[0]-X_test.shape[0]:, 1:2].values\n","rmse = np.sqrt(np.mean(((original - y) ** 2)))\n","print(rmse)\n","\n","res.append(round(measure_accuarcy(original, n_days = 15)[0]  * 100,2))\n","print(measure_diff(original, n_days = 15))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xM5nhkpWmX7i","executionInfo":{"status":"ok","timestamp":1669959930084,"user_tz":-540,"elapsed":717,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"d20220eb-64dc-4be8-82d2-05fca5506920"},"id":"xM5nhkpWmX7i","execution_count":61,"outputs":[{"output_type":"stream","name":"stdout","text":["24/24 [==============================] - 1s 3ms/step\n","3.02687430926232\n","[46.31391]\n"]}]},{"cell_type":"code","source":["model20 = Sequential()\n","\n","#Adding the first LSTM layer and some Dropout regularisation\n","\n","model20.add(LSTM(units = 40, return_sequences = True, input_shape = (X_train.shape[-2:])))\n","\n","model20.add(LSTM(40))\n","model20.add(Dropout(0.8))\n","\n","\n","# Adding the output layer i \n"," \n","model20.add(Dense(units = 1))\n","\n","# Compiling the RNN\n","\n","model20.compile(optimizer = 'adam' , loss = 'mean_squared_error' )\n","\n","# Fitting the RNN to the Training set\n","\n","model20.fit(X_train, y_train, epochs = 80, batch_size = 32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"riWka8fYl5B2","executionInfo":{"status":"ok","timestamp":1669959978120,"user_tz":-540,"elapsed":48038,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"bd07ed89-b645-42c2-b651-2e6ec9de6ed4"},"id":"riWka8fYl5B2","execution_count":62,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/80\n","98/98 [==============================] - 3s 6ms/step - loss: 0.2901\n","Epoch 2/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1572\n","Epoch 3/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1479\n","Epoch 4/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1303\n","Epoch 5/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1205\n","Epoch 6/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1225\n","Epoch 7/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1220\n","Epoch 8/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1195\n","Epoch 9/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1162\n","Epoch 10/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1180\n","Epoch 11/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1070\n","Epoch 12/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1028\n","Epoch 13/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1068\n","Epoch 14/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1116\n","Epoch 15/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1070\n","Epoch 16/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1072\n","Epoch 17/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1138\n","Epoch 18/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1111\n","Epoch 19/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1122\n","Epoch 20/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1106\n","Epoch 21/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1109\n","Epoch 22/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1155\n","Epoch 23/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1121\n","Epoch 24/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1062\n","Epoch 25/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1090\n","Epoch 26/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1079\n","Epoch 27/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1089\n","Epoch 28/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1044\n","Epoch 29/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1115\n","Epoch 30/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1132\n","Epoch 31/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1028\n","Epoch 32/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1078\n","Epoch 33/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1076\n","Epoch 34/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1117\n","Epoch 35/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1034\n","Epoch 36/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1011\n","Epoch 37/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1020\n","Epoch 38/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1054\n","Epoch 39/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1015\n","Epoch 40/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0969\n","Epoch 41/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1092\n","Epoch 42/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1024\n","Epoch 43/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1054\n","Epoch 44/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1114\n","Epoch 45/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1057\n","Epoch 46/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1010\n","Epoch 47/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1040\n","Epoch 48/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1040\n","Epoch 49/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1051\n","Epoch 50/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1024\n","Epoch 51/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1021\n","Epoch 52/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1006\n","Epoch 53/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1012\n","Epoch 54/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1106\n","Epoch 55/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1015\n","Epoch 56/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1023\n","Epoch 57/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1047\n","Epoch 58/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0989\n","Epoch 59/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0980\n","Epoch 60/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1057\n","Epoch 61/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1017\n","Epoch 62/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1029\n","Epoch 63/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1008\n","Epoch 64/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1037\n","Epoch 65/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1069\n","Epoch 66/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1035\n","Epoch 67/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0963\n","Epoch 68/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1008\n","Epoch 69/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1083\n","Epoch 70/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1019\n","Epoch 71/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1028\n","Epoch 72/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1028\n","Epoch 73/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1026\n","Epoch 74/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0988\n","Epoch 75/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1084\n","Epoch 76/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0953\n","Epoch 77/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1014\n","Epoch 78/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1021\n","Epoch 79/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1028\n","Epoch 80/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0971\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f5514355700>"]},"metadata":{},"execution_count":62}]},{"cell_type":"code","source":["predicted_stock_price = model20.predict(X_test)\n","log = feature.iloc[:feature.shape[0]-X_test.shape[0], 0].values\n","data_mean = log.mean(axis=0) \n","data_std = log.std(axis=0)\n","original = (predicted_stock_price)*data_std+data_mean\n","\n","y = feature.iloc[feature.shape[0]-X_test.shape[0]:, 1:2].values\n","rmse = np.sqrt(np.mean(((original - y) ** 2)))\n","print(rmse)\n","\n","res.append(round(measure_accuarcy(original, n_days = 15)[0]  * 100,2))\n","print(measure_diff(original, n_days = 15))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wTQhtH-pmAfy","executionInfo":{"status":"ok","timestamp":1669959978644,"user_tz":-540,"elapsed":529,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"0625a740-2d39-4ed8-d983-f2dc796643d3"},"id":"wTQhtH-pmAfy","execution_count":63,"outputs":[{"output_type":"stream","name":"stdout","text":["24/24 [==============================] - 1s 3ms/step\n","2.9808229776481125\n","[34.64051]\n"]}]},{"cell_type":"code","source":["model21 = Sequential()\n","\n","#Adding the first LSTM layer and some Dropout regularisation\n","\n","model21.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[-2:])))\n","\n","model21.add(LSTM(50))\n","model21.add(Dropout(0.8))\n","\n","\n","# Adding the output layer i \n"," \n","model21.add(Dense(units = 1))\n","\n","# Compiling the RNN\n","\n","model21.compile(optimizer = 'adam' , loss = 'mean_squared_error' )\n","\n","# Fitting the RNN to the Training set\n","\n","model21.fit(X_train, y_train, epochs = 80, batch_size = 32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zwSU0ZV7ma10","executionInfo":{"status":"ok","timestamp":1669960029212,"user_tz":-540,"elapsed":50573,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"01520d73-827c-4c4d-c868-bfc8c6105c85"},"id":"zwSU0ZV7ma10","execution_count":64,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/80\n","98/98 [==============================] - 3s 6ms/step - loss: 0.2228\n","Epoch 2/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1278\n","Epoch 3/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1100\n","Epoch 4/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1034\n","Epoch 5/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1032\n","Epoch 6/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1012\n","Epoch 7/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1004\n","Epoch 8/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0977\n","Epoch 9/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0959\n","Epoch 10/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0953\n","Epoch 11/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0986\n","Epoch 12/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1000\n","Epoch 13/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0928\n","Epoch 14/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.1004\n","Epoch 15/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0936\n","Epoch 16/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0963\n","Epoch 17/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0887\n","Epoch 18/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0942\n","Epoch 19/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0922\n","Epoch 20/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0919\n","Epoch 21/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0890\n","Epoch 22/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0934\n","Epoch 23/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0859\n","Epoch 24/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0964\n","Epoch 25/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0974\n","Epoch 26/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0869\n","Epoch 27/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0904\n","Epoch 28/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0866\n","Epoch 29/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0893\n","Epoch 30/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0913\n","Epoch 31/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0868\n","Epoch 32/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0808\n","Epoch 33/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0888\n","Epoch 34/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0902\n","Epoch 35/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0908\n","Epoch 36/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0867\n","Epoch 37/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0906\n","Epoch 38/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0842\n","Epoch 39/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0842\n","Epoch 40/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0891\n","Epoch 41/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0908\n","Epoch 42/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0874\n","Epoch 43/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0880\n","Epoch 44/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0805\n","Epoch 45/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0842\n","Epoch 46/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0818\n","Epoch 47/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0845\n","Epoch 48/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0804\n","Epoch 49/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0810\n","Epoch 50/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0852\n","Epoch 51/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0889\n","Epoch 52/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0792\n","Epoch 53/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0833\n","Epoch 54/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0807\n","Epoch 55/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0841\n","Epoch 56/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0816\n","Epoch 57/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0832\n","Epoch 58/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0850\n","Epoch 59/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0828\n","Epoch 60/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0823\n","Epoch 61/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0782\n","Epoch 62/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0820\n","Epoch 63/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0806\n","Epoch 64/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0848\n","Epoch 65/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0816\n","Epoch 66/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0862\n","Epoch 67/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0763\n","Epoch 68/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0845\n","Epoch 69/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0880\n","Epoch 70/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0819\n","Epoch 71/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0821\n","Epoch 72/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0783\n","Epoch 73/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0874\n","Epoch 74/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0857\n","Epoch 75/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0843\n","Epoch 76/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0840\n","Epoch 77/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0857\n","Epoch 78/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0817\n","Epoch 79/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0850\n","Epoch 80/80\n","98/98 [==============================] - 1s 6ms/step - loss: 0.0809\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f551086f820>"]},"metadata":{},"execution_count":64}]},{"cell_type":"code","source":["predicted_stock_price = model21.predict(X_test)\n","log = feature.iloc[:feature.shape[0]-X_test.shape[0], 0].values\n","data_mean = log.mean(axis=0) \n","data_std = log.std(axis=0)\n","original = (predicted_stock_price)*data_std+data_mean\n","\n","y = feature.iloc[feature.shape[0]-X_test.shape[0]:, 1:2].values\n","rmse = np.sqrt(np.mean(((original - y) ** 2)))\n","print(rmse)\n","\n","res.append(round(measure_accuarcy(original, n_days = 15)[0]  * 100,2))\n","print(measure_diff(original, n_days = 15))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yC_4fwKfnhzh","executionInfo":{"status":"ok","timestamp":1669960029735,"user_tz":-540,"elapsed":530,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"ee5be990-e9dc-42dd-a4e9-fb554466a5b0"},"id":"yC_4fwKfnhzh","execution_count":65,"outputs":[{"output_type":"stream","name":"stdout","text":["24/24 [==============================] - 1s 3ms/step\n","2.9906063610686147\n","[32.2612]\n"]}]},{"cell_type":"code","source":["score = pd.DataFrame(res)\n","score"],"metadata":{"id":"aZYBvhcUnkTd","colab":{"base_uri":"https://localhost:8080/","height":700},"executionInfo":{"status":"ok","timestamp":1669960029736,"user_tz":-540,"elapsed":18,"user":{"displayName":"구태형","userId":"12113658638621684006"}},"outputId":"6026b990-a950-441f-a75b-833f4111fd01"},"id":"aZYBvhcUnkTd","execution_count":66,"outputs":[{"output_type":"execute_result","data":{"text/plain":["        0\n","0   54.55\n","1   62.57\n","2   63.50\n","3   55.21\n","4   61.36\n","5   67.25\n","6   58.29\n","7   71.39\n","8   54.01\n","9   65.78\n","10  60.29\n","11  72.59\n","12  60.56\n","13  73.93\n","14  59.89\n","15  69.79\n","16  75.00\n","17  71.93\n","18  74.47\n","19  76.07\n","20  75.40"],"text/html":["\n","  <div id=\"df-e2b55ad2-f979-40f3-b2f3-739507ce00f2\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>54.55</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>62.57</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>63.50</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>55.21</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>61.36</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>67.25</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>58.29</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>71.39</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>54.01</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>65.78</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>60.29</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>72.59</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>60.56</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>73.93</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>59.89</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>69.79</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>75.00</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>71.93</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>74.47</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>76.07</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>75.40</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e2b55ad2-f979-40f3-b2f3-739507ce00f2')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-e2b55ad2-f979-40f3-b2f3-739507ce00f2 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-e2b55ad2-f979-40f3-b2f3-739507ce00f2');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":66}]},{"cell_type":"code","source":["score.to_csv('res_5.csv', index=False)"],"metadata":{"id":"jaodNUGU4Wul","executionInfo":{"status":"ok","timestamp":1669960029737,"user_tz":-540,"elapsed":15,"user":{"displayName":"구태형","userId":"12113658638621684006"}}},"id":"jaodNUGU4Wul","execution_count":67,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"A3iqPuXG5HhD","executionInfo":{"status":"ok","timestamp":1669960029737,"user_tz":-540,"elapsed":14,"user":{"displayName":"구태형","userId":"12113658638621684006"}}},"id":"A3iqPuXG5HhD","execution_count":67,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"provenance":[]},"accelerator":"GPU","gpuClass":"premium"},"nbformat":4,"nbformat_minor":5}